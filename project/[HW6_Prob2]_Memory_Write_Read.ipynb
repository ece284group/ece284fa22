{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tensorboardX import SummaryWriter      \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"VGG16_quant_proj\" # vgg16_quant_proj \n",
    "model = VGG16_quant_proj()\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW\n",
    "\n",
    "#  1. Load your saved model and validate\n",
    "#  2. Replace your model's all the Conv's weight with quantized weight\n",
    "#  3. Apply reasonable alpha\n",
    "#  4. Then, try to multiple bit precisions and draw graph of bit precision vs. accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"result/VGG16_quant_proj/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -th layer prehooked\n",
      "7 -th layer prehooked\n",
      "12 -th layer prehooked\n",
      "16 -th layer prehooked\n",
      "21 -th layer prehooked\n",
      "25 -th layer prehooked\n",
      "29 -th layer prehooked\n",
      "34 -th layer prehooked\n",
      "38 -th layer prehooked\n",
      "42 -th layer prehooked\n",
      "47 -th layer prehooked\n",
      "51 -th layer prehooked\n",
      "55 -th layer prehooked\n"
     ]
    }
   ],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.0000, -1.0000, -3.0000],\n",
      "          [-2.0000, -3.0000, -2.0000],\n",
      "          [-1.0000, -2.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000,  2.0000],\n",
      "          [-1.0000,  1.0000,  0.0000],\n",
      "          [-0.0000, -1.0000,  1.0000]],\n",
      "\n",
      "         [[-0.0000,  2.0000, -1.0000],\n",
      "          [ 2.0000,  1.0000,  2.0000],\n",
      "          [ 0.0000,  2.0000,  1.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0000,  0.0000,  3.0000],\n",
      "          [ 2.0000,  1.0000, -1.0000],\n",
      "          [ 2.0000,  0.0000, -1.0000]],\n",
      "\n",
      "         [[ 2.0000,  0.0000,  1.0000],\n",
      "          [ 4.0000,  3.0000,  1.0000],\n",
      "          [ 1.0000,  3.0000,  1.0000]],\n",
      "\n",
      "         [[-3.0000, -3.0000, -2.0000],\n",
      "          [-1.0000, -2.0000, -3.0000],\n",
      "          [-2.0000, -2.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  1.0000,  4.0000],\n",
      "          [ 3.0000,  2.0000,  2.0000],\n",
      "          [ 1.0000,  2.0000,  3.0000]],\n",
      "\n",
      "         [[ 1.0000,  2.0000,  1.0000],\n",
      "          [-2.0000,  1.0000,  1.0000],\n",
      "          [-3.0000, -1.0000,  0.0000]],\n",
      "\n",
      "         [[ 5.0000,  5.0000,  4.0000],\n",
      "          [ 4.0000,  1.0000, -0.0000],\n",
      "          [ 2.0000,  1.0000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0000, -1.0000, -1.0000],\n",
      "          [-2.0000, -1.0000, -2.0000],\n",
      "          [-1.0000,  0.0000, -1.0000]],\n",
      "\n",
      "         [[ 0.0000,  2.0000, -2.0000],\n",
      "          [-0.0000,  2.0000, -2.0000],\n",
      "          [-2.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000,  1.0000,  2.0000],\n",
      "          [ 2.0000, -1.0000,  2.0000],\n",
      "          [ 1.0000,  1.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-2.0000, -1.0000, -3.0000],\n",
      "          [ 0.0000, -1.0000, -1.0000],\n",
      "          [ 1.0000,  1.0000,  2.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -3.0000],\n",
      "          [ 0.0000, -0.0000, -2.0000],\n",
      "          [ 1.0000,  3.0000,  2.0000]],\n",
      "\n",
      "         [[ 2.0000,  3.0000,  2.0000],\n",
      "          [ 5.0000,  3.0000,  1.0000],\n",
      "          [ 4.0000,  2.0000,  2.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0000,  0.0000,  1.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000],\n",
      "          [ 3.0000,  2.0000,  1.0000]],\n",
      "\n",
      "         [[-0.0000, -1.0000, -2.0000],\n",
      "          [ 3.0000,  3.0000, -2.0000],\n",
      "          [ 0.0000,  2.0000, -0.0000]],\n",
      "\n",
      "         [[-3.0000, -3.0000, -2.0000],\n",
      "          [-1.0000, -2.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.0000, -4.0000, -3.0000],\n",
      "          [-0.0000, -2.0000, -3.0000],\n",
      "          [ 0.0000, -4.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  0.0000, -2.0000],\n",
      "          [ 1.0000,  1.0000, -3.0000],\n",
      "          [ 2.0000,  1.0000, -3.0000]],\n",
      "\n",
      "         [[ 0.0000, -2.0000, -3.0000],\n",
      "          [-2.0000, -3.0000, -1.0000],\n",
      "          [-3.0000, -3.0000, -3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0000,  3.0000,  3.0000],\n",
      "          [-1.0000,  0.0000,  4.0000],\n",
      "          [-1.0000,  1.0000,  2.0000]],\n",
      "\n",
      "         [[ 2.0000,  0.0000,  2.0000],\n",
      "          [ 3.0000,  3.0000,  1.0000],\n",
      "          [ 3.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -3.0000],\n",
      "          [-1.0000, -3.0000, -2.0000],\n",
      "          [-1.0000, -1.0000, -4.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  3.0000,  1.0000],\n",
      "          [ 3.0000,  2.0000,  3.0000],\n",
      "          [ 3.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -1.0000],\n",
      "          [ 0.0000, -2.0000, -1.0000]],\n",
      "\n",
      "         [[ 3.0000,  2.0000,  2.0000],\n",
      "          [ 4.0000,  4.0000,  4.0000],\n",
      "          [ 4.0000,  4.0000,  4.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  1.0000, -0.0000],\n",
      "          [-1.0000, -0.0000, -1.0000],\n",
      "          [-1.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-3.0000, -5.0000, -4.0000],\n",
      "          [-2.0000, -3.0000, -2.0000],\n",
      "          [-3.0000, -3.0000, -4.0000]],\n",
      "\n",
      "         [[ 0.0000,  1.0000,  0.0000],\n",
      "          [ 0.0000,  1.0000, -0.0000],\n",
      "          [ 2.0000,  2.0000,  3.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0000,  1.0000,  0.0000],\n",
      "          [-0.0000, -3.0000, -2.0000],\n",
      "          [-2.0000, -1.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000,  1.0000, -1.0000],\n",
      "          [ 2.0000, -0.0000, -0.0000],\n",
      "          [ 2.0000, -1.0000,  2.0000]],\n",
      "\n",
      "         [[ 1.0000, -1.0000, -1.0000],\n",
      "          [ 0.0000,  0.0000, -1.0000],\n",
      "          [-0.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0000,  1.0000,  1.0000],\n",
      "          [-0.0000, -0.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  7.0000,  6.0000],\n",
      "          [-4.0000,  3.0000,  3.0000],\n",
      "          [-7.0000, -1.0000,  2.0000]],\n",
      "\n",
      "         [[-5.0000, -3.0000, -3.0000],\n",
      "          [-4.0000, -3.0000, -2.0000],\n",
      "          [-2.0000, -1.0000,  0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "weight_q = model.features[3].weight_q\n",
    "w_alpha = model.features[3].weight_quant.wgt_alpha\n",
    "w_bit = 4\n",
    "\n",
    "weight_int = weight_q / (w_alpha / (2**(w_bit-1)-1))\n",
    "print(weight_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [1., 2., 2.,  ..., 2., 2., 1.],\n",
      "          [1., 2., 2.,  ..., 1., 2., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 2., 1.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 2.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 3.],\n",
      "          [0., 1., 1.,  ..., 0., 1., 3.],\n",
      "          ...,\n",
      "          [0., 0., 1.,  ..., 0., 0., 3.],\n",
      "          [0., 0., 1.,  ..., 0., 0., 3.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [2., 2., 2.,  ..., 2., 3., 1.],\n",
      "          [1., 2., 2.,  ..., 2., 3., 1.],\n",
      "          [1., 1., 1.,  ..., 2., 2., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[2., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [2., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [2., 0., 0.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 3., 1.,  ..., 1., 4., 2.],\n",
      "          [0., 2., 2.,  ..., 0., 1., 2.],\n",
      "          [0., 0., 1.,  ..., 0., 0., 4.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 0., 0., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 2., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 2., 1.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2.,  ..., 2., 2., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "          [0., 1., 1.,  ..., 0., 0., 0.],\n",
      "          [1., 1., 2.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[5., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 2., 1., 0.],\n",
      "          [0., 0., 0.,  ..., 2., 1., 0.],\n",
      "          [0., 0., 0.,  ..., 2., 2., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 2.,  ..., 0., 0., 0.],\n",
      "          [0., 1., 1.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 2., 2.,  ..., 2., 2., 6.],\n",
      "          [0., 2., 2.,  ..., 2., 2., 1.],\n",
      "          [0., 2., 2.,  ..., 2., 2., 1.],\n",
      "          ...,\n",
      "          [2., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "          [0., 0., 1.,  ..., 2., 0., 0.]],\n",
      "\n",
      "         [[4., 3., 3.,  ..., 3., 3., 1.],\n",
      "          [2., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [2., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 1.,  ..., 1., 0., 0.],\n",
      "          [0., 1., 2.,  ..., 0., 0., 0.],\n",
      "          [2., 3., 4.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 2., 2.,  ..., 2., 3., 2.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 0., 0., 0.],\n",
      "          [0., 1., 1.,  ..., 0., 0., 0.],\n",
      "          [1., 2., 2.,  ..., 3., 3., 2.]],\n",
      "\n",
      "         [[3., 0., 0.,  ..., 1., 1., 0.],\n",
      "          [3., 0., 0.,  ..., 1., 0., 0.],\n",
      "          [3., 0., 0.,  ..., 1., 0., 0.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 0., 0., 6.],\n",
      "          [0., 1., 1.,  ..., 0., 1., 6.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 3.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [2., 1., 2.,  ..., 2., 2., 1.],\n",
      "          [2., 2., 2.,  ..., 2., 2., 1.],\n",
      "          [1., 0., 1.,  ..., 1., 1., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 1., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 3., 4.,  ..., 1., 2., 7.],\n",
      "          [0., 2., 3.,  ..., 2., 2., 1.],\n",
      "          [0., 1., 2.,  ..., 3., 2., 1.],\n",
      "          ...,\n",
      "          [4., 3., 2.,  ..., 3., 1., 2.],\n",
      "          [4., 2., 2.,  ..., 2., 0., 2.],\n",
      "          [0., 2., 2.,  ..., 1., 2., 9.]],\n",
      "\n",
      "         [[3., 2., 1.,  ..., 4., 4., 1.],\n",
      "          [2., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 1., 0.,  ..., 0., 0., 1.],\n",
      "          [2., 4., 4.,  ..., 5., 5., 3.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 0.,  ..., 0., 0., 2.],\n",
      "          [2., 0., 1.,  ..., 0., 0., 2.],\n",
      "          [2., 0., 0.,  ..., 0., 0., 3.],\n",
      "          ...,\n",
      "          [3., 2., 0.,  ..., 2., 1., 2.],\n",
      "          [3., 3., 1.,  ..., 3., 2., 2.],\n",
      "          [2., 3., 2.,  ..., 2., 1., 1.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 2., 2.,  ..., 5., 4., 1.],\n",
      "          [0., 1., 1.,  ..., 3., 2., 1.],\n",
      "          [1., 2., 2.,  ..., 4., 2., 0.],\n",
      "          ...,\n",
      "          [2., 0., 0.,  ..., 0., 0., 2.],\n",
      "          [3., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [4., 4., 1.,  ..., 4., 2., 3.]],\n",
      "\n",
      "         [[2., 2., 2.,  ..., 1., 0., 0.],\n",
      "          [1., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 3., 2., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[3., 2., 2.,  ..., 1., 1., 0.],\n",
      "          [2., 1., 1.,  ..., 0., 1., 0.],\n",
      "          [3., 1., 1.,  ..., 0., 1., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 2.],\n",
      "          [1., 1., 1.,  ..., 2., 1., 2.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 1.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 2., 0.,  ..., 2., 1., 3.],\n",
      "          [0., 2., 1.,  ..., 1., 0., 0.],\n",
      "          [0., 2., 2.,  ..., 1., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 2., 3., 2.],\n",
      "          [0., 0., 0.,  ..., 1., 2., 2.],\n",
      "          [0., 0., 0.,  ..., 2., 2., 3.]],\n",
      "\n",
      "         [[2., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 0.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 0.],\n",
      "          [0., 0., 0.,  ..., 3., 3., 2.]],\n",
      "\n",
      "         [[0., 0., 1.,  ..., 0., 1., 6.],\n",
      "          [0., 1., 1.,  ..., 0., 1., 7.],\n",
      "          [0., 1., 1.,  ..., 0., 1., 7.],\n",
      "          ...,\n",
      "          [2., 1., 1.,  ..., 1., 1., 7.],\n",
      "          [2., 1., 1.,  ..., 1., 1., 7.],\n",
      "          [2., 1., 1.,  ..., 0., 0., 3.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 3., 3., 1.],\n",
      "          [1., 0., 0.,  ..., 2., 2., 1.],\n",
      "          [1., 0., 0.,  ..., 2., 2., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 2., 2., 1.],\n",
      "          [0., 0., 0.,  ..., 2., 2., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[5., 1., 1.,  ..., 2., 1., 0.],\n",
      "          [3., 1., 2.,  ..., 3., 2., 2.],\n",
      "          [3., 1., 2.,  ..., 3., 2., 2.],\n",
      "          ...,\n",
      "          [3., 2., 2.,  ..., 1., 1., 2.],\n",
      "          [1., 3., 3.,  ..., 2., 1., 2.],\n",
      "          [2., 2., 3.,  ..., 2., 2., 9.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 5., 6., 3.]]]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "act = save_output.outputs[1][0]\n",
    "act_alpha  = model.features[3].act_alpha\n",
    "act_bit = 4\n",
    "act_quant_fn = act_quantization(act_bit)\n",
    "\n",
    "act_q = act_quant_fn(act, act_alpha)\n",
    "\n",
    "act_int = act_q / (act_alpha / (2**act_bit-1))\n",
    "print(act_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-above",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[  -5.6834,  -16.2083,  -25.2596,  ...,  -17.4712,  -16.8397,\n",
      "            -27.3646],\n",
      "          [  -0.2105,  -12.8403,  -27.1541,  ...,  -10.5248,   -2.3155,\n",
      "            -19.1552],\n",
      "          [  -6.3149,  -18.5237,  -29.2590,  ...,  -34.3110,   -9.2619,\n",
      "            -19.7867],\n",
      "          ...,\n",
      "          [ -37.2579,  -41.8889,  -28.8381,  ...,  -50.3087,  -21.4707,\n",
      "             -4.8414],\n",
      "          [ -45.4673,  -59.1496,  -40.2049,  ...,  -60.8336,  -38.0999,\n",
      "            -14.3138],\n",
      "          [ -28.2066,  -45.0463,  -34.7320,  ...,  -42.5203,  -26.9436,\n",
      "            -17.6817]],\n",
      "\n",
      "         [[ -20.6287,  -41.6784,  -35.1530,  ...,  -36.8369,  -42.5203,\n",
      "            -26.7331],\n",
      "          [ -25.4701,  -57.6761,  -47.7828,  ...,  -39.3629,  -47.7828,\n",
      "            -23.5756],\n",
      "          [ -27.7856,  -59.1496,  -43.7833,  ...,  -50.3087,  -57.6761,\n",
      "            -25.8911],\n",
      "          ...,\n",
      "          [  -5.0519,   30.7325,   20.2077,  ...,    1.0525,   32.4165,\n",
      "             32.2060],\n",
      "          [ -14.9453,   13.4718,   15.5768,  ...,    3.7889,   15.1558,\n",
      "             42.3098],\n",
      "          [   3.3679,   19.3657,   27.9961,  ...,   17.0502,   13.2613,\n",
      "             35.7844]],\n",
      "\n",
      "         [[  25.6806,   66.3065,   71.3584,  ...,   90.7241,   87.3562,\n",
      "             76.6208],\n",
      "          [  47.1513,  103.9854,  110.0898,  ...,  125.0351,  110.5108,\n",
      "            100.4070],\n",
      "          [  45.0463,   99.5650,  102.9329,  ...,   79.7783,   77.2523,\n",
      "             80.1993],\n",
      "          ...,\n",
      "          [   6.5254,   30.3115,   30.3115,  ...,   29.6800,   43.3623,\n",
      "             55.3606],\n",
      "          [   3.3679,   19.7867,   18.5237,  ...,   39.7839,   34.3110,\n",
      "             49.8877],\n",
      "          [  13.2613,   32.8375,   29.6800,  ...,   32.2060,   14.5243,\n",
      "             35.7844]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -19.7867,  -18.9447,  -25.0491,  ...,  -14.9453,  -15.5768,\n",
      "              5.6834],\n",
      "          [  -7.5779,   10.5248,    5.6834,  ...,   30.3115,   24.2071,\n",
      "             32.6270],\n",
      "          [  -7.5779,   11.3668,    2.3155,  ...,    7.1569,   -3.7889,\n",
      "             12.4193],\n",
      "          ...,\n",
      "          [ -33.8900,  -56.8341,  -37.0474,  ...,  -50.0982,  -54.9397,\n",
      "              2.5260],\n",
      "          [ -42.9413,  -70.9374,  -59.7811,  ...,  -72.8319,  -69.0429,\n",
      "            -17.4712],\n",
      "          [ -12.2088,  -23.1546,  -19.7867,  ...,  -14.1033,  -16.8397,\n",
      "              2.3155]],\n",
      "\n",
      "         [[  12.4193,   26.1016,   39.1524,  ...,   30.3115,   28.4171,\n",
      "             17.2607],\n",
      "          [  -6.5254,   -1.4735,    9.6828,  ...,  -27.7856,  -15.9978,\n",
      "             -2.5260],\n",
      "          [  -8.2094,   -7.5779,    1.0525,  ...,  -16.4187,    3.3679,\n",
      "              3.7889],\n",
      "          ...,\n",
      "          [  61.6755,   92.1976,   88.4086,  ...,   87.9876,   85.0407,\n",
      "             51.7822],\n",
      "          [  72.4109,  112.6158,  123.7721,  ...,  121.8776,  112.6158,\n",
      "             69.4639],\n",
      "          [  29.2590,   51.1507,   56.2026,  ...,   60.2021,   59.3601,\n",
      "             32.6270]],\n",
      "\n",
      "         [[ -11.7878,  -65.0435,  -62.5175,  ...,  -71.9899,  -79.7783,\n",
      "            -79.3573],\n",
      "          [  12.6298,  -80.8308,  -92.1976,  ...,  -99.9860, -104.8274,\n",
      "           -109.2478],\n",
      "          [  28.4171,  -70.3059,  -89.2506,  ...,  -78.7258,  -91.7766,\n",
      "           -101.4594],\n",
      "          ...,\n",
      "          [ -64.2015,    2.9470,   -3.9994,  ...,  -16.2083,   11.1563,\n",
      "             17.2607],\n",
      "          [ -73.0424,  -24.4176,  -20.8392,  ...,  -23.1546,   -7.1569,\n",
      "             23.7861],\n",
      "          [ -57.8866,  -46.5198,  -35.1530,  ...,  -38.5209,  -29.0486,\n",
      "              1.4735]]],\n",
      "\n",
      "\n",
      "        [[[ -50.9402,  -83.1462,  -48.6247,  ...,  -48.6247,  -63.5700,\n",
      "            -29.6800],\n",
      "          [ -42.5203,  -97.6705,  -58.9391,  ...,  -58.9391,  -87.7771,\n",
      "            -64.8330],\n",
      "          [ -19.1552,  -64.6225,  -27.5751,  ...,  -27.5751,  -59.5706,\n",
      "            -47.9933],\n",
      "          ...,\n",
      "          [ -41.2574,  -46.9408,  -32.4165,  ...,  -28.8381,  -56.2026,\n",
      "            -41.2574],\n",
      "          [ -54.5187,  -58.3076,  -40.4154,  ...,  -35.5740,  -73.2529,\n",
      "            -65.6750],\n",
      "          [ -49.0457,  -61.2546,  -43.9938,  ...,   -2.3155,  -28.4171,\n",
      "            -42.3098]],\n",
      "\n",
      "         [[ -27.9961,    2.3155,  -10.9458,  ...,  -10.9458,   -1.0525,\n",
      "            -51.9927],\n",
      "          [ -35.1530,  -21.4707,  -44.4148,  ...,  -44.4148,  -16.4187,\n",
      "            -93.2501],\n",
      "          [ -38.0999,  -26.3121,  -41.0469,  ...,  -41.0469,   -9.2619,\n",
      "            -97.6705],\n",
      "          ...,\n",
      "          [ -29.0486,  -40.4154,   -9.6828,  ...,   -9.8933,    0.0000,\n",
      "            -59.1496],\n",
      "          [ -24.2071,  -17.4712,   11.3668,  ...,  -31.3640,  -29.0486,\n",
      "            -74.7263],\n",
      "          [  -8.8409,   -2.1050,   15.1558,  ...,    1.2630,    1.2630,\n",
      "            -43.5728]],\n",
      "\n",
      "         [[  29.6800,   38.9419,   34.1005,  ...,   34.1005,   32.8375,\n",
      "             48.8352],\n",
      "          [  40.2049,   51.9927,   33.0480,  ...,   33.0480,   28.8381,\n",
      "             47.7828],\n",
      "          [  64.2015,   69.2534,   47.9933,  ...,   47.9933,   44.4148,\n",
      "             53.4662],\n",
      "          ...,\n",
      "          [  20.6287,   81.4622,   82.3042,  ...,   35.7844,   35.7844,\n",
      "             41.2574],\n",
      "          [  17.4712,   67.3590,   67.9904,  ...,   20.6287,   25.4701,\n",
      "             34.5215],\n",
      "          [ -10.1038,   20.4182,   24.8386,  ...,   38.3104,   39.7839,\n",
      "             37.2579]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -11.5773,  -37.2579,  -42.9413,  ...,  -42.9413,  -49.8877,\n",
      "            -31.7850],\n",
      "          [  24.4176,    8.8409,    0.6315,  ...,    0.6315,  -13.4718,\n",
      "             -5.6834],\n",
      "          [  53.4662,   40.2049,   22.1022,  ...,   22.1022,   11.5773,\n",
      "             15.5768],\n",
      "          ...,\n",
      "          [ -27.5751,  -37.2579,  -43.3623,  ...,    5.0519,    6.9464,\n",
      "              7.1569],\n",
      "          [ -42.9413,  -56.2026,  -66.3065,  ...,    0.2105,   -6.5254,\n",
      "             -3.5784],\n",
      "          [ -22.5232,  -31.3640,  -33.4690,  ...,   37.2579,   36.2054,\n",
      "             31.5745]],\n",
      "\n",
      "         [[  28.8381,   55.1502,   40.6259,  ...,   40.6259,   45.6778,\n",
      "             53.8872],\n",
      "          [  26.3121,   32.8375,   10.7353,  ...,   10.7353,   12.4193,\n",
      "             42.0993],\n",
      "          [  26.9436,   34.9425,   16.2083,  ...,   16.2083,   16.8397,\n",
      "             49.6772],\n",
      "          ...,\n",
      "          [   9.2619,   26.3121,   40.2049,  ...,   36.8369,   34.3110,\n",
      "             51.1507],\n",
      "          [  21.4707,   42.5203,   51.9927,  ...,   62.9385,   67.1485,\n",
      "             67.5695],\n",
      "          [  10.3143,   17.2607,   15.7873,  ...,   29.4695,   37.8894,\n",
      "             38.5209]],\n",
      "\n",
      "         [[ -41.6784,  -31.5745,  -46.0988,  ...,  -46.0988,  -45.6778,\n",
      "            -47.7828],\n",
      "          [ -37.4684,  -41.4679,  -54.9397,  ...,  -54.9397,  -54.3082,\n",
      "            -75.7788],\n",
      "          [ -21.6812,  -19.1552,  -22.9441,  ...,  -22.9441,  -33.8900,\n",
      "            -70.9374],\n",
      "          ...,\n",
      "          [ -13.4718,  -43.3623,  -57.8866,  ...,  -19.7867,  -22.5232,\n",
      "            -33.6795],\n",
      "          [ -15.7873,  -53.4662,  -62.3070,  ...,  -17.8922,  -15.9978,\n",
      "            -23.7861],\n",
      "          [ -17.8922,  -54.5187,  -57.2551,  ...,  -30.1010,  -34.1005,\n",
      "            -42.0993]]],\n",
      "\n",
      "\n",
      "        [[[ -51.3612,  -69.8849,  -20.4182,  ...,  -50.9402,  -72.2004,\n",
      "            -30.7325],\n",
      "          [ -58.7286, -111.1423,  -54.3082,  ...,  -58.3076,  -99.1440,\n",
      "            -72.8319],\n",
      "          [ -35.7844,  -90.9346,  -37.0474,  ...,  -21.8917,  -62.9385,\n",
      "            -50.9402],\n",
      "          ...,\n",
      "          [  -9.0514,   -8.2094,  -13.0508,  ...,   -9.0514,    0.2105,\n",
      "            -18.5237],\n",
      "          [ -21.2602,  -17.0502,  -18.5237,  ...,  -17.0502,   10.9458,\n",
      "             -2.5260],\n",
      "          [ -34.3110,  -35.7844,  -31.7850,  ...,  -34.9425,   -6.9464,\n",
      "             -3.7889]],\n",
      "\n",
      "         [[ -20.4182,    0.0000,  -14.1033,  ...,  -15.5768,   -3.1575,\n",
      "            -49.0457],\n",
      "          [ -19.1552,   -6.5254,  -35.7844,  ...,  -50.7297,  -18.3132,\n",
      "            -90.0926],\n",
      "          [ -25.2596,  -23.7861,  -50.3087,  ...,  -47.7828,   -9.8933,\n",
      "            -95.5655],\n",
      "          ...,\n",
      "          [  12.8403,   -4.2099,   16.4187,  ...,   -6.5254,  -22.9441,\n",
      "             15.9978],\n",
      "          [  13.2613,    3.5784,   26.5226,  ...,    4.4204,   -6.1044,\n",
      "             29.4695],\n",
      "          [  18.7342,   21.8917,   33.8900,  ...,   17.2607,   16.2083,\n",
      "             43.9938]],\n",
      "\n",
      "         [[   8.4199,    3.5784,    4.6309,  ...,   31.3640,   26.9436,\n",
      "             44.2043],\n",
      "          [   5.2624,    4.4204,    3.3679,  ...,   19.5762,    7.3674,\n",
      "             33.4690],\n",
      "          [  37.2579,   34.1005,   36.2054,  ...,   52.8347,   42.3098,\n",
      "             54.3082],\n",
      "          ...,\n",
      "          [  31.3640,   78.9363,   53.6767,  ...,   76.4103,   81.0412,\n",
      "            114.0892],\n",
      "          [  30.3115,   81.8832,   50.9402,  ...,  100.4070,   86.9352,\n",
      "            104.6169],\n",
      "          [   3.9994,   28.4171,   17.6817,  ...,   29.8905,   17.2607,\n",
      "             58.5181]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -22.5232,  -51.1507,  -61.2546,  ...,  -45.2568,  -52.6242,\n",
      "            -35.7844],\n",
      "          [  -2.3155,  -34.7320,  -49.2562,  ...,    2.3155,  -18.3132,\n",
      "            -17.8922],\n",
      "          [  31.9955,    9.4724,   -9.6828,  ...,   30.1010,   15.3663,\n",
      "             16.4187],\n",
      "          ...,\n",
      "          [ -37.6789,    2.9470,  -17.6817,  ...,   -8.8409,  -22.3127,\n",
      "             25.4701],\n",
      "          [ -55.3606,  -28.2066,  -43.5728,  ...,  -34.9425,  -37.6789,\n",
      "             15.7873],\n",
      "          [ -32.4165,  -14.5243,  -24.8386,  ...,  -15.1558,  -13.0508,\n",
      "             21.0497]],\n",
      "\n",
      "         [[  39.9944,   68.8324,   51.7822,  ...,   41.0469,   48.2038,\n",
      "             55.7816],\n",
      "          [  50.0982,   67.9904,   43.9938,  ...,   19.9972,   27.3646,\n",
      "             53.2557],\n",
      "          [  42.0993,   57.4656,   29.2590,  ...,   22.5232,   26.1016,\n",
      "             55.7816],\n",
      "          ...,\n",
      "          [   9.2619,   42.9413,   44.6253,  ...,   34.7320,   13.4718,\n",
      "              4.4204],\n",
      "          [  27.7856,   70.7269,   75.1473,  ...,   65.0435,   47.1513,\n",
      "             23.1546],\n",
      "          [   5.4729,   31.7850,   30.5220,  ...,   24.2071,   18.5237,\n",
      "              5.4729]],\n",
      "\n",
      "         [[ -38.3104,   -1.6840,  -12.8403,  ...,  -54.0977,  -43.1518,\n",
      "            -41.0469],\n",
      "          [ -50.9402,  -19.1552,  -20.8392,  ...,  -64.2015,  -48.2038,\n",
      "            -59.5706],\n",
      "          [ -50.9402,  -23.3651,  -12.2088,  ...,  -26.1016,  -25.6806,\n",
      "            -53.6767],\n",
      "          ...,\n",
      "          [  -5.6834,  -33.4690,  -14.3138,  ...,  -13.0508,  -28.2066,\n",
      "            -55.5711],\n",
      "          [ -20.6287,  -45.2568,  -24.8386,  ...,  -34.1005,  -40.8364,\n",
      "            -54.3082],\n",
      "          [ -31.3640,  -55.3606,  -47.3618,  ...,  -54.0977,  -48.4143,\n",
      "            -45.8883]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -25.8911,  -42.3098,  -27.9961,  ...,  -15.1558,  -17.6817,\n",
      "            -20.6287],\n",
      "          [ -17.8922,  -45.2568,  -32.4165,  ...,  -42.0993,  -35.7844,\n",
      "            -30.5220],\n",
      "          [ -13.2613,  -31.1535,  -26.7331,  ...,  -38.9419,  -34.7320,\n",
      "            -38.0999],\n",
      "          ...,\n",
      "          [   8.6304,  -41.8889,  -61.2546,  ...,  -98.5125,  -71.3584,\n",
      "            -36.2054],\n",
      "          [  15.3663,  -23.1546,  -61.0441,  ...,  -19.5762,  -38.3104,\n",
      "            -26.5226],\n",
      "          [  17.4712,    5.2624,  -24.2071,  ...,    8.6304,    1.4735,\n",
      "             -7.7884]],\n",
      "\n",
      "         [[ -36.8369,  -15.9978,  -26.9436,  ...,  -62.5175,  -48.2038,\n",
      "            -15.3663],\n",
      "          [ -49.4667,  -36.2054,  -49.6772,  ...,  -89.8821,  -59.7811,\n",
      "             -8.4199],\n",
      "          [ -51.7822,  -38.5209,  -53.4662,  ..., -104.4064,  -69.8849,\n",
      "            -15.9978],\n",
      "          ...,\n",
      "          [ -38.0999,  -67.5695,  -81.2517,  ...,  -58.5181,  -25.2596,\n",
      "             -9.8933],\n",
      "          [ -26.3121,  -59.1496,  -85.2512,  ...,  -27.1541,  -27.7856,\n",
      "             -5.4729],\n",
      "          [  -4.4204,  -21.4707,  -39.5734,  ...,   27.3646,   13.6823,\n",
      "             19.7867]],\n",
      "\n",
      "         [[  28.4171,   50.7297,   53.4662,  ...,  126.0876,   93.4606,\n",
      "             57.6761],\n",
      "          [  49.4667,   83.7777,   77.2523,  ...,  174.0808,  119.1412,\n",
      "             81.8832],\n",
      "          [  39.1524,   70.5164,   59.7811,  ...,  110.9318,   92.8291,\n",
      "             73.6739],\n",
      "          ...,\n",
      "          [  43.9938,   82.3042,   91.3556,  ...,   67.9904,   63.5700,\n",
      "             64.4120],\n",
      "          [  32.4165,   78.9363,   78.0943,  ...,   57.0446,   35.9949,\n",
      "             34.1005],\n",
      "          [  -0.8420,   22.1022,   18.5237,  ...,   20.4182,   16.4187,\n",
      "             23.7861]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -12.8403,  -31.7850,  -21.0497,  ...,  -19.7867,  -24.8386,\n",
      "             -1.6840],\n",
      "          [  18.9447,   15.9978,   24.4176,  ...,   42.7308,   23.5756,\n",
      "             23.5756],\n",
      "          [  33.4690,   35.9949,   35.9949,  ...,   41.6784,   21.6812,\n",
      "             29.4695],\n",
      "          ...,\n",
      "          [  34.5215,   72.4109,   54.9397,  ...,   43.1518,    3.9994,\n",
      "             14.9453],\n",
      "          [  40.6259,   82.7252,   69.4639,  ...,   65.0435,   41.0469,\n",
      "             31.9955],\n",
      "          [  33.0480,   72.2004,   74.7263,  ...,   28.4171,   27.9961,\n",
      "             27.9961]],\n",
      "\n",
      "         [[  16.8397,   26.3121,   23.3651,  ...,   25.8911,   33.4690,\n",
      "             24.6281],\n",
      "          [  -4.2099,  -22.3127,  -16.8397,  ...,  -63.1490,  -22.7337,\n",
      "             11.1563],\n",
      "          [ -12.4193,  -22.5232,  -24.6281,  ...,  -46.0988,  -23.1546,\n",
      "              1.4735],\n",
      "          ...,\n",
      "          [   1.8945,   -7.1569,  -14.3138,  ...,   33.6795,   21.8917,\n",
      "             13.2613],\n",
      "          [ -14.5243,  -21.0497,  -21.4707,  ...,   36.8369,   20.6287,\n",
      "             12.4193],\n",
      "          [ -19.5762,  -27.7856,  -22.9441,  ...,   18.7342,   13.4718,\n",
      "              5.2624]],\n",
      "\n",
      "         [[ -33.4690,  -54.7292,  -45.0463,  ..., -137.4544,  -91.3556,\n",
      "            -36.8369],\n",
      "          [ -21.2602,  -80.1993,  -69.2534,  ..., -188.8156, -153.8731,\n",
      "            -64.8330],\n",
      "          [   4.4204,  -59.5706,  -49.2562,  ..., -149.0317, -137.0334,\n",
      "            -74.3054],\n",
      "          ...,\n",
      "          [  59.3601,  -48.6247,  -91.5661,  ..., -111.1423,  -45.0463,\n",
      "            -13.4718],\n",
      "          [  63.9910,  -25.2596,  -82.3042,  ...,  -72.4109,  -56.8341,\n",
      "            -28.4171],\n",
      "          [  45.2568,   -9.8933,  -52.6242,  ...,  -35.9949,  -41.2574,\n",
      "            -23.9966]]],\n",
      "\n",
      "\n",
      "        [[[ -32.2060,  -51.5717,  -35.3635,  ...,  -31.7850,  -35.5740,\n",
      "            -20.6287],\n",
      "          [ -35.9949,  -70.5164,  -46.7303,  ...,  -51.1507,  -56.2026,\n",
      "            -42.5203],\n",
      "          [ -22.9441,  -55.9921,  -30.5220,  ...,  -39.7839,  -46.0988,\n",
      "            -35.1530],\n",
      "          ...,\n",
      "          [ -10.7353,  -30.9430,  -24.2071,  ...,  -34.9425,  -22.3127,\n",
      "            -17.4712],\n",
      "          [ -11.9983,  -36.6264,  -31.7850,  ...,  -22.1022,  -23.3651,\n",
      "            -13.4718],\n",
      "          [   0.6315,  -17.2607,  -16.2083,  ...,   -7.3674,  -11.9983,\n",
      "             -7.7884]],\n",
      "\n",
      "         [[ -19.5762,    6.3149,  -10.5248,  ...,   -1.4735,   -5.0519,\n",
      "            -29.2590],\n",
      "          [ -23.9966,   -1.4735,  -19.5762,  ...,   -9.6828,   -8.4199,\n",
      "            -45.4673],\n",
      "          [ -21.2602,   -5.0519,  -15.7873,  ...,  -10.1038,   -2.9470,\n",
      "            -47.7828],\n",
      "          ...,\n",
      "          [  -6.5254,   -2.1050,   -5.0519,  ...,  -17.2607,  -14.1033,\n",
      "             -3.7889],\n",
      "          [ -11.1563,  -10.3143,  -12.8403,  ...,  -10.5248,   -8.6304,\n",
      "              2.1050],\n",
      "          [   3.3679,    1.2630,   -0.4210,  ...,    9.0514,    3.1575,\n",
      "             11.1563]],\n",
      "\n",
      "         [[  10.5248,   14.3138,    6.5254,  ...,   13.8928,   16.8397,\n",
      "             25.6806],\n",
      "          [   4.2099,    6.9464,   -3.3679,  ...,    8.8409,   11.3668,\n",
      "             24.2071],\n",
      "          [  16.2083,   15.9978,   14.1033,  ...,   21.4707,   24.2071,\n",
      "             30.7325],\n",
      "          ...,\n",
      "          [  19.5762,   27.3646,   22.7337,  ...,   21.2602,   27.7856,\n",
      "             39.5734],\n",
      "          [  12.2088,   17.0502,   14.7348,  ...,   18.7342,   14.7348,\n",
      "             30.5220],\n",
      "          [  16.4187,   27.3646,   26.1016,  ...,   12.8403,    4.8414,\n",
      "             20.8392]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -13.8928,  -35.7844,  -29.0486,  ...,  -44.8358,  -40.2049,\n",
      "            -23.1546],\n",
      "          [   2.9470,  -12.6298,   -5.8939,  ...,  -31.5745,  -25.6806,\n",
      "            -10.9458],\n",
      "          [  20.6287,    8.4199,   11.7878,  ...,  -15.5768,  -13.0508,\n",
      "             -1.0525],\n",
      "          ...,\n",
      "          [  -2.9470,  -11.7878,  -15.1558,  ...,    7.9989,    2.1050,\n",
      "             15.3663],\n",
      "          [  -8.6304,  -20.6287,  -23.7861,  ...,    1.0525,   -5.4729,\n",
      "              9.8933],\n",
      "          [   7.3674,   10.7353,    7.3674,  ...,   17.4712,   12.4193,\n",
      "             14.7348]],\n",
      "\n",
      "         [[  27.5751,   47.7828,   41.2574,  ...,   48.2038,   45.6778,\n",
      "             39.9944],\n",
      "          [  33.8900,   45.0463,   38.3104,  ...,   45.6778,   43.5728,\n",
      "             43.3623],\n",
      "          [  35.3635,   51.3612,   36.4159,  ...,   50.3087,   50.0982,\n",
      "             46.7303],\n",
      "          ...,\n",
      "          [  38.5209,   57.8866,   54.5187,  ...,   17.4712,   12.8403,\n",
      "              4.4204],\n",
      "          [  50.7297,   75.3578,   71.9899,  ...,   46.5198,   31.9955,\n",
      "             16.4187],\n",
      "          [  27.7856,   39.9944,   37.8894,  ...,   19.9972,   14.3138,\n",
      "              5.2624]],\n",
      "\n",
      "         [[ -26.1016,   -7.7884,  -16.8397,  ...,   -1.8945,   -8.4199,\n",
      "            -11.3668],\n",
      "          [ -35.5740,  -18.5237,  -25.0491,  ...,   -8.6304,  -10.5248,\n",
      "            -17.6817],\n",
      "          [ -35.1530,   -7.1569,   -7.9989,  ...,   -2.3155,   -4.8414,\n",
      "            -16.4187],\n",
      "          ...,\n",
      "          [ -23.1546,   -9.0514,   -5.0519,  ...,   -0.8420,   -1.8945,\n",
      "            -10.5248],\n",
      "          [ -26.3121,   -9.8933,   -9.4724,  ...,   -3.5784,   -1.0525,\n",
      "             -7.3674],\n",
      "          [ -25.0491,  -25.2596,  -23.3651,  ...,  -16.6292,  -11.5773,\n",
      "             -9.8933]]],\n",
      "\n",
      "\n",
      "        [[[   0.6315,   -4.4204,  -15.5768,  ...,    6.9464,   -1.0525,\n",
      "            -22.1022],\n",
      "          [ -10.3143,   -8.4199,   -8.8409,  ...,   16.8397,   26.9436,\n",
      "             -5.4729],\n",
      "          [ -12.4193,  -12.6298,  -18.1027,  ...,    7.1569,   29.6800,\n",
      "             -4.8414],\n",
      "          ...,\n",
      "          [   7.3674,  -23.5756,  -23.7861,  ...,   -9.0514,   16.4187,\n",
      "            -10.9458],\n",
      "          [  -0.2105,  -19.3657,  -11.7878,  ...,  -10.5248,   17.4712,\n",
      "              4.6309],\n",
      "          [   7.1569,   -9.8933,   -5.8939,  ...,  -36.2054,   -3.7889,\n",
      "             -1.6840]],\n",
      "\n",
      "         [[ -13.0508,  -41.8889,  -29.8905,  ...,  -28.8381,  -37.6789,\n",
      "            -17.2607],\n",
      "          [   7.5779,  -20.2077,    3.5784,  ...,   31.9955,   12.8403,\n",
      "             34.9425],\n",
      "          [  -6.5254,  -32.2060,  -17.8922,  ...,   10.9458,    0.6315,\n",
      "             29.0486],\n",
      "          ...,\n",
      "          [ -34.5215,  -48.6247,  -64.6225,  ...,   -3.5784,   -0.8420,\n",
      "             33.8900],\n",
      "          [ -21.2602,  -33.4690,  -38.7314,  ...,   20.4182,   13.4718,\n",
      "             41.2574],\n",
      "          [   0.2105,   -9.4724,  -17.2607,  ...,   31.1535,   20.2077,\n",
      "             44.6253]],\n",
      "\n",
      "         [[  20.8392,   53.8872,   39.1524,  ...,   79.5678,   77.0418,\n",
      "             87.5667],\n",
      "          [  21.2602,   59.9916,   42.0993,  ...,   86.3037,   66.3065,\n",
      "            105.4589],\n",
      "          [  22.7337,   61.8860,   47.9933,  ...,   79.5678,   81.8832,\n",
      "            118.5097],\n",
      "          ...,\n",
      "          [  38.3104,   62.3070,   61.6755,  ...,   99.3545,   89.0401,\n",
      "            116.8257],\n",
      "          [   9.2619,   27.3646,   41.0469,  ...,   93.4606,   85.2512,\n",
      "            112.6158],\n",
      "          [   7.1569,   20.2077,   24.4176,  ...,   24.4176,   15.7873,\n",
      "             59.3601]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -25.0491,   -2.5260,   -7.1569,  ...,   -5.8939,  -17.2607,\n",
      "             19.9972],\n",
      "          [ -20.8392,   16.6292,    7.9989,  ...,    1.2630,   -7.5779,\n",
      "             38.5209],\n",
      "          [ -24.6281,    5.6834,  -10.3143,  ...,  -34.7320,  -40.4154,\n",
      "             14.5243],\n",
      "          ...,\n",
      "          [  50.0982,   69.8849,   64.8330,  ...,   -3.3679,  -25.4701,\n",
      "             15.5768],\n",
      "          [  27.5751,   41.4679,   48.4143,  ...,  -43.9938,  -49.6772,\n",
      "              4.4204],\n",
      "          [  21.0497,   35.1530,   45.2568,  ...,  -28.8381,  -24.6281,\n",
      "             15.7873]],\n",
      "\n",
      "         [[  17.2607,   27.1541,   28.4171,  ...,   51.3612,   36.4159,\n",
      "             14.7348],\n",
      "          [  -3.5784,   12.2088,    9.0514,  ...,   34.9425,   17.8922,\n",
      "             17.8922],\n",
      "          [  -2.3155,   13.2613,   14.3138,  ...,   38.5209,   26.3121,\n",
      "              9.0514],\n",
      "          ...,\n",
      "          [  -7.1569,  -13.2613,   -9.0514,  ...,   19.5762,   25.6806,\n",
      "             11.3668],\n",
      "          [   8.8409,    7.5779,    1.4735,  ...,   70.9374,   58.3076,\n",
      "             30.5220],\n",
      "          [   5.2624,   -1.8945,  -13.8928,  ...,   32.6270,   21.6812,\n",
      "              7.7884]],\n",
      "\n",
      "         [[ -12.2088,  -26.3121,  -24.2071,  ...,  -38.9419,  -43.9938,\n",
      "            -67.7800],\n",
      "          [  -6.1044,  -31.1535,  -17.4712,  ...,  -18.9447,  -33.8900,\n",
      "            -60.6231],\n",
      "          [ -12.4193,  -40.8364,  -17.8922,  ...,  -11.9983,  -22.1022,\n",
      "            -57.2551],\n",
      "          ...,\n",
      "          [  15.9978,  -24.6281,  -38.3104,  ...,  -57.4656,  -49.2562,\n",
      "            -57.6761],\n",
      "          [  22.1022,    9.0514,  -11.9983,  ...,  -48.6247,  -46.3093,\n",
      "            -55.1502],\n",
      "          [   3.7889,   -6.9464,   -8.2094,  ...,  -48.4143,  -43.3623,\n",
      "            -46.3093]]]], device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## This cell is provided\n",
    "\n",
    "conv_int = torch.nn.Conv2d(in_channels = 64, out_channels=64, kernel_size = 3, padding=1)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "conv_int.bias = model.features[3].bias\n",
    "output_int = conv_int(act_int)\n",
    "output_recovered = output_int * (act_alpha / (2**act_bit-1)) * (w_alpha / (2**(w_bit-1)-1))\n",
    "print(output_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1978, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## This cell is provided\n",
    "\n",
    "conv_ref = torch.nn.Conv2d(in_channels = 64, out_channels=64, kernel_size = 3, padding=1)\n",
    "conv_ref.weight = model.features[3].weight_q\n",
    "conv_ref.bias = model.features[3].bias\n",
    "output_ref = conv_ref(act)\n",
    "#print(output_ref)\n",
    "\n",
    "print(abs((output_ref - output_recovered)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# act_int.size = torch.Size([128, 64, 32, 32])  <- batch_size, input_ch, ni, nj\n",
    "a_int = act_int[0,:,:,:]  # pick only one input out of batch\n",
    "# a_int.size() = [64, 32, 32]\n",
    "\n",
    "# conv_int.weight.size() = torch.Size([64, 64, 3, 3])  <- output_ch, input_ch, ki, kj\n",
    "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))  # merge ki, kj index to kij\n",
    "# w_int.weight.size() = torch.Size([64, 64, 9])\n",
    "                      \n",
    "padding = 1\n",
    "stride = 1\n",
    "array_size = 8 # row and column number\n",
    "\n",
    "nig = range(a_int.size(1))  ## ni group\n",
    "njg = range(a_int.size(2))  ## nj group\n",
    "\n",
    "icg = range(int(w_int.size(1)))  ## input channel \n",
    "ocg = range(int(w_int.size(0)))  ## output channel\n",
    "\n",
    "ic_tileg = range(int(len(icg)/array_size))\n",
    "oc_tileg = range(int(len(ocg)/array_size))\n",
    "\n",
    "kijg = range(w_int.size(2))\n",
    "ki_dim = int(math.sqrt(w_int.size(2)))  ## Kernel's 1 dim size\n",
    "\n",
    "######## Padding before Convolution #######\n",
    "a_pad = torch.zeros(len(icg), len(nig)+padding*2, len(nig)+padding*2).cuda()\n",
    "# a_pad.size() = [64, 32+2pad, 32+2pad]\n",
    "a_pad[ :, padding:padding+len(nig), padding:padding+len(njg)] = a_int.cuda()\n",
    "a_pad = torch.reshape(a_pad, (a_pad.size(0), -1))\n",
    "# a_pad.size() = [64, (32+2pad)*(32+2pad)]\n",
    "\n",
    "\n",
    "a_tile = torch.zeros(len(ic_tileg), array_size,    a_pad.size(1)).cuda() \n",
    "w_tile = torch.zeros(len(oc_tileg)*len(ic_tileg), array_size, array_size, len(kijg)).cuda() \n",
    "\n",
    "for ic_tile in ic_tileg:\n",
    "    a_tile[ic_tile,:,:] = a_pad[ic_tile*array_size:(ic_tile+1)*array_size,:]\n",
    "\n",
    "for ic_tile in ic_tileg:\n",
    "    for oc_tile in oc_tileg:\n",
    "        w_tile[oc_tile*len(oc_tileg) + ic_tile,:,:,:] = w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, :]\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "p_nijg = range(a_pad.size(1)) ## psum nij group\n",
    "\n",
    "psum = torch.zeros(len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)).cuda() \n",
    "\n",
    "for kij in kijg:\n",
    "    for ic_tile in ic_tileg:       # Tiling into array_sizeXarray_size array\n",
    "        for oc_tile in oc_tileg:   # Tiling into array_sizeXarray_size array        \n",
    "            for nij in p_nijg:       # time domain, sequentially given input\n",
    "                    m = nn.Linear(array_size, array_size, bias=False)\n",
    "                    #m.weight = torch.nn.Parameter(w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, kij])\n",
    "                    m.weight = torch.nn.Parameter(w_tile[len(oc_tileg)*oc_tile+ic_tile,:,:,kij])\n",
    "                    psum[ic_tile, oc_tile, :, nij, kij] = m(a_tile[ic_tile,:,nij]).cuda()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "a_pad_ni_dim = int(math.sqrt(a_pad.size(1))) # 32\n",
    "\n",
    "o_ni_dim = int((a_pad_ni_dim - (ki_dim- 1) - 1)/stride + 1)\n",
    "o_nijg = range(o_ni_dim**2)    \n",
    "    \n",
    "out = torch.zeros(len(ocg), len(o_nijg)).cuda()\n",
    "  \n",
    "   \n",
    "### SFP accumulation ###\n",
    "for o_nij in o_nijg: \n",
    "    for kij in kijg:\n",
    "        for ic_tile in ic_tileg:    \n",
    "            for oc_tile in oc_tileg:   \n",
    "                out[oc_tile*array_size:(oc_tile+1)*array_size, o_nij] = out[oc_tile*array_size:(oc_tile+1)*array_size, o_nij] + \\\n",
    "                psum[ic_tile, oc_tile, :, int(o_nij/o_ni_dim)*a_pad_ni_dim + o_nij%o_ni_dim + int(kij/ki_dim)*a_pad_ni_dim + kij%ki_dim, kij]\n",
    "                ## 4th index = (int(o_nij/30)*32 + o_nij%30) + (int(kij/3)*32 + kij%3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0137, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_2D = torch.reshape(out, (out.size(0), o_ni_dim, -1))\n",
    "difference = (out_2D - output_int[0,:,:,:])\n",
    "print(difference.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "### show this cell partially. The following cells should be printed by students ###\n",
    "tile_id = 0 \n",
    "nij = 200 # just a random number\n",
    "X = a_tile[tile_id,:,nij:nij+64]  # [tile_num, array row num, time_steps]\n",
    "\n",
    "bit_precision = 4\n",
    "file = open('activation.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:04b}'.format(int(X[7-j,i].item()+0.001))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-projector",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 1., 1., 0., 0., 3.], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,0] # check this number with your first line in activation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete this cell ###\n",
    "tile_id = 0 \n",
    "kij = 0\n",
    "W = w_tile[tile_id,:,:,kij]  # w_tile[tile_num, array col num, array row num, kij]\n",
    "\n",
    "\n",
    "bit_precision = 4\n",
    "file = open('weight.txt', 'w') #write to file\n",
    "file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(W.size(0)):  # col# \n",
    "    for j in range(W.size(1)): # row#\n",
    "        if W[i,7-j] >= 0 : \n",
    "            W_bin = '{0:04b}'.format(int(W[i,7-j].item()+0.001))\n",
    "        else : \n",
    "            W_bin = '{0:04b}'.format(int(W[i,7-j].item()+15.99))\n",
    "        \n",
    "        for k in range(bit_precision):\n",
    "            file.write(W_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-panel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.0000, -1.0000, -0.0000, -1.0000, -2.0000, -3.0000,  1.0000,  1.0000],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0,:] # check this number with your 2nd line in weight.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete this cell ###\n",
    "ic_tile_id = 0 \n",
    "oc_tile_id = 0 \n",
    "\n",
    "\n",
    "kij = 0\n",
    "nij = 200\n",
    "psum_tile = psum[ic_tile_id,oc_tile_id,:,nij:nij+64,kij]  \n",
    "# psum[len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)]\n",
    "\n",
    "\n",
    "bit_precision = 16\n",
    "file = open('out.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(psum_tile.size(1)):  # time step\n",
    "    for j in range(psum_tile.size(0)): # col #\n",
    "        if psum_tile[7-j,i] >= 0 : \n",
    "            p_bin = format(int(psum_tile[7-j,i].item()+0.001), '016b')\n",
    "        else : \n",
    "            p_bin = '{0:16b}'.format(int(psum_tile[7-j,i].item()+2**16))\n",
    "        \n",
    "            \n",
    "        for k in range(bit_precision):\n",
    "            file.write(p_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\"acc_address.txt\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "19a5962e6d84800114f5be1990aedf0d767e540ecded1626ca5d3360899d2fff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
