{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "ResNet_Cifar(\n",
      "  (conv1): QuantConv2d(\n",
      "    3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "    (weight_quant): weight_quantize_fn()\n",
      "  )\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          8, 32, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "     \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"resnet20_cifar_project\"\n",
    "model = resnet20_quant()\n",
    "\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        #loss1 = criterion(output, target)\n",
    "        #loss2 = model.conv1.weight.abs().sum() + model.conv2.weight.abs().sum()\n",
    "        #loss = loss1\n",
    "        #loss = loss1 + 0.05*loss2\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "junior-reminder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.280 (0.280)\tData 0.233 (0.233)\tLoss 0.1761 (0.1761)\tPrec 94.531% (94.531%)\n",
      "Epoch: [0][100/391]\tTime 0.058 (0.050)\tData 0.002 (0.004)\tLoss 0.2710 (0.2781)\tPrec 89.844% (90.091%)\n",
      "Epoch: [0][200/391]\tTime 0.041 (0.047)\tData 0.001 (0.003)\tLoss 0.2797 (0.2787)\tPrec 88.281% (90.306%)\n",
      "Epoch: [0][300/391]\tTime 0.072 (0.049)\tData 0.002 (0.003)\tLoss 0.1764 (0.2740)\tPrec 95.312% (90.555%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 0.2695 (0.2695)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.230% \n",
      "best acc: 87.230000\n",
      "Epoch: [1][0/391]\tTime 0.289 (0.289)\tData 0.232 (0.232)\tLoss 0.1209 (0.1209)\tPrec 98.438% (98.438%)\n",
      "Epoch: [1][100/391]\tTime 0.049 (0.058)\tData 0.002 (0.004)\tLoss 0.3106 (0.2615)\tPrec 87.500% (90.896%)\n",
      "Epoch: [1][200/391]\tTime 0.049 (0.056)\tData 0.002 (0.003)\tLoss 0.1471 (0.2564)\tPrec 94.531% (91.088%)\n",
      "Epoch: [1][300/391]\tTime 0.054 (0.055)\tData 0.002 (0.003)\tLoss 0.1994 (0.2545)\tPrec 92.969% (91.157%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.2277 (0.2277)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.610% \n",
      "best acc: 87.610000\n",
      "Epoch: [2][0/391]\tTime 0.302 (0.302)\tData 0.246 (0.246)\tLoss 0.2747 (0.2747)\tPrec 90.625% (90.625%)\n",
      "Epoch: [2][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.005)\tLoss 0.2876 (0.2461)\tPrec 90.625% (91.352%)\n",
      "Epoch: [2][200/391]\tTime 0.051 (0.054)\tData 0.002 (0.003)\tLoss 0.2446 (0.2423)\tPrec 90.625% (91.472%)\n",
      "Epoch: [2][300/391]\tTime 0.045 (0.051)\tData 0.002 (0.003)\tLoss 0.1777 (0.2442)\tPrec 92.188% (91.398%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 0.2683 (0.2683)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.400% \n",
      "best acc: 87.610000\n",
      "Epoch: [3][0/391]\tTime 0.265 (0.265)\tData 0.199 (0.199)\tLoss 0.1611 (0.1611)\tPrec 93.750% (93.750%)\n",
      "Epoch: [3][100/391]\tTime 0.037 (0.054)\tData 0.002 (0.004)\tLoss 0.2887 (0.2406)\tPrec 89.062% (91.793%)\n",
      "Epoch: [3][200/391]\tTime 0.058 (0.047)\tData 0.002 (0.003)\tLoss 0.2422 (0.2443)\tPrec 93.750% (91.616%)\n",
      "Epoch: [3][300/391]\tTime 0.044 (0.048)\tData 0.002 (0.003)\tLoss 0.1728 (0.2439)\tPrec 92.969% (91.593%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.2344 (0.2344)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.870% \n",
      "best acc: 87.870000\n",
      "Epoch: [4][0/391]\tTime 0.275 (0.275)\tData 0.217 (0.217)\tLoss 0.3275 (0.3275)\tPrec 90.625% (90.625%)\n",
      "Epoch: [4][100/391]\tTime 0.052 (0.052)\tData 0.002 (0.004)\tLoss 0.2166 (0.2384)\tPrec 92.188% (91.669%)\n",
      "Epoch: [4][200/391]\tTime 0.038 (0.048)\tData 0.002 (0.003)\tLoss 0.1861 (0.2342)\tPrec 92.188% (91.884%)\n",
      "Epoch: [4][300/391]\tTime 0.040 (0.046)\tData 0.002 (0.003)\tLoss 0.1689 (0.2369)\tPrec 94.531% (91.783%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.246 (0.246)\tLoss 0.2552 (0.2552)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.600% \n",
      "best acc: 87.870000\n",
      "Epoch: [5][0/391]\tTime 0.253 (0.253)\tData 0.189 (0.189)\tLoss 0.2612 (0.2612)\tPrec 92.188% (92.188%)\n",
      "Epoch: [5][100/391]\tTime 0.035 (0.045)\tData 0.001 (0.004)\tLoss 0.2361 (0.2254)\tPrec 91.406% (92.010%)\n",
      "Epoch: [5][200/391]\tTime 0.042 (0.042)\tData 0.002 (0.003)\tLoss 0.2022 (0.2282)\tPrec 94.531% (91.974%)\n",
      "Epoch: [5][300/391]\tTime 0.044 (0.042)\tData 0.002 (0.002)\tLoss 0.2620 (0.2296)\tPrec 88.281% (91.933%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.232 (0.232)\tLoss 0.2208 (0.2208)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.400% \n",
      "best acc: 87.870000\n",
      "Epoch: [6][0/391]\tTime 0.269 (0.269)\tData 0.214 (0.214)\tLoss 0.3223 (0.3223)\tPrec 86.719% (86.719%)\n",
      "Epoch: [6][100/391]\tTime 0.043 (0.048)\tData 0.002 (0.004)\tLoss 0.1964 (0.2270)\tPrec 92.188% (92.327%)\n",
      "Epoch: [6][200/391]\tTime 0.043 (0.047)\tData 0.002 (0.003)\tLoss 0.2677 (0.2244)\tPrec 90.625% (92.254%)\n",
      "Epoch: [6][300/391]\tTime 0.040 (0.047)\tData 0.002 (0.003)\tLoss 0.2359 (0.2286)\tPrec 91.406% (92.112%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 0.2203 (0.2203)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.480% \n",
      "best acc: 87.870000\n",
      "Epoch: [7][0/391]\tTime 0.306 (0.306)\tData 0.245 (0.245)\tLoss 0.3587 (0.3587)\tPrec 90.625% (90.625%)\n",
      "Epoch: [7][100/391]\tTime 0.037 (0.043)\tData 0.001 (0.004)\tLoss 0.2430 (0.2245)\tPrec 89.844% (92.218%)\n",
      "Epoch: [7][200/391]\tTime 0.045 (0.044)\tData 0.002 (0.003)\tLoss 0.3113 (0.2227)\tPrec 87.500% (92.222%)\n",
      "Epoch: [7][300/391]\tTime 0.052 (0.044)\tData 0.002 (0.002)\tLoss 0.2072 (0.2244)\tPrec 93.750% (92.169%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.2491 (0.2491)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.890% \n",
      "best acc: 87.890000\n",
      "Epoch: [8][0/391]\tTime 0.351 (0.351)\tData 0.284 (0.284)\tLoss 0.1568 (0.1568)\tPrec 94.531% (94.531%)\n",
      "Epoch: [8][100/391]\tTime 0.040 (0.053)\tData 0.002 (0.005)\tLoss 0.1920 (0.2194)\tPrec 92.969% (92.373%)\n",
      "Epoch: [8][200/391]\tTime 0.050 (0.052)\tData 0.002 (0.003)\tLoss 0.2187 (0.2245)\tPrec 92.188% (92.079%)\n",
      "Epoch: [8][300/391]\tTime 0.039 (0.049)\tData 0.001 (0.003)\tLoss 0.1420 (0.2234)\tPrec 96.094% (92.167%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.2576 (0.2576)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.700% \n",
      "best acc: 87.890000\n",
      "Epoch: [9][0/391]\tTime 0.280 (0.280)\tData 0.226 (0.226)\tLoss 0.2139 (0.2139)\tPrec 92.969% (92.969%)\n",
      "Epoch: [9][100/391]\tTime 0.039 (0.051)\tData 0.002 (0.004)\tLoss 0.2306 (0.2128)\tPrec 92.969% (92.497%)\n",
      "Epoch: [9][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.003)\tLoss 0.2231 (0.2136)\tPrec 92.969% (92.487%)\n",
      "Epoch: [9][300/391]\tTime 0.048 (0.048)\tData 0.002 (0.003)\tLoss 0.1947 (0.2192)\tPrec 92.969% (92.377%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.245 (0.245)\tLoss 0.2393 (0.2393)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.980% \n",
      "best acc: 87.980000\n",
      "Epoch: [10][0/391]\tTime 0.294 (0.294)\tData 0.237 (0.237)\tLoss 0.1571 (0.1571)\tPrec 95.312% (95.312%)\n",
      "Epoch: [10][100/391]\tTime 0.038 (0.050)\tData 0.001 (0.004)\tLoss 0.2765 (0.2155)\tPrec 90.625% (92.079%)\n",
      "Epoch: [10][200/391]\tTime 0.047 (0.050)\tData 0.002 (0.003)\tLoss 0.2289 (0.2170)\tPrec 92.188% (92.211%)\n",
      "Epoch: [10][300/391]\tTime 0.058 (0.049)\tData 0.002 (0.003)\tLoss 0.3078 (0.2172)\tPrec 92.188% (92.271%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.2274 (0.2274)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.620% \n",
      "best acc: 87.980000\n",
      "Epoch: [11][0/391]\tTime 0.316 (0.316)\tData 0.256 (0.256)\tLoss 0.1820 (0.1820)\tPrec 93.750% (93.750%)\n",
      "Epoch: [11][100/391]\tTime 0.039 (0.053)\tData 0.002 (0.005)\tLoss 0.1733 (0.2062)\tPrec 93.750% (92.853%)\n",
      "Epoch: [11][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.003)\tLoss 0.1621 (0.2117)\tPrec 94.531% (92.572%)\n",
      "Epoch: [11][300/391]\tTime 0.048 (0.048)\tData 0.002 (0.003)\tLoss 0.2253 (0.2146)\tPrec 94.531% (92.447%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.2358 (0.2358)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.870% \n",
      "best acc: 87.980000\n",
      "Epoch: [12][0/391]\tTime 0.273 (0.273)\tData 0.212 (0.212)\tLoss 0.2175 (0.2175)\tPrec 92.969% (92.969%)\n",
      "Epoch: [12][100/391]\tTime 0.062 (0.051)\tData 0.003 (0.004)\tLoss 0.2359 (0.2102)\tPrec 90.625% (92.698%)\n",
      "Epoch: [12][200/391]\tTime 0.041 (0.049)\tData 0.001 (0.003)\tLoss 0.1560 (0.2135)\tPrec 96.094% (92.584%)\n",
      "Epoch: [12][300/391]\tTime 0.040 (0.047)\tData 0.002 (0.003)\tLoss 0.2819 (0.2123)\tPrec 89.844% (92.592%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 0.2491 (0.2491)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.820% \n",
      "best acc: 87.980000\n",
      "Epoch: [13][0/391]\tTime 0.270 (0.270)\tData 0.205 (0.205)\tLoss 0.2992 (0.2992)\tPrec 89.844% (89.844%)\n",
      "Epoch: [13][100/391]\tTime 0.048 (0.051)\tData 0.002 (0.004)\tLoss 0.2144 (0.2142)\tPrec 94.531% (92.659%)\n",
      "Epoch: [13][200/391]\tTime 0.057 (0.049)\tData 0.002 (0.003)\tLoss 0.2086 (0.2131)\tPrec 92.188% (92.654%)\n",
      "Epoch: [13][300/391]\tTime 0.040 (0.050)\tData 0.002 (0.003)\tLoss 0.2299 (0.2151)\tPrec 92.188% (92.616%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 0.2302 (0.2302)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.820% \n",
      "best acc: 87.980000\n",
      "Epoch: [14][0/391]\tTime 0.253 (0.253)\tData 0.204 (0.204)\tLoss 0.2231 (0.2231)\tPrec 92.969% (92.969%)\n",
      "Epoch: [14][100/391]\tTime 0.040 (0.047)\tData 0.002 (0.004)\tLoss 0.2842 (0.2172)\tPrec 92.969% (92.435%)\n",
      "Epoch: [14][200/391]\tTime 0.049 (0.045)\tData 0.003 (0.003)\tLoss 0.1334 (0.2144)\tPrec 95.312% (92.491%)\n",
      "Epoch: [14][300/391]\tTime 0.042 (0.046)\tData 0.002 (0.002)\tLoss 0.2024 (0.2126)\tPrec 92.188% (92.548%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.2214 (0.2214)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.140% \n",
      "best acc: 88.140000\n",
      "Epoch: [15][0/391]\tTime 0.278 (0.278)\tData 0.215 (0.215)\tLoss 0.1920 (0.1920)\tPrec 94.531% (94.531%)\n",
      "Epoch: [15][100/391]\tTime 0.051 (0.056)\tData 0.002 (0.004)\tLoss 0.1767 (0.2192)\tPrec 92.969% (92.296%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/391]\tTime 0.062 (0.052)\tData 0.002 (0.003)\tLoss 0.1826 (0.2130)\tPrec 92.969% (92.572%)\n",
      "Epoch: [15][300/391]\tTime 0.046 (0.050)\tData 0.002 (0.003)\tLoss 0.1954 (0.2111)\tPrec 91.406% (92.595%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.2667 (0.2667)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.770% \n",
      "best acc: 88.140000\n",
      "Epoch: [16][0/391]\tTime 0.263 (0.263)\tData 0.209 (0.209)\tLoss 0.2802 (0.2802)\tPrec 89.844% (89.844%)\n",
      "Epoch: [16][100/391]\tTime 0.058 (0.045)\tData 0.002 (0.004)\tLoss 0.2250 (0.2007)\tPrec 92.188% (92.961%)\n",
      "Epoch: [16][200/391]\tTime 0.048 (0.049)\tData 0.002 (0.003)\tLoss 0.1411 (0.2063)\tPrec 96.094% (92.759%)\n",
      "Epoch: [16][300/391]\tTime 0.038 (0.047)\tData 0.002 (0.003)\tLoss 0.2132 (0.2106)\tPrec 92.969% (92.618%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.227 (0.227)\tLoss 0.2306 (0.2306)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.670% \n",
      "best acc: 88.140000\n",
      "Epoch: [17][0/391]\tTime 0.270 (0.270)\tData 0.215 (0.215)\tLoss 0.2719 (0.2719)\tPrec 89.844% (89.844%)\n",
      "Epoch: [17][100/391]\tTime 0.044 (0.055)\tData 0.002 (0.004)\tLoss 0.1868 (0.2060)\tPrec 92.969% (92.713%)\n",
      "Epoch: [17][200/391]\tTime 0.036 (0.048)\tData 0.002 (0.003)\tLoss 0.1350 (0.2040)\tPrec 96.094% (92.747%)\n",
      "Epoch: [17][300/391]\tTime 0.042 (0.049)\tData 0.002 (0.003)\tLoss 0.1508 (0.2053)\tPrec 93.750% (92.686%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.227 (0.227)\tLoss 0.2906 (0.2906)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.670% \n",
      "best acc: 88.140000\n",
      "Epoch: [18][0/391]\tTime 0.293 (0.293)\tData 0.229 (0.229)\tLoss 0.1497 (0.1497)\tPrec 92.969% (92.969%)\n",
      "Epoch: [18][100/391]\tTime 0.043 (0.049)\tData 0.001 (0.004)\tLoss 0.2484 (0.2131)\tPrec 89.844% (92.381%)\n",
      "Epoch: [18][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.003)\tLoss 0.2163 (0.2089)\tPrec 93.750% (92.642%)\n",
      "Epoch: [18][300/391]\tTime 0.050 (0.047)\tData 0.002 (0.003)\tLoss 0.3785 (0.2091)\tPrec 87.500% (92.637%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.2286 (0.2286)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.010% \n",
      "best acc: 88.140000\n",
      "Epoch: [19][0/391]\tTime 0.270 (0.270)\tData 0.213 (0.213)\tLoss 0.2175 (0.2175)\tPrec 91.406% (91.406%)\n",
      "Epoch: [19][100/391]\tTime 0.063 (0.047)\tData 0.002 (0.004)\tLoss 0.1539 (0.2046)\tPrec 95.312% (92.922%)\n",
      "Epoch: [19][200/391]\tTime 0.040 (0.046)\tData 0.001 (0.003)\tLoss 0.1029 (0.1993)\tPrec 96.875% (93.015%)\n",
      "Epoch: [19][300/391]\tTime 0.036 (0.043)\tData 0.001 (0.002)\tLoss 0.1933 (0.2011)\tPrec 93.750% (92.948%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.195 (0.195)\tLoss 0.2141 (0.2141)\tPrec 93.750% (93.750%)\n",
      " * Prec 87.660% \n",
      "best acc: 88.140000\n",
      "Epoch: [20][0/391]\tTime 0.242 (0.242)\tData 0.200 (0.200)\tLoss 0.1991 (0.1991)\tPrec 92.969% (92.969%)\n",
      "Epoch: [20][100/391]\tTime 0.039 (0.043)\tData 0.001 (0.004)\tLoss 0.1810 (0.1953)\tPrec 92.969% (93.185%)\n",
      "Epoch: [20][200/391]\tTime 0.038 (0.043)\tData 0.002 (0.003)\tLoss 0.1918 (0.2017)\tPrec 92.969% (92.774%)\n",
      "Epoch: [20][300/391]\tTime 0.038 (0.041)\tData 0.001 (0.002)\tLoss 0.3730 (0.2015)\tPrec 88.281% (92.738%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.2311 (0.2311)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.000% \n",
      "best acc: 88.140000\n",
      "Epoch: [21][0/391]\tTime 0.271 (0.271)\tData 0.226 (0.226)\tLoss 0.2039 (0.2039)\tPrec 92.188% (92.188%)\n",
      "Epoch: [21][100/391]\tTime 0.063 (0.043)\tData 0.003 (0.004)\tLoss 0.0949 (0.1898)\tPrec 96.875% (93.232%)\n",
      "Epoch: [21][200/391]\tTime 0.037 (0.046)\tData 0.002 (0.003)\tLoss 0.2278 (0.1949)\tPrec 91.406% (93.105%)\n",
      "Epoch: [21][300/391]\tTime 0.066 (0.047)\tData 0.002 (0.003)\tLoss 0.2169 (0.1996)\tPrec 92.188% (92.878%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 0.2950 (0.2950)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.360% \n",
      "best acc: 88.140000\n",
      "Epoch: [22][0/391]\tTime 0.272 (0.272)\tData 0.211 (0.211)\tLoss 0.2056 (0.2056)\tPrec 92.969% (92.969%)\n",
      "Epoch: [22][100/391]\tTime 0.039 (0.051)\tData 0.002 (0.004)\tLoss 0.2681 (0.2038)\tPrec 89.844% (92.698%)\n",
      "Epoch: [22][200/391]\tTime 0.063 (0.050)\tData 0.003 (0.003)\tLoss 0.1785 (0.2007)\tPrec 92.969% (92.895%)\n",
      "Epoch: [22][300/391]\tTime 0.058 (0.049)\tData 0.003 (0.003)\tLoss 0.2010 (0.1986)\tPrec 94.531% (92.992%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.2719 (0.2719)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.740% \n",
      "best acc: 88.140000\n",
      "Epoch: [23][0/391]\tTime 0.331 (0.331)\tData 0.268 (0.268)\tLoss 0.2049 (0.2049)\tPrec 94.531% (94.531%)\n",
      "Epoch: [23][100/391]\tTime 0.048 (0.052)\tData 0.002 (0.005)\tLoss 0.2079 (0.1884)\tPrec 92.969% (93.557%)\n",
      "Epoch: [23][200/391]\tTime 0.043 (0.050)\tData 0.001 (0.003)\tLoss 0.2381 (0.1893)\tPrec 94.531% (93.439%)\n",
      "Epoch: [23][300/391]\tTime 0.040 (0.049)\tData 0.002 (0.003)\tLoss 0.1387 (0.1948)\tPrec 93.750% (93.270%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.2581 (0.2581)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.670% \n",
      "best acc: 88.140000\n",
      "Epoch: [24][0/391]\tTime 0.241 (0.241)\tData 0.193 (0.193)\tLoss 0.2112 (0.2112)\tPrec 94.531% (94.531%)\n",
      "Epoch: [24][100/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.1795 (0.1883)\tPrec 95.312% (93.472%)\n",
      "Epoch: [24][200/391]\tTime 0.048 (0.046)\tData 0.002 (0.003)\tLoss 0.1680 (0.1938)\tPrec 94.531% (93.287%)\n",
      "Epoch: [24][300/391]\tTime 0.048 (0.046)\tData 0.002 (0.002)\tLoss 0.1706 (0.1937)\tPrec 93.750% (93.239%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.2706 (0.2706)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.680% \n",
      "best acc: 88.140000\n",
      "Epoch: [25][0/391]\tTime 0.274 (0.274)\tData 0.229 (0.229)\tLoss 0.1240 (0.1240)\tPrec 96.875% (96.875%)\n",
      "Epoch: [25][100/391]\tTime 0.045 (0.054)\tData 0.002 (0.004)\tLoss 0.1554 (0.1896)\tPrec 93.750% (93.425%)\n",
      "Epoch: [25][200/391]\tTime 0.039 (0.048)\tData 0.001 (0.003)\tLoss 0.1766 (0.1874)\tPrec 94.531% (93.466%)\n",
      "Epoch: [25][300/391]\tTime 0.042 (0.048)\tData 0.002 (0.003)\tLoss 0.1287 (0.1958)\tPrec 94.531% (93.195%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.2682 (0.2682)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.480% \n",
      "best acc: 88.140000\n",
      "Epoch: [26][0/391]\tTime 0.281 (0.281)\tData 0.225 (0.225)\tLoss 0.1622 (0.1622)\tPrec 96.094% (96.094%)\n",
      "Epoch: [26][100/391]\tTime 0.039 (0.053)\tData 0.002 (0.004)\tLoss 0.1982 (0.1855)\tPrec 93.750% (93.758%)\n",
      "Epoch: [26][200/391]\tTime 0.038 (0.047)\tData 0.002 (0.003)\tLoss 0.1945 (0.1890)\tPrec 92.188% (93.571%)\n",
      "Epoch: [26][300/391]\tTime 0.038 (0.046)\tData 0.002 (0.003)\tLoss 0.2013 (0.1912)\tPrec 92.969% (93.433%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.1548 (0.1548)\tPrec 93.750% (93.750%)\n",
      " * Prec 87.870% \n",
      "best acc: 88.140000\n",
      "Epoch: [27][0/391]\tTime 0.277 (0.277)\tData 0.229 (0.229)\tLoss 0.1409 (0.1409)\tPrec 96.094% (96.094%)\n",
      "Epoch: [27][100/391]\tTime 0.041 (0.051)\tData 0.002 (0.004)\tLoss 0.2090 (0.1865)\tPrec 90.625% (93.479%)\n",
      "Epoch: [27][200/391]\tTime 0.037 (0.048)\tData 0.002 (0.003)\tLoss 0.1570 (0.1904)\tPrec 95.312% (93.221%)\n",
      "Epoch: [27][300/391]\tTime 0.038 (0.047)\tData 0.002 (0.003)\tLoss 0.2722 (0.1905)\tPrec 90.625% (93.252%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.2064 (0.2064)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.790% \n",
      "best acc: 88.140000\n",
      "Epoch: [28][0/391]\tTime 0.312 (0.312)\tData 0.253 (0.253)\tLoss 0.1444 (0.1444)\tPrec 95.312% (95.312%)\n",
      "Epoch: [28][100/391]\tTime 0.059 (0.051)\tData 0.002 (0.004)\tLoss 0.2089 (0.1833)\tPrec 93.750% (93.711%)\n",
      "Epoch: [28][200/391]\tTime 0.057 (0.050)\tData 0.002 (0.003)\tLoss 0.1704 (0.1853)\tPrec 94.531% (93.486%)\n",
      "Epoch: [28][300/391]\tTime 0.051 (0.050)\tData 0.002 (0.003)\tLoss 0.1164 (0.1889)\tPrec 96.094% (93.397%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 0.2175 (0.2175)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.770% \n",
      "best acc: 88.140000\n",
      "Epoch: [29][0/391]\tTime 0.284 (0.284)\tData 0.220 (0.220)\tLoss 0.2031 (0.2031)\tPrec 93.750% (93.750%)\n",
      "Epoch: [29][100/391]\tTime 0.058 (0.051)\tData 0.002 (0.004)\tLoss 0.1463 (0.1860)\tPrec 96.094% (93.363%)\n",
      "Epoch: [29][200/391]\tTime 0.047 (0.047)\tData 0.002 (0.003)\tLoss 0.1767 (0.1905)\tPrec 94.531% (93.299%)\n",
      "Epoch: [29][300/391]\tTime 0.042 (0.048)\tData 0.002 (0.003)\tLoss 0.2247 (0.1903)\tPrec 92.969% (93.355%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.2625 (0.2625)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.920% \n",
      "best acc: 88.140000\n",
      "Epoch: [30][0/391]\tTime 0.287 (0.287)\tData 0.232 (0.232)\tLoss 0.1611 (0.1611)\tPrec 92.969% (92.969%)\n",
      "Epoch: [30][100/391]\tTime 0.045 (0.049)\tData 0.002 (0.004)\tLoss 0.1857 (0.1949)\tPrec 95.312% (93.139%)\n",
      "Epoch: [30][200/391]\tTime 0.037 (0.048)\tData 0.002 (0.003)\tLoss 0.1969 (0.1958)\tPrec 92.969% (93.132%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][300/391]\tTime 0.062 (0.047)\tData 0.003 (0.003)\tLoss 0.1934 (0.1933)\tPrec 92.188% (93.210%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 0.2405 (0.2405)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.420% \n",
      "best acc: 88.140000\n",
      "Epoch: [31][0/391]\tTime 0.247 (0.247)\tData 0.196 (0.196)\tLoss 0.2037 (0.2037)\tPrec 94.531% (94.531%)\n",
      "Epoch: [31][100/391]\tTime 0.053 (0.053)\tData 0.002 (0.004)\tLoss 0.2548 (0.1911)\tPrec 91.406% (93.386%)\n",
      "Epoch: [31][200/391]\tTime 0.044 (0.051)\tData 0.002 (0.003)\tLoss 0.1844 (0.1874)\tPrec 92.969% (93.385%)\n",
      "Epoch: [31][300/391]\tTime 0.043 (0.050)\tData 0.002 (0.003)\tLoss 0.2192 (0.1903)\tPrec 92.188% (93.246%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.249 (0.249)\tLoss 0.2677 (0.2677)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.450% \n",
      "best acc: 88.140000\n",
      "Epoch: [32][0/391]\tTime 0.284 (0.284)\tData 0.226 (0.226)\tLoss 0.1861 (0.1861)\tPrec 92.969% (92.969%)\n",
      "Epoch: [32][100/391]\tTime 0.060 (0.055)\tData 0.002 (0.004)\tLoss 0.1587 (0.1788)\tPrec 96.094% (93.580%)\n",
      "Epoch: [32][200/391]\tTime 0.041 (0.051)\tData 0.002 (0.003)\tLoss 0.1706 (0.1831)\tPrec 93.750% (93.420%)\n",
      "Epoch: [32][300/391]\tTime 0.041 (0.048)\tData 0.002 (0.003)\tLoss 0.2075 (0.1850)\tPrec 91.406% (93.449%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.2367 (0.2367)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.820% \n",
      "best acc: 88.140000\n",
      "Epoch: [33][0/391]\tTime 0.298 (0.298)\tData 0.242 (0.242)\tLoss 0.1653 (0.1653)\tPrec 94.531% (94.531%)\n",
      "Epoch: [33][100/391]\tTime 0.046 (0.049)\tData 0.002 (0.004)\tLoss 0.1698 (0.1757)\tPrec 92.188% (93.943%)\n",
      "Epoch: [33][200/391]\tTime 0.041 (0.048)\tData 0.002 (0.003)\tLoss 0.1586 (0.1803)\tPrec 94.531% (93.715%)\n",
      "Epoch: [33][300/391]\tTime 0.045 (0.048)\tData 0.002 (0.003)\tLoss 0.1629 (0.1832)\tPrec 92.969% (93.607%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 0.2659 (0.2659)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.590% \n",
      "best acc: 88.140000\n",
      "Epoch: [34][0/391]\tTime 0.303 (0.303)\tData 0.228 (0.228)\tLoss 0.2103 (0.2103)\tPrec 91.406% (91.406%)\n",
      "Epoch: [34][100/391]\tTime 0.039 (0.053)\tData 0.002 (0.004)\tLoss 0.1619 (0.1795)\tPrec 94.531% (93.611%)\n",
      "Epoch: [34][200/391]\tTime 0.039 (0.052)\tData 0.002 (0.003)\tLoss 0.1017 (0.1882)\tPrec 95.312% (93.299%)\n",
      "Epoch: [34][300/391]\tTime 0.047 (0.052)\tData 0.002 (0.003)\tLoss 0.2554 (0.1859)\tPrec 88.281% (93.402%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.2428 (0.2428)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.490% \n",
      "best acc: 88.140000\n",
      "Epoch: [35][0/391]\tTime 0.286 (0.286)\tData 0.221 (0.221)\tLoss 0.1793 (0.1793)\tPrec 93.750% (93.750%)\n",
      "Epoch: [35][100/391]\tTime 0.049 (0.052)\tData 0.002 (0.004)\tLoss 0.2104 (0.1802)\tPrec 92.188% (93.572%)\n",
      "Epoch: [35][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.003)\tLoss 0.1630 (0.1796)\tPrec 93.750% (93.560%)\n",
      "Epoch: [35][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.003)\tLoss 0.2025 (0.1835)\tPrec 91.406% (93.490%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.2634 (0.2634)\tPrec 94.531% (94.531%)\n",
      " * Prec 87.510% \n",
      "best acc: 88.140000\n",
      "Epoch: [36][0/391]\tTime 0.269 (0.269)\tData 0.218 (0.218)\tLoss 0.1847 (0.1847)\tPrec 94.531% (94.531%)\n",
      "Epoch: [36][100/391]\tTime 0.049 (0.053)\tData 0.002 (0.004)\tLoss 0.1572 (0.1775)\tPrec 94.531% (93.897%)\n",
      "Epoch: [36][200/391]\tTime 0.037 (0.050)\tData 0.002 (0.003)\tLoss 0.1531 (0.1750)\tPrec 96.094% (93.991%)\n",
      "Epoch: [36][300/391]\tTime 0.056 (0.047)\tData 0.002 (0.003)\tLoss 0.2818 (0.1755)\tPrec 88.281% (93.911%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 0.2363 (0.2363)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.730% \n",
      "best acc: 88.140000\n",
      "Epoch: [37][0/391]\tTime 0.272 (0.272)\tData 0.209 (0.209)\tLoss 0.1519 (0.1519)\tPrec 94.531% (94.531%)\n",
      "Epoch: [37][100/391]\tTime 0.046 (0.051)\tData 0.002 (0.004)\tLoss 0.1673 (0.1862)\tPrec 93.750% (93.317%)\n",
      "Epoch: [37][200/391]\tTime 0.048 (0.047)\tData 0.002 (0.003)\tLoss 0.1887 (0.1819)\tPrec 94.531% (93.637%)\n",
      "Epoch: [37][300/391]\tTime 0.041 (0.045)\tData 0.002 (0.002)\tLoss 0.2503 (0.1827)\tPrec 92.188% (93.566%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.2853 (0.2853)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.790% \n",
      "best acc: 88.140000\n",
      "Epoch: [38][0/391]\tTime 0.272 (0.272)\tData 0.213 (0.213)\tLoss 0.2282 (0.2282)\tPrec 92.188% (92.188%)\n",
      "Epoch: [38][100/391]\tTime 0.049 (0.048)\tData 0.002 (0.004)\tLoss 0.1803 (0.1830)\tPrec 93.750% (93.727%)\n",
      "Epoch: [38][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.003)\tLoss 0.2120 (0.1827)\tPrec 91.406% (93.513%)\n",
      "Epoch: [38][300/391]\tTime 0.049 (0.046)\tData 0.002 (0.003)\tLoss 0.2135 (0.1800)\tPrec 90.625% (93.605%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.2680 (0.2680)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.610% \n",
      "best acc: 88.140000\n",
      "Epoch: [39][0/391]\tTime 0.285 (0.285)\tData 0.226 (0.226)\tLoss 0.1678 (0.1678)\tPrec 92.188% (92.188%)\n",
      "Epoch: [39][100/391]\tTime 0.059 (0.049)\tData 0.002 (0.004)\tLoss 0.1131 (0.1743)\tPrec 96.094% (93.920%)\n",
      "Epoch: [39][200/391]\tTime 0.045 (0.053)\tData 0.002 (0.003)\tLoss 0.1736 (0.1782)\tPrec 92.969% (93.703%)\n",
      "Epoch: [39][300/391]\tTime 0.040 (0.050)\tData 0.002 (0.003)\tLoss 0.1208 (0.1798)\tPrec 94.531% (93.651%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.231 (0.231)\tLoss 0.2541 (0.2541)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.090% \n",
      "best acc: 88.140000\n",
      "Epoch: [40][0/391]\tTime 0.270 (0.270)\tData 0.224 (0.224)\tLoss 0.1478 (0.1478)\tPrec 93.750% (93.750%)\n",
      "Epoch: [40][100/391]\tTime 0.056 (0.045)\tData 0.003 (0.004)\tLoss 0.1909 (0.1766)\tPrec 92.969% (93.858%)\n",
      "Epoch: [40][200/391]\tTime 0.056 (0.045)\tData 0.002 (0.003)\tLoss 0.1303 (0.1764)\tPrec 96.094% (93.855%)\n",
      "Epoch: [40][300/391]\tTime 0.041 (0.048)\tData 0.002 (0.003)\tLoss 0.2446 (0.1750)\tPrec 92.969% (93.885%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.231 (0.231)\tLoss 0.2460 (0.2460)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.290% \n",
      "best acc: 88.140000\n",
      "Epoch: [41][0/391]\tTime 0.301 (0.301)\tData 0.243 (0.243)\tLoss 0.1469 (0.1469)\tPrec 96.094% (96.094%)\n",
      "Epoch: [41][100/391]\tTime 0.044 (0.050)\tData 0.002 (0.004)\tLoss 0.1737 (0.1756)\tPrec 94.531% (93.765%)\n",
      "Epoch: [41][200/391]\tTime 0.042 (0.046)\tData 0.002 (0.003)\tLoss 0.1977 (0.1813)\tPrec 93.750% (93.424%)\n",
      "Epoch: [41][300/391]\tTime 0.043 (0.046)\tData 0.002 (0.003)\tLoss 0.2580 (0.1803)\tPrec 89.062% (93.532%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.229 (0.229)\tLoss 0.2731 (0.2731)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.390% \n",
      "best acc: 88.140000\n",
      "Epoch: [42][0/391]\tTime 0.288 (0.288)\tData 0.230 (0.230)\tLoss 0.2337 (0.2337)\tPrec 91.406% (91.406%)\n",
      "Epoch: [42][100/391]\tTime 0.038 (0.047)\tData 0.002 (0.004)\tLoss 0.1484 (0.1729)\tPrec 95.312% (94.021%)\n",
      "Epoch: [42][200/391]\tTime 0.038 (0.046)\tData 0.001 (0.003)\tLoss 0.2663 (0.1744)\tPrec 89.844% (93.886%)\n",
      "Epoch: [42][300/391]\tTime 0.041 (0.047)\tData 0.002 (0.003)\tLoss 0.2241 (0.1732)\tPrec 92.188% (93.856%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.2119 (0.2119)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.710% \n",
      "best acc: 88.140000\n",
      "Epoch: [43][0/391]\tTime 0.325 (0.325)\tData 0.259 (0.259)\tLoss 0.0885 (0.0885)\tPrec 96.094% (96.094%)\n",
      "Epoch: [43][100/391]\tTime 0.040 (0.054)\tData 0.002 (0.005)\tLoss 0.1758 (0.1763)\tPrec 93.750% (93.905%)\n",
      "Epoch: [43][200/391]\tTime 0.050 (0.049)\tData 0.002 (0.003)\tLoss 0.1120 (0.1762)\tPrec 96.875% (93.773%)\n",
      "Epoch: [43][300/391]\tTime 0.042 (0.049)\tData 0.002 (0.003)\tLoss 0.2649 (0.1785)\tPrec 91.406% (93.662%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.239 (0.239)\tLoss 0.3027 (0.3027)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.870% \n",
      "best acc: 88.140000\n",
      "Epoch: [44][0/391]\tTime 0.278 (0.278)\tData 0.217 (0.217)\tLoss 0.1555 (0.1555)\tPrec 95.312% (95.312%)\n",
      "Epoch: [44][100/391]\tTime 0.042 (0.055)\tData 0.002 (0.004)\tLoss 0.1268 (0.1671)\tPrec 96.875% (94.206%)\n",
      "Epoch: [44][200/391]\tTime 0.061 (0.047)\tData 0.002 (0.003)\tLoss 0.1690 (0.1720)\tPrec 93.750% (93.929%)\n",
      "Epoch: [44][300/391]\tTime 0.040 (0.048)\tData 0.002 (0.003)\tLoss 0.1588 (0.1729)\tPrec 96.094% (93.934%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.3086 (0.3086)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.500% \n",
      "best acc: 88.140000\n",
      "Epoch: [45][0/391]\tTime 0.261 (0.261)\tData 0.204 (0.204)\tLoss 0.1876 (0.1876)\tPrec 94.531% (94.531%)\n",
      "Epoch: [45][100/391]\tTime 0.046 (0.050)\tData 0.002 (0.004)\tLoss 0.1587 (0.1720)\tPrec 92.969% (93.758%)\n",
      "Epoch: [45][200/391]\tTime 0.040 (0.048)\tData 0.002 (0.003)\tLoss 0.1731 (0.1738)\tPrec 92.969% (93.789%)\n",
      "Epoch: [45][300/391]\tTime 0.059 (0.046)\tData 0.008 (0.003)\tLoss 0.1157 (0.1734)\tPrec 96.094% (93.851%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.2651 (0.2651)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.630% \n",
      "best acc: 88.140000\n",
      "Epoch: [46][0/391]\tTime 0.271 (0.271)\tData 0.214 (0.214)\tLoss 0.0764 (0.0764)\tPrec 96.875% (96.875%)\n",
      "Epoch: [46][100/391]\tTime 0.050 (0.049)\tData 0.002 (0.004)\tLoss 0.1404 (0.1715)\tPrec 92.969% (93.959%)\n",
      "Epoch: [46][200/391]\tTime 0.039 (0.046)\tData 0.002 (0.003)\tLoss 0.1721 (0.1745)\tPrec 92.188% (93.855%)\n",
      "Epoch: [46][300/391]\tTime 0.038 (0.046)\tData 0.002 (0.003)\tLoss 0.1301 (0.1738)\tPrec 96.875% (93.838%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.2282 (0.2282)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.550% \n",
      "best acc: 88.140000\n",
      "Epoch: [47][0/391]\tTime 0.278 (0.278)\tData 0.221 (0.221)\tLoss 0.1350 (0.1350)\tPrec 96.094% (96.094%)\n",
      "Epoch: [47][100/391]\tTime 0.049 (0.050)\tData 0.001 (0.004)\tLoss 0.1753 (0.1674)\tPrec 95.312% (93.843%)\n",
      "Epoch: [47][200/391]\tTime 0.040 (0.050)\tData 0.002 (0.003)\tLoss 0.1391 (0.1690)\tPrec 95.312% (93.898%)\n",
      "Epoch: [47][300/391]\tTime 0.046 (0.049)\tData 0.002 (0.003)\tLoss 0.0746 (0.1704)\tPrec 99.219% (93.929%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 0.2209 (0.2209)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.470% \n",
      "best acc: 88.140000\n",
      "Epoch: [48][0/391]\tTime 0.266 (0.266)\tData 0.212 (0.212)\tLoss 0.1877 (0.1877)\tPrec 93.750% (93.750%)\n",
      "Epoch: [48][100/391]\tTime 0.046 (0.048)\tData 0.002 (0.004)\tLoss 0.1333 (0.1710)\tPrec 93.750% (93.974%)\n",
      "Epoch: [48][200/391]\tTime 0.058 (0.049)\tData 0.002 (0.003)\tLoss 0.2006 (0.1710)\tPrec 92.969% (93.964%)\n",
      "Epoch: [48][300/391]\tTime 0.059 (0.048)\tData 0.002 (0.003)\tLoss 0.1610 (0.1723)\tPrec 93.750% (93.924%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.2238 (0.2238)\tPrec 93.750% (93.750%)\n",
      " * Prec 87.600% \n",
      "best acc: 88.140000\n",
      "Epoch: [49][0/391]\tTime 0.279 (0.279)\tData 0.219 (0.219)\tLoss 0.1743 (0.1743)\tPrec 93.750% (93.750%)\n",
      "Epoch: [49][100/391]\tTime 0.055 (0.049)\tData 0.002 (0.004)\tLoss 0.1718 (0.1719)\tPrec 92.969% (93.951%)\n",
      "Epoch: [49][200/391]\tTime 0.037 (0.049)\tData 0.002 (0.003)\tLoss 0.1483 (0.1686)\tPrec 94.531% (94.139%)\n",
      "Epoch: [49][300/391]\tTime 0.064 (0.047)\tData 0.003 (0.003)\tLoss 0.1636 (0.1693)\tPrec 95.312% (94.160%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 0.2289 (0.2289)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.530% \n",
      "best acc: 88.140000\n",
      "Epoch: [50][0/391]\tTime 0.259 (0.259)\tData 0.204 (0.204)\tLoss 0.0862 (0.0862)\tPrec 96.875% (96.875%)\n",
      "Epoch: [50][100/391]\tTime 0.039 (0.047)\tData 0.002 (0.004)\tLoss 0.2240 (0.1670)\tPrec 92.188% (94.067%)\n",
      "Epoch: [50][200/391]\tTime 0.048 (0.046)\tData 0.002 (0.003)\tLoss 0.1595 (0.1691)\tPrec 91.406% (93.886%)\n",
      "Epoch: [50][300/391]\tTime 0.048 (0.046)\tData 0.002 (0.003)\tLoss 0.1484 (0.1709)\tPrec 94.531% (93.817%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.2659 (0.2659)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.890% \n",
      "best acc: 88.140000\n",
      "Epoch: [51][0/391]\tTime 0.267 (0.267)\tData 0.214 (0.214)\tLoss 0.1924 (0.1924)\tPrec 93.750% (93.750%)\n",
      "Epoch: [51][100/391]\tTime 0.039 (0.048)\tData 0.002 (0.004)\tLoss 0.2360 (0.1577)\tPrec 92.188% (94.206%)\n",
      "Epoch: [51][200/391]\tTime 0.039 (0.046)\tData 0.001 (0.003)\tLoss 0.2145 (0.1623)\tPrec 91.406% (94.053%)\n",
      "Epoch: [51][300/391]\tTime 0.039 (0.046)\tData 0.002 (0.002)\tLoss 0.1476 (0.1661)\tPrec 94.531% (93.986%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.2459 (0.2459)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.160% \n",
      "best acc: 88.140000\n",
      "Epoch: [52][0/391]\tTime 0.280 (0.280)\tData 0.218 (0.218)\tLoss 0.1238 (0.1238)\tPrec 95.312% (95.312%)\n",
      "Epoch: [52][100/391]\tTime 0.040 (0.052)\tData 0.001 (0.004)\tLoss 0.1314 (0.1611)\tPrec 95.312% (94.152%)\n",
      "Epoch: [52][200/391]\tTime 0.061 (0.050)\tData 0.002 (0.003)\tLoss 0.1584 (0.1668)\tPrec 95.312% (94.030%)\n",
      "Epoch: [52][300/391]\tTime 0.048 (0.050)\tData 0.002 (0.003)\tLoss 0.1714 (0.1668)\tPrec 92.969% (94.025%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.246 (0.246)\tLoss 0.1971 (0.1971)\tPrec 93.750% (93.750%)\n",
      " * Prec 87.530% \n",
      "best acc: 88.140000\n",
      "Epoch: [53][0/391]\tTime 0.322 (0.322)\tData 0.250 (0.250)\tLoss 0.1117 (0.1117)\tPrec 94.531% (94.531%)\n",
      "Epoch: [53][100/391]\tTime 0.047 (0.054)\tData 0.002 (0.005)\tLoss 0.2875 (0.1725)\tPrec 92.969% (93.959%)\n",
      "Epoch: [53][200/391]\tTime 0.049 (0.051)\tData 0.002 (0.003)\tLoss 0.1857 (0.1686)\tPrec 92.188% (94.092%)\n",
      "Epoch: [53][300/391]\tTime 0.045 (0.051)\tData 0.002 (0.003)\tLoss 0.1169 (0.1694)\tPrec 95.312% (94.028%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 0.3206 (0.3206)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.230% \n",
      "best acc: 88.140000\n",
      "Epoch: [54][0/391]\tTime 0.312 (0.312)\tData 0.251 (0.251)\tLoss 0.1226 (0.1226)\tPrec 94.531% (94.531%)\n",
      "Epoch: [54][100/391]\tTime 0.041 (0.052)\tData 0.001 (0.004)\tLoss 0.1160 (0.1670)\tPrec 96.094% (94.152%)\n",
      "Epoch: [54][200/391]\tTime 0.036 (0.047)\tData 0.002 (0.003)\tLoss 0.1288 (0.1653)\tPrec 95.312% (94.127%)\n",
      "Epoch: [54][300/391]\tTime 0.039 (0.046)\tData 0.002 (0.003)\tLoss 0.1776 (0.1673)\tPrec 95.312% (94.108%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.3099 (0.3099)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.290% \n",
      "best acc: 88.140000\n",
      "Epoch: [55][0/391]\tTime 0.256 (0.256)\tData 0.205 (0.205)\tLoss 0.0814 (0.0814)\tPrec 97.656% (97.656%)\n",
      "Epoch: [55][100/391]\tTime 0.049 (0.053)\tData 0.002 (0.004)\tLoss 0.2143 (0.1568)\tPrec 92.969% (94.547%)\n",
      "Epoch: [55][200/391]\tTime 0.041 (0.050)\tData 0.002 (0.003)\tLoss 0.1246 (0.1638)\tPrec 96.094% (94.271%)\n",
      "Epoch: [55][300/391]\tTime 0.060 (0.048)\tData 0.003 (0.003)\tLoss 0.2039 (0.1664)\tPrec 92.188% (94.176%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.194 (0.194)\tLoss 0.3029 (0.3029)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.430% \n",
      "best acc: 88.140000\n",
      "Epoch: [56][0/391]\tTime 0.283 (0.283)\tData 0.223 (0.223)\tLoss 0.1309 (0.1309)\tPrec 97.656% (97.656%)\n",
      "Epoch: [56][100/391]\tTime 0.051 (0.047)\tData 0.002 (0.004)\tLoss 0.2326 (0.1554)\tPrec 92.969% (94.493%)\n",
      "Epoch: [56][200/391]\tTime 0.046 (0.046)\tData 0.002 (0.003)\tLoss 0.1323 (0.1581)\tPrec 94.531% (94.372%)\n",
      "Epoch: [56][300/391]\tTime 0.049 (0.045)\tData 0.002 (0.003)\tLoss 0.2112 (0.1582)\tPrec 91.406% (94.391%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.3029 (0.3029)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.710% \n",
      "best acc: 88.140000\n",
      "Epoch: [57][0/391]\tTime 0.258 (0.258)\tData 0.203 (0.203)\tLoss 0.2349 (0.2349)\tPrec 91.406% (91.406%)\n",
      "Epoch: [57][100/391]\tTime 0.046 (0.051)\tData 0.002 (0.004)\tLoss 0.1014 (0.1628)\tPrec 96.875% (94.121%)\n",
      "Epoch: [57][200/391]\tTime 0.040 (0.048)\tData 0.001 (0.003)\tLoss 0.1504 (0.1607)\tPrec 96.875% (94.279%)\n",
      "Epoch: [57][300/391]\tTime 0.041 (0.047)\tData 0.001 (0.003)\tLoss 0.1579 (0.1620)\tPrec 96.094% (94.233%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 0.2466 (0.2466)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.720% \n",
      "best acc: 88.140000\n",
      "Epoch: [58][0/391]\tTime 0.264 (0.264)\tData 0.196 (0.196)\tLoss 0.2473 (0.2473)\tPrec 88.281% (88.281%)\n",
      "Epoch: [58][100/391]\tTime 0.041 (0.046)\tData 0.002 (0.004)\tLoss 0.0759 (0.1612)\tPrec 96.875% (94.075%)\n",
      "Epoch: [58][200/391]\tTime 0.051 (0.046)\tData 0.002 (0.003)\tLoss 0.2326 (0.1619)\tPrec 92.969% (94.162%)\n",
      "Epoch: [58][300/391]\tTime 0.039 (0.045)\tData 0.002 (0.003)\tLoss 0.0880 (0.1639)\tPrec 95.312% (94.132%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.3145 (0.3145)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.440% \n",
      "best acc: 88.140000\n",
      "Epoch: [59][0/391]\tTime 0.280 (0.280)\tData 0.236 (0.236)\tLoss 0.1341 (0.1341)\tPrec 92.188% (92.188%)\n",
      "Epoch: [59][100/391]\tTime 0.037 (0.047)\tData 0.002 (0.004)\tLoss 0.1450 (0.1540)\tPrec 93.750% (94.469%)\n",
      "Epoch: [59][200/391]\tTime 0.044 (0.045)\tData 0.003 (0.003)\tLoss 0.2540 (0.1580)\tPrec 89.062% (94.286%)\n",
      "Epoch: [59][300/391]\tTime 0.046 (0.046)\tData 0.002 (0.003)\tLoss 0.1262 (0.1619)\tPrec 96.875% (94.157%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.3148 (0.3148)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.040% \n",
      "best acc: 88.140000\n",
      "Epoch: [60][0/391]\tTime 0.252 (0.252)\tData 0.201 (0.201)\tLoss 0.1155 (0.1155)\tPrec 94.531% (94.531%)\n",
      "Epoch: [60][100/391]\tTime 0.060 (0.047)\tData 0.002 (0.004)\tLoss 0.1475 (0.1533)\tPrec 95.312% (94.485%)\n",
      "Epoch: [60][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.003)\tLoss 0.1415 (0.1520)\tPrec 95.312% (94.586%)\n",
      "Epoch: [60][300/391]\tTime 0.040 (0.047)\tData 0.002 (0.003)\tLoss 0.1483 (0.1563)\tPrec 95.312% (94.435%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.2960 (0.2960)\tPrec 89.062% (89.062%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec 87.150% \n",
      "best acc: 88.140000\n",
      "Epoch: [61][0/391]\tTime 0.236 (0.236)\tData 0.190 (0.190)\tLoss 0.1234 (0.1234)\tPrec 94.531% (94.531%)\n",
      "Epoch: [61][100/391]\tTime 0.042 (0.049)\tData 0.002 (0.004)\tLoss 0.2262 (0.1566)\tPrec 95.312% (94.593%)\n",
      "Epoch: [61][200/391]\tTime 0.046 (0.048)\tData 0.003 (0.003)\tLoss 0.3035 (0.1604)\tPrec 88.281% (94.411%)\n",
      "Epoch: [61][300/391]\tTime 0.043 (0.048)\tData 0.002 (0.003)\tLoss 0.1708 (0.1577)\tPrec 93.750% (94.505%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.2839 (0.2839)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.420% \n",
      "best acc: 88.140000\n",
      "Epoch: [62][0/391]\tTime 0.247 (0.247)\tData 0.199 (0.199)\tLoss 0.1883 (0.1883)\tPrec 93.750% (93.750%)\n",
      "Epoch: [62][100/391]\tTime 0.041 (0.047)\tData 0.002 (0.004)\tLoss 0.1618 (0.1639)\tPrec 96.094% (94.098%)\n",
      "Epoch: [62][200/391]\tTime 0.042 (0.047)\tData 0.002 (0.003)\tLoss 0.1496 (0.1631)\tPrec 92.969% (94.166%)\n",
      "Epoch: [62][300/391]\tTime 0.048 (0.047)\tData 0.002 (0.003)\tLoss 0.1065 (0.1656)\tPrec 96.094% (94.059%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.2801 (0.2801)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.260% \n",
      "best acc: 88.140000\n",
      "Epoch: [63][0/391]\tTime 0.276 (0.276)\tData 0.217 (0.217)\tLoss 0.1383 (0.1383)\tPrec 95.312% (95.312%)\n",
      "Epoch: [63][100/391]\tTime 0.044 (0.046)\tData 0.002 (0.004)\tLoss 0.1177 (0.1531)\tPrec 96.875% (94.609%)\n",
      "Epoch: [63][200/391]\tTime 0.047 (0.045)\tData 0.002 (0.003)\tLoss 0.1592 (0.1557)\tPrec 92.969% (94.543%)\n",
      "Epoch: [63][300/391]\tTime 0.041 (0.044)\tData 0.002 (0.003)\tLoss 0.1927 (0.1580)\tPrec 92.188% (94.407%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.3058 (0.3058)\tPrec 86.719% (86.719%)\n",
      " * Prec 86.590% \n",
      "best acc: 88.140000\n",
      "Epoch: [64][0/391]\tTime 0.265 (0.265)\tData 0.205 (0.205)\tLoss 0.1072 (0.1072)\tPrec 97.656% (97.656%)\n",
      "Epoch: [64][100/391]\tTime 0.049 (0.048)\tData 0.002 (0.004)\tLoss 0.1647 (0.1523)\tPrec 93.750% (94.632%)\n",
      "Epoch: [64][200/391]\tTime 0.054 (0.049)\tData 0.004 (0.003)\tLoss 0.1888 (0.1544)\tPrec 93.750% (94.539%)\n",
      "Epoch: [64][300/391]\tTime 0.057 (0.049)\tData 0.002 (0.003)\tLoss 0.1379 (0.1554)\tPrec 95.312% (94.510%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.3035 (0.3035)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.310% \n",
      "best acc: 88.140000\n",
      "Epoch: [65][0/391]\tTime 0.268 (0.268)\tData 0.221 (0.221)\tLoss 0.1294 (0.1294)\tPrec 94.531% (94.531%)\n",
      "Epoch: [65][100/391]\tTime 0.061 (0.049)\tData 0.002 (0.004)\tLoss 0.1627 (0.1498)\tPrec 92.969% (94.516%)\n",
      "Epoch: [65][200/391]\tTime 0.049 (0.048)\tData 0.002 (0.003)\tLoss 0.1709 (0.1516)\tPrec 93.750% (94.531%)\n",
      "Epoch: [65][300/391]\tTime 0.043 (0.048)\tData 0.002 (0.003)\tLoss 0.2010 (0.1542)\tPrec 92.188% (94.451%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.3116 (0.3116)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.370% \n",
      "best acc: 88.140000\n",
      "Epoch: [66][0/391]\tTime 0.282 (0.282)\tData 0.220 (0.220)\tLoss 0.1979 (0.1979)\tPrec 91.406% (91.406%)\n",
      "Epoch: [66][100/391]\tTime 0.049 (0.049)\tData 0.002 (0.004)\tLoss 0.1864 (0.1583)\tPrec 93.750% (94.500%)\n",
      "Epoch: [66][200/391]\tTime 0.056 (0.049)\tData 0.002 (0.003)\tLoss 0.1226 (0.1576)\tPrec 96.094% (94.407%)\n",
      "Epoch: [66][300/391]\tTime 0.041 (0.049)\tData 0.002 (0.003)\tLoss 0.2083 (0.1573)\tPrec 90.625% (94.412%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.2405 (0.2405)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.680% \n",
      "best acc: 88.140000\n",
      "Epoch: [67][0/391]\tTime 0.254 (0.254)\tData 0.201 (0.201)\tLoss 0.2168 (0.2168)\tPrec 92.969% (92.969%)\n",
      "Epoch: [67][100/391]\tTime 0.040 (0.049)\tData 0.002 (0.004)\tLoss 0.0864 (0.1478)\tPrec 96.094% (94.864%)\n",
      "Epoch: [67][200/391]\tTime 0.040 (0.049)\tData 0.002 (0.003)\tLoss 0.1397 (0.1533)\tPrec 92.969% (94.582%)\n",
      "Epoch: [67][300/391]\tTime 0.043 (0.049)\tData 0.002 (0.002)\tLoss 0.0972 (0.1547)\tPrec 96.094% (94.575%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 0.2845 (0.2845)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.370% \n",
      "best acc: 88.140000\n",
      "Epoch: [68][0/391]\tTime 0.260 (0.260)\tData 0.206 (0.206)\tLoss 0.1136 (0.1136)\tPrec 93.750% (93.750%)\n",
      "Epoch: [68][100/391]\tTime 0.040 (0.048)\tData 0.001 (0.004)\tLoss 0.1242 (0.1556)\tPrec 95.312% (94.524%)\n",
      "Epoch: [68][200/391]\tTime 0.052 (0.047)\tData 0.002 (0.003)\tLoss 0.2183 (0.1552)\tPrec 92.188% (94.488%)\n",
      "Epoch: [68][300/391]\tTime 0.056 (0.046)\tData 0.003 (0.002)\tLoss 0.1634 (0.1577)\tPrec 94.531% (94.370%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.2689 (0.2689)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.630% \n",
      "best acc: 88.140000\n",
      "Epoch: [69][0/391]\tTime 0.270 (0.270)\tData 0.216 (0.216)\tLoss 0.2149 (0.2149)\tPrec 93.750% (93.750%)\n",
      "Epoch: [69][100/391]\tTime 0.059 (0.050)\tData 0.002 (0.004)\tLoss 0.1054 (0.1494)\tPrec 96.094% (94.864%)\n",
      "Epoch: [69][200/391]\tTime 0.050 (0.052)\tData 0.002 (0.003)\tLoss 0.1066 (0.1513)\tPrec 96.875% (94.722%)\n",
      "Epoch: [69][300/391]\tTime 0.071 (0.051)\tData 0.002 (0.003)\tLoss 0.1083 (0.1531)\tPrec 96.094% (94.586%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.2363 (0.2363)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.480% \n",
      "best acc: 88.140000\n",
      "Epoch: [70][0/391]\tTime 0.280 (0.280)\tData 0.226 (0.226)\tLoss 0.0712 (0.0712)\tPrec 99.219% (99.219%)\n",
      "Epoch: [70][100/391]\tTime 0.063 (0.050)\tData 0.002 (0.004)\tLoss 0.1295 (0.1515)\tPrec 94.531% (94.670%)\n",
      "Epoch: [70][200/391]\tTime 0.041 (0.052)\tData 0.002 (0.003)\tLoss 0.1660 (0.1533)\tPrec 94.531% (94.535%)\n",
      "Epoch: [70][300/391]\tTime 0.059 (0.051)\tData 0.003 (0.003)\tLoss 0.1079 (0.1542)\tPrec 92.188% (94.503%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 0.2428 (0.2428)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.220% \n",
      "best acc: 88.140000\n",
      "Epoch: [71][0/391]\tTime 0.274 (0.274)\tData 0.214 (0.214)\tLoss 0.1477 (0.1477)\tPrec 94.531% (94.531%)\n",
      "Epoch: [71][100/391]\tTime 0.043 (0.050)\tData 0.001 (0.004)\tLoss 0.1469 (0.1470)\tPrec 92.969% (94.701%)\n",
      "Epoch: [71][200/391]\tTime 0.040 (0.047)\tData 0.002 (0.003)\tLoss 0.1921 (0.1508)\tPrec 94.531% (94.496%)\n",
      "Epoch: [71][300/391]\tTime 0.041 (0.046)\tData 0.002 (0.002)\tLoss 0.2150 (0.1518)\tPrec 92.969% (94.505%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.227 (0.227)\tLoss 0.3025 (0.3025)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.940% \n",
      "best acc: 88.140000\n",
      "Epoch: [72][0/391]\tTime 0.274 (0.274)\tData 0.227 (0.227)\tLoss 0.1112 (0.1112)\tPrec 95.312% (95.312%)\n",
      "Epoch: [72][100/391]\tTime 0.041 (0.047)\tData 0.002 (0.004)\tLoss 0.1389 (0.1468)\tPrec 95.312% (94.647%)\n",
      "Epoch: [72][200/391]\tTime 0.042 (0.046)\tData 0.002 (0.003)\tLoss 0.1227 (0.1497)\tPrec 95.312% (94.590%)\n",
      "Epoch: [72][300/391]\tTime 0.040 (0.045)\tData 0.002 (0.002)\tLoss 0.1589 (0.1503)\tPrec 94.531% (94.614%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.2835 (0.2835)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.500% \n",
      "best acc: 88.140000\n",
      "Epoch: [73][0/391]\tTime 0.244 (0.244)\tData 0.195 (0.195)\tLoss 0.1020 (0.1020)\tPrec 97.656% (97.656%)\n",
      "Epoch: [73][100/391]\tTime 0.049 (0.049)\tData 0.002 (0.004)\tLoss 0.0896 (0.1553)\tPrec 96.875% (94.384%)\n",
      "Epoch: [73][200/391]\tTime 0.040 (0.050)\tData 0.002 (0.003)\tLoss 0.1667 (0.1491)\tPrec 97.656% (94.613%)\n",
      "Epoch: [73][300/391]\tTime 0.039 (0.049)\tData 0.002 (0.003)\tLoss 0.1594 (0.1479)\tPrec 95.312% (94.690%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.2618 (0.2618)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.780% \n",
      "best acc: 88.140000\n",
      "Epoch: [74][0/391]\tTime 0.321 (0.321)\tData 0.261 (0.261)\tLoss 0.0883 (0.0883)\tPrec 97.656% (97.656%)\n",
      "Epoch: [74][100/391]\tTime 0.039 (0.046)\tData 0.002 (0.004)\tLoss 0.2255 (0.1522)\tPrec 91.406% (94.516%)\n",
      "Epoch: [74][200/391]\tTime 0.062 (0.050)\tData 0.002 (0.003)\tLoss 0.0599 (0.1545)\tPrec 98.438% (94.457%)\n",
      "Epoch: [74][300/391]\tTime 0.062 (0.050)\tData 0.002 (0.003)\tLoss 0.1188 (0.1527)\tPrec 95.312% (94.599%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.2344 (0.2344)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.320% \n",
      "best acc: 88.140000\n",
      "Epoch: [75][0/391]\tTime 0.267 (0.267)\tData 0.209 (0.209)\tLoss 0.1768 (0.1768)\tPrec 92.969% (92.969%)\n",
      "Epoch: [75][100/391]\tTime 0.044 (0.052)\tData 0.002 (0.004)\tLoss 0.1343 (0.1430)\tPrec 94.531% (95.057%)\n",
      "Epoch: [75][200/391]\tTime 0.048 (0.052)\tData 0.002 (0.003)\tLoss 0.0910 (0.1487)\tPrec 97.656% (94.764%)\n",
      "Epoch: [75][300/391]\tTime 0.052 (0.051)\tData 0.002 (0.003)\tLoss 0.1220 (0.1505)\tPrec 94.531% (94.716%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.2922 (0.2922)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.610% \n",
      "best acc: 88.140000\n",
      "Epoch: [76][0/391]\tTime 0.291 (0.291)\tData 0.225 (0.225)\tLoss 0.0459 (0.0459)\tPrec 99.219% (99.219%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [76][100/391]\tTime 0.070 (0.047)\tData 0.002 (0.004)\tLoss 0.2742 (0.1442)\tPrec 90.625% (94.895%)\n",
      "Epoch: [76][200/391]\tTime 0.043 (0.046)\tData 0.002 (0.003)\tLoss 0.2659 (0.1443)\tPrec 91.406% (94.866%)\n",
      "Epoch: [76][300/391]\tTime 0.046 (0.047)\tData 0.002 (0.003)\tLoss 0.1314 (0.1466)\tPrec 95.312% (94.825%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.3199 (0.3199)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.940% \n",
      "best acc: 88.140000\n",
      "Epoch: [77][0/391]\tTime 0.278 (0.278)\tData 0.213 (0.213)\tLoss 0.1287 (0.1287)\tPrec 94.531% (94.531%)\n",
      "Epoch: [77][100/391]\tTime 0.052 (0.049)\tData 0.001 (0.004)\tLoss 0.1494 (0.1491)\tPrec 93.750% (94.477%)\n",
      "Epoch: [77][200/391]\tTime 0.069 (0.049)\tData 0.003 (0.003)\tLoss 0.0883 (0.1496)\tPrec 96.875% (94.613%)\n",
      "Epoch: [77][300/391]\tTime 0.048 (0.048)\tData 0.002 (0.002)\tLoss 0.1087 (0.1485)\tPrec 96.094% (94.664%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.1948 (0.1948)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.340% \n",
      "best acc: 88.140000\n",
      "Epoch: [78][0/391]\tTime 0.256 (0.256)\tData 0.201 (0.201)\tLoss 0.1424 (0.1424)\tPrec 90.625% (90.625%)\n",
      "Epoch: [78][100/391]\tTime 0.042 (0.045)\tData 0.002 (0.004)\tLoss 0.1712 (0.1464)\tPrec 92.969% (94.593%)\n",
      "Epoch: [78][200/391]\tTime 0.041 (0.045)\tData 0.002 (0.003)\tLoss 0.2004 (0.1465)\tPrec 93.750% (94.741%)\n",
      "Epoch: [78][300/391]\tTime 0.062 (0.045)\tData 0.002 (0.002)\tLoss 0.0530 (0.1479)\tPrec 99.219% (94.736%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.2668 (0.2668)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.050% \n",
      "best acc: 88.140000\n",
      "Epoch: [79][0/391]\tTime 0.285 (0.285)\tData 0.229 (0.229)\tLoss 0.1257 (0.1257)\tPrec 96.875% (96.875%)\n",
      "Epoch: [79][100/391]\tTime 0.042 (0.048)\tData 0.002 (0.004)\tLoss 0.1290 (0.1448)\tPrec 95.312% (95.050%)\n",
      "Epoch: [79][200/391]\tTime 0.039 (0.048)\tData 0.001 (0.003)\tLoss 0.0935 (0.1469)\tPrec 96.875% (94.951%)\n",
      "Epoch: [79][300/391]\tTime 0.052 (0.046)\tData 0.002 (0.002)\tLoss 0.1773 (0.1474)\tPrec 95.312% (94.830%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 0.2388 (0.2388)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.320% \n",
      "best acc: 88.140000\n",
      "Epoch: [80][0/391]\tTime 0.299 (0.299)\tData 0.234 (0.234)\tLoss 0.1072 (0.1072)\tPrec 97.656% (97.656%)\n",
      "Epoch: [80][100/391]\tTime 0.043 (0.049)\tData 0.002 (0.004)\tLoss 0.2140 (0.1378)\tPrec 91.406% (95.088%)\n",
      "Epoch: [80][200/391]\tTime 0.046 (0.049)\tData 0.002 (0.003)\tLoss 0.1640 (0.1412)\tPrec 94.531% (95.037%)\n",
      "Epoch: [80][300/391]\tTime 0.059 (0.048)\tData 0.002 (0.003)\tLoss 0.1662 (0.1459)\tPrec 94.531% (94.804%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 0.2532 (0.2532)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.740% \n",
      "best acc: 88.140000\n",
      "Epoch: [81][0/391]\tTime 0.281 (0.281)\tData 0.224 (0.224)\tLoss 0.1101 (0.1101)\tPrec 97.656% (97.656%)\n",
      "Epoch: [81][100/391]\tTime 0.044 (0.050)\tData 0.002 (0.004)\tLoss 0.2036 (0.1463)\tPrec 93.750% (94.848%)\n",
      "Epoch: [81][200/391]\tTime 0.063 (0.050)\tData 0.003 (0.003)\tLoss 0.2122 (0.1453)\tPrec 92.188% (94.792%)\n",
      "Epoch: [81][300/391]\tTime 0.057 (0.052)\tData 0.002 (0.003)\tLoss 0.0814 (0.1465)\tPrec 98.438% (94.788%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.4065 (0.4065)\tPrec 85.156% (85.156%)\n",
      " * Prec 86.950% \n",
      "best acc: 88.140000\n",
      "Epoch: [82][0/391]\tTime 0.270 (0.270)\tData 0.216 (0.216)\tLoss 0.1701 (0.1701)\tPrec 96.094% (96.094%)\n",
      "Epoch: [82][100/391]\tTime 0.045 (0.048)\tData 0.001 (0.004)\tLoss 0.1234 (0.1446)\tPrec 96.094% (94.779%)\n",
      "Epoch: [82][200/391]\tTime 0.049 (0.048)\tData 0.002 (0.003)\tLoss 0.1164 (0.1459)\tPrec 95.312% (94.819%)\n",
      "Epoch: [82][300/391]\tTime 0.042 (0.049)\tData 0.002 (0.003)\tLoss 0.1652 (0.1473)\tPrec 96.094% (94.767%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.3012 (0.3012)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.170% \n",
      "best acc: 88.140000\n",
      "Epoch: [83][0/391]\tTime 0.261 (0.261)\tData 0.208 (0.208)\tLoss 0.0864 (0.0864)\tPrec 97.656% (97.656%)\n",
      "Epoch: [83][100/391]\tTime 0.039 (0.050)\tData 0.002 (0.004)\tLoss 0.1497 (0.1429)\tPrec 95.312% (94.810%)\n",
      "Epoch: [83][200/391]\tTime 0.037 (0.044)\tData 0.002 (0.003)\tLoss 0.2064 (0.1465)\tPrec 92.188% (94.761%)\n",
      "Epoch: [83][300/391]\tTime 0.038 (0.043)\tData 0.002 (0.002)\tLoss 0.1230 (0.1451)\tPrec 95.312% (94.799%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 0.3065 (0.3065)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.110% \n",
      "best acc: 88.140000\n",
      "Epoch: [84][0/391]\tTime 0.289 (0.289)\tData 0.235 (0.235)\tLoss 0.1713 (0.1713)\tPrec 92.969% (92.969%)\n",
      "Epoch: [84][100/391]\tTime 0.038 (0.047)\tData 0.002 (0.004)\tLoss 0.1934 (0.1386)\tPrec 91.406% (95.034%)\n",
      "Epoch: [84][200/391]\tTime 0.044 (0.046)\tData 0.002 (0.003)\tLoss 0.0891 (0.1389)\tPrec 96.094% (94.893%)\n",
      "Epoch: [84][300/391]\tTime 0.041 (0.046)\tData 0.002 (0.003)\tLoss 0.1785 (0.1396)\tPrec 92.188% (94.910%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.2894 (0.2894)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.230% \n",
      "best acc: 88.140000\n",
      "Epoch: [85][0/391]\tTime 0.274 (0.274)\tData 0.217 (0.217)\tLoss 0.2093 (0.2093)\tPrec 92.969% (92.969%)\n",
      "Epoch: [85][100/391]\tTime 0.057 (0.044)\tData 0.002 (0.004)\tLoss 0.0847 (0.1460)\tPrec 96.875% (94.701%)\n",
      "Epoch: [85][200/391]\tTime 0.044 (0.045)\tData 0.002 (0.003)\tLoss 0.1376 (0.1446)\tPrec 96.875% (94.753%)\n",
      "Epoch: [85][300/391]\tTime 0.055 (0.047)\tData 0.002 (0.003)\tLoss 0.1381 (0.1449)\tPrec 94.531% (94.773%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.3141 (0.3141)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.350% \n",
      "best acc: 88.140000\n",
      "Epoch: [86][0/391]\tTime 0.267 (0.267)\tData 0.204 (0.204)\tLoss 0.1363 (0.1363)\tPrec 93.750% (93.750%)\n",
      "Epoch: [86][100/391]\tTime 0.044 (0.045)\tData 0.002 (0.004)\tLoss 0.1077 (0.1361)\tPrec 96.875% (95.297%)\n",
      "Epoch: [86][200/391]\tTime 0.055 (0.049)\tData 0.002 (0.003)\tLoss 0.1031 (0.1405)\tPrec 96.875% (95.052%)\n",
      "Epoch: [86][300/391]\tTime 0.048 (0.050)\tData 0.002 (0.003)\tLoss 0.1781 (0.1405)\tPrec 96.094% (95.061%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.237 (0.237)\tLoss 0.2940 (0.2940)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.400% \n",
      "best acc: 88.140000\n",
      "Epoch: [87][0/391]\tTime 0.282 (0.282)\tData 0.218 (0.218)\tLoss 0.0573 (0.0573)\tPrec 98.438% (98.438%)\n",
      "Epoch: [87][100/391]\tTime 0.051 (0.050)\tData 0.003 (0.004)\tLoss 0.0782 (0.1291)\tPrec 97.656% (95.297%)\n",
      "Epoch: [87][200/391]\tTime 0.054 (0.053)\tData 0.002 (0.003)\tLoss 0.1342 (0.1362)\tPrec 96.094% (95.134%)\n",
      "Epoch: [87][300/391]\tTime 0.059 (0.051)\tData 0.002 (0.003)\tLoss 0.1338 (0.1412)\tPrec 97.656% (94.884%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.2449 (0.2449)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.490% \n",
      "best acc: 88.140000\n",
      "Epoch: [88][0/391]\tTime 0.270 (0.270)\tData 0.207 (0.207)\tLoss 0.1071 (0.1071)\tPrec 96.094% (96.094%)\n",
      "Epoch: [88][100/391]\tTime 0.068 (0.055)\tData 0.002 (0.004)\tLoss 0.2004 (0.1375)\tPrec 92.188% (94.817%)\n",
      "Epoch: [88][200/391]\tTime 0.041 (0.052)\tData 0.002 (0.003)\tLoss 0.0996 (0.1390)\tPrec 95.312% (94.889%)\n",
      "Epoch: [88][300/391]\tTime 0.045 (0.051)\tData 0.002 (0.003)\tLoss 0.1011 (0.1391)\tPrec 97.656% (94.988%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.2373 (0.2373)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.930% \n",
      "best acc: 88.140000\n",
      "Epoch: [89][0/391]\tTime 0.257 (0.257)\tData 0.213 (0.213)\tLoss 0.0986 (0.0986)\tPrec 96.094% (96.094%)\n",
      "Epoch: [89][100/391]\tTime 0.047 (0.046)\tData 0.002 (0.004)\tLoss 0.1542 (0.1411)\tPrec 94.531% (94.848%)\n",
      "Epoch: [89][200/391]\tTime 0.059 (0.046)\tData 0.002 (0.003)\tLoss 0.1874 (0.1422)\tPrec 92.969% (94.873%)\n",
      "Epoch: [89][300/391]\tTime 0.042 (0.047)\tData 0.002 (0.003)\tLoss 0.1253 (0.1410)\tPrec 93.750% (94.952%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.2836 (0.2836)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.410% \n",
      "best acc: 88.140000\n",
      "Epoch: [90][0/391]\tTime 0.257 (0.257)\tData 0.201 (0.201)\tLoss 0.1047 (0.1047)\tPrec 96.875% (96.875%)\n",
      "Epoch: [90][100/391]\tTime 0.049 (0.047)\tData 0.002 (0.004)\tLoss 0.1807 (0.1365)\tPrec 91.406% (95.057%)\n",
      "Epoch: [90][200/391]\tTime 0.040 (0.045)\tData 0.002 (0.003)\tLoss 0.1525 (0.1384)\tPrec 93.750% (95.017%)\n",
      "Epoch: [90][300/391]\tTime 0.050 (0.045)\tData 0.002 (0.002)\tLoss 0.1575 (0.1387)\tPrec 94.531% (94.957%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.2235 (0.2235)\tPrec 94.531% (94.531%)\n",
      " * Prec 87.340% \n",
      "best acc: 88.140000\n",
      "Epoch: [91][0/391]\tTime 0.275 (0.275)\tData 0.216 (0.216)\tLoss 0.1638 (0.1638)\tPrec 94.531% (94.531%)\n",
      "Epoch: [91][100/391]\tTime 0.043 (0.050)\tData 0.002 (0.004)\tLoss 0.0973 (0.1393)\tPrec 96.875% (95.181%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [91][200/391]\tTime 0.039 (0.048)\tData 0.001 (0.003)\tLoss 0.1479 (0.1407)\tPrec 95.312% (95.009%)\n",
      "Epoch: [91][300/391]\tTime 0.039 (0.046)\tData 0.002 (0.003)\tLoss 0.1394 (0.1401)\tPrec 96.094% (95.014%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.3160 (0.3160)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.520% \n",
      "best acc: 88.140000\n",
      "Epoch: [92][0/391]\tTime 0.257 (0.257)\tData 0.201 (0.201)\tLoss 0.1043 (0.1043)\tPrec 96.094% (96.094%)\n",
      "Epoch: [92][100/391]\tTime 0.036 (0.046)\tData 0.002 (0.004)\tLoss 0.1359 (0.1334)\tPrec 96.094% (95.359%)\n",
      "Epoch: [92][200/391]\tTime 0.055 (0.047)\tData 0.002 (0.003)\tLoss 0.2187 (0.1354)\tPrec 92.969% (95.305%)\n",
      "Epoch: [92][300/391]\tTime 0.037 (0.047)\tData 0.002 (0.002)\tLoss 0.1652 (0.1380)\tPrec 95.312% (95.167%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.2472 (0.2472)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.540% \n",
      "best acc: 88.140000\n",
      "Epoch: [93][0/391]\tTime 0.267 (0.267)\tData 0.206 (0.206)\tLoss 0.1043 (0.1043)\tPrec 97.656% (97.656%)\n",
      "Epoch: [93][100/391]\tTime 0.040 (0.046)\tData 0.002 (0.004)\tLoss 0.0947 (0.1393)\tPrec 96.875% (95.088%)\n",
      "Epoch: [93][200/391]\tTime 0.046 (0.045)\tData 0.002 (0.003)\tLoss 0.2101 (0.1359)\tPrec 89.844% (95.153%)\n",
      "Epoch: [93][300/391]\tTime 0.061 (0.048)\tData 0.002 (0.002)\tLoss 0.1007 (0.1342)\tPrec 95.312% (95.237%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.229 (0.229)\tLoss 0.2462 (0.2462)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.050% \n",
      "best acc: 88.140000\n",
      "Epoch: [94][0/391]\tTime 0.270 (0.270)\tData 0.214 (0.214)\tLoss 0.1368 (0.1368)\tPrec 94.531% (94.531%)\n",
      "Epoch: [94][100/391]\tTime 0.037 (0.047)\tData 0.001 (0.004)\tLoss 0.1018 (0.1332)\tPrec 96.094% (95.235%)\n",
      "Epoch: [94][200/391]\tTime 0.057 (0.043)\tData 0.002 (0.003)\tLoss 0.1591 (0.1350)\tPrec 93.750% (95.149%)\n",
      "Epoch: [94][300/391]\tTime 0.063 (0.045)\tData 0.002 (0.002)\tLoss 0.2288 (0.1379)\tPrec 94.531% (95.094%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.2870 (0.2870)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.060% \n",
      "best acc: 88.140000\n",
      "Epoch: [95][0/391]\tTime 0.281 (0.281)\tData 0.211 (0.211)\tLoss 0.1410 (0.1410)\tPrec 95.312% (95.312%)\n",
      "Epoch: [95][100/391]\tTime 0.045 (0.050)\tData 0.002 (0.004)\tLoss 0.1872 (0.1292)\tPrec 92.969% (95.421%)\n",
      "Epoch: [95][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.003)\tLoss 0.1757 (0.1330)\tPrec 94.531% (95.382%)\n",
      "Epoch: [95][300/391]\tTime 0.044 (0.048)\tData 0.002 (0.002)\tLoss 0.1864 (0.1354)\tPrec 96.094% (95.258%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.1812 (0.1812)\tPrec 93.750% (93.750%)\n",
      " * Prec 87.560% \n",
      "best acc: 88.140000\n",
      "Epoch: [96][0/391]\tTime 0.261 (0.261)\tData 0.208 (0.208)\tLoss 0.1732 (0.1732)\tPrec 92.969% (92.969%)\n",
      "Epoch: [96][100/391]\tTime 0.042 (0.048)\tData 0.002 (0.004)\tLoss 0.1404 (0.1337)\tPrec 94.531% (95.258%)\n",
      "Epoch: [96][200/391]\tTime 0.051 (0.045)\tData 0.002 (0.003)\tLoss 0.1948 (0.1351)\tPrec 94.531% (95.130%)\n",
      "Epoch: [96][300/391]\tTime 0.051 (0.046)\tData 0.002 (0.003)\tLoss 0.1840 (0.1379)\tPrec 94.531% (95.040%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.2857 (0.2857)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.060% \n",
      "best acc: 88.140000\n",
      "Epoch: [97][0/391]\tTime 0.316 (0.316)\tData 0.247 (0.247)\tLoss 0.1474 (0.1474)\tPrec 95.312% (95.312%)\n",
      "Epoch: [97][100/391]\tTime 0.038 (0.054)\tData 0.001 (0.005)\tLoss 0.1249 (0.1369)\tPrec 93.750% (95.196%)\n",
      "Epoch: [97][200/391]\tTime 0.040 (0.049)\tData 0.001 (0.003)\tLoss 0.1101 (0.1358)\tPrec 96.875% (95.157%)\n",
      "Epoch: [97][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.003)\tLoss 0.1455 (0.1355)\tPrec 94.531% (95.180%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.2099 (0.2099)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.240% \n",
      "best acc: 88.140000\n",
      "Epoch: [98][0/391]\tTime 0.305 (0.305)\tData 0.240 (0.240)\tLoss 0.0724 (0.0724)\tPrec 97.656% (97.656%)\n",
      "Epoch: [98][100/391]\tTime 0.040 (0.049)\tData 0.002 (0.004)\tLoss 0.1029 (0.1383)\tPrec 95.312% (94.887%)\n",
      "Epoch: [98][200/391]\tTime 0.046 (0.048)\tData 0.002 (0.003)\tLoss 0.1507 (0.1372)\tPrec 93.750% (95.029%)\n",
      "Epoch: [98][300/391]\tTime 0.045 (0.047)\tData 0.001 (0.003)\tLoss 0.1579 (0.1363)\tPrec 93.750% (95.081%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 0.2250 (0.2250)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.220% \n",
      "best acc: 88.140000\n",
      "Epoch: [99][0/391]\tTime 0.284 (0.284)\tData 0.235 (0.235)\tLoss 0.0868 (0.0868)\tPrec 96.094% (96.094%)\n",
      "Epoch: [99][100/391]\tTime 0.046 (0.051)\tData 0.003 (0.005)\tLoss 0.1397 (0.1367)\tPrec 97.656% (95.042%)\n",
      "Epoch: [99][200/391]\tTime 0.043 (0.050)\tData 0.002 (0.003)\tLoss 0.1492 (0.1361)\tPrec 92.969% (95.021%)\n",
      "Epoch: [99][300/391]\tTime 0.042 (0.049)\tData 0.002 (0.003)\tLoss 0.1193 (0.1340)\tPrec 94.531% (95.193%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.2417 (0.2417)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.730% \n",
      "best acc: 88.140000\n",
      "Epoch: [100][0/391]\tTime 0.279 (0.279)\tData 0.213 (0.213)\tLoss 0.1366 (0.1366)\tPrec 96.875% (96.875%)\n",
      "Epoch: [100][100/391]\tTime 0.046 (0.047)\tData 0.002 (0.004)\tLoss 0.1478 (0.1235)\tPrec 95.312% (95.722%)\n",
      "Epoch: [100][200/391]\tTime 0.043 (0.046)\tData 0.002 (0.003)\tLoss 0.1168 (0.1280)\tPrec 94.531% (95.484%)\n",
      "Epoch: [100][300/391]\tTime 0.048 (0.047)\tData 0.002 (0.003)\tLoss 0.0935 (0.1307)\tPrec 96.094% (95.300%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.2560 (0.2560)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.190% \n",
      "best acc: 88.190000\n",
      "Epoch: [101][0/391]\tTime 0.282 (0.282)\tData 0.221 (0.221)\tLoss 0.0446 (0.0446)\tPrec 98.438% (98.438%)\n",
      "Epoch: [101][100/391]\tTime 0.040 (0.048)\tData 0.002 (0.004)\tLoss 0.1858 (0.1244)\tPrec 92.969% (95.475%)\n",
      "Epoch: [101][200/391]\tTime 0.037 (0.046)\tData 0.002 (0.003)\tLoss 0.0644 (0.1288)\tPrec 98.438% (95.324%)\n",
      "Epoch: [101][300/391]\tTime 0.041 (0.045)\tData 0.002 (0.003)\tLoss 0.0840 (0.1275)\tPrec 96.875% (95.385%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 0.2045 (0.2045)\tPrec 93.750% (93.750%)\n",
      " * Prec 87.470% \n",
      "best acc: 88.190000\n",
      "Epoch: [102][0/391]\tTime 0.245 (0.245)\tData 0.201 (0.201)\tLoss 0.1347 (0.1347)\tPrec 95.312% (95.312%)\n",
      "Epoch: [102][100/391]\tTime 0.040 (0.047)\tData 0.002 (0.004)\tLoss 0.1483 (0.1271)\tPrec 95.312% (95.398%)\n",
      "Epoch: [102][200/391]\tTime 0.050 (0.047)\tData 0.002 (0.003)\tLoss 0.1213 (0.1267)\tPrec 95.312% (95.437%)\n",
      "Epoch: [102][300/391]\tTime 0.061 (0.046)\tData 0.002 (0.003)\tLoss 0.2078 (0.1270)\tPrec 95.312% (95.427%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.234 (0.234)\tLoss 0.2113 (0.2113)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.670% \n",
      "best acc: 88.190000\n",
      "Epoch: [103][0/391]\tTime 0.251 (0.251)\tData 0.199 (0.199)\tLoss 0.2118 (0.2118)\tPrec 93.750% (93.750%)\n",
      "Epoch: [103][100/391]\tTime 0.040 (0.049)\tData 0.002 (0.004)\tLoss 0.0986 (0.1268)\tPrec 96.094% (95.421%)\n",
      "Epoch: [103][200/391]\tTime 0.057 (0.050)\tData 0.002 (0.003)\tLoss 0.0886 (0.1305)\tPrec 96.875% (95.305%)\n",
      "Epoch: [103][300/391]\tTime 0.039 (0.049)\tData 0.001 (0.003)\tLoss 0.1549 (0.1290)\tPrec 94.531% (95.367%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.3211 (0.3211)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.110% \n",
      "best acc: 88.190000\n",
      "Epoch: [104][0/391]\tTime 0.286 (0.286)\tData 0.226 (0.226)\tLoss 0.1433 (0.1433)\tPrec 96.875% (96.875%)\n",
      "Epoch: [104][100/391]\tTime 0.059 (0.049)\tData 0.002 (0.004)\tLoss 0.1986 (0.1331)\tPrec 93.750% (95.328%)\n",
      "Epoch: [104][200/391]\tTime 0.040 (0.047)\tData 0.002 (0.003)\tLoss 0.1185 (0.1318)\tPrec 95.312% (95.351%)\n",
      "Epoch: [104][300/391]\tTime 0.044 (0.048)\tData 0.001 (0.003)\tLoss 0.1893 (0.1340)\tPrec 94.531% (95.263%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.3079 (0.3079)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.900% \n",
      "best acc: 88.190000\n",
      "Epoch: [105][0/391]\tTime 0.299 (0.299)\tData 0.250 (0.250)\tLoss 0.1750 (0.1750)\tPrec 91.406% (91.406%)\n",
      "Epoch: [105][100/391]\tTime 0.038 (0.050)\tData 0.001 (0.004)\tLoss 0.0961 (0.1265)\tPrec 96.875% (95.467%)\n",
      "Epoch: [105][200/391]\tTime 0.040 (0.047)\tData 0.002 (0.003)\tLoss 0.0870 (0.1281)\tPrec 94.531% (95.452%)\n",
      "Epoch: [105][300/391]\tTime 0.041 (0.046)\tData 0.002 (0.003)\tLoss 0.0892 (0.1288)\tPrec 95.312% (95.414%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.3518 (0.3518)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.880% \n",
      "best acc: 88.190000\n",
      "Epoch: [106][0/391]\tTime 0.263 (0.263)\tData 0.213 (0.213)\tLoss 0.0434 (0.0434)\tPrec 99.219% (99.219%)\n",
      "Epoch: [106][100/391]\tTime 0.044 (0.048)\tData 0.002 (0.004)\tLoss 0.1789 (0.1265)\tPrec 94.531% (95.583%)\n",
      "Epoch: [106][200/391]\tTime 0.039 (0.047)\tData 0.002 (0.003)\tLoss 0.1764 (0.1308)\tPrec 93.750% (95.390%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [106][300/391]\tTime 0.036 (0.044)\tData 0.002 (0.002)\tLoss 0.1357 (0.1314)\tPrec 93.750% (95.328%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.2407 (0.2407)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.740% \n",
      "best acc: 88.190000\n",
      "Epoch: [107][0/391]\tTime 0.292 (0.292)\tData 0.230 (0.230)\tLoss 0.1604 (0.1604)\tPrec 95.312% (95.312%)\n",
      "Epoch: [107][100/391]\tTime 0.042 (0.048)\tData 0.002 (0.004)\tLoss 0.1178 (0.1283)\tPrec 95.312% (95.490%)\n",
      "Epoch: [107][200/391]\tTime 0.043 (0.047)\tData 0.002 (0.003)\tLoss 0.0916 (0.1262)\tPrec 96.875% (95.538%)\n",
      "Epoch: [107][300/391]\tTime 0.042 (0.047)\tData 0.002 (0.003)\tLoss 0.0988 (0.1273)\tPrec 95.312% (95.502%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.2917 (0.2917)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.370% \n",
      "best acc: 88.190000\n",
      "Epoch: [108][0/391]\tTime 0.259 (0.259)\tData 0.212 (0.212)\tLoss 0.0931 (0.0931)\tPrec 96.875% (96.875%)\n",
      "Epoch: [108][100/391]\tTime 0.041 (0.048)\tData 0.002 (0.004)\tLoss 0.0758 (0.1203)\tPrec 97.656% (95.506%)\n",
      "Epoch: [108][200/391]\tTime 0.036 (0.047)\tData 0.002 (0.003)\tLoss 0.1483 (0.1235)\tPrec 94.531% (95.522%)\n",
      "Epoch: [108][300/391]\tTime 0.051 (0.046)\tData 0.003 (0.003)\tLoss 0.1000 (0.1239)\tPrec 96.094% (95.577%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.2504 (0.2504)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.520% \n",
      "best acc: 88.190000\n",
      "Epoch: [109][0/391]\tTime 0.263 (0.263)\tData 0.215 (0.215)\tLoss 0.0739 (0.0739)\tPrec 97.656% (97.656%)\n",
      "Epoch: [109][100/391]\tTime 0.044 (0.046)\tData 0.002 (0.004)\tLoss 0.1383 (0.1262)\tPrec 94.531% (95.653%)\n",
      "Epoch: [109][200/391]\tTime 0.040 (0.044)\tData 0.002 (0.003)\tLoss 0.0619 (0.1269)\tPrec 98.438% (95.604%)\n",
      "Epoch: [109][300/391]\tTime 0.046 (0.045)\tData 0.002 (0.003)\tLoss 0.0765 (0.1276)\tPrec 97.656% (95.494%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.193 (0.193)\tLoss 0.2682 (0.2682)\tPrec 87.500% (87.500%)\n",
      " * Prec 87.290% \n",
      "best acc: 88.190000\n",
      "Epoch: [110][0/391]\tTime 0.275 (0.275)\tData 0.214 (0.214)\tLoss 0.1530 (0.1530)\tPrec 92.969% (92.969%)\n",
      "Epoch: [110][100/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 0.1019 (0.1247)\tPrec 95.312% (95.436%)\n",
      "Epoch: [110][200/391]\tTime 0.042 (0.047)\tData 0.002 (0.003)\tLoss 0.1119 (0.1275)\tPrec 94.531% (95.320%)\n",
      "Epoch: [110][300/391]\tTime 0.048 (0.046)\tData 0.001 (0.003)\tLoss 0.1812 (0.1290)\tPrec 92.969% (95.271%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.2285 (0.2285)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.360% \n",
      "best acc: 88.190000\n",
      "Epoch: [111][0/391]\tTime 0.273 (0.273)\tData 0.229 (0.229)\tLoss 0.1188 (0.1188)\tPrec 95.312% (95.312%)\n",
      "Epoch: [111][100/391]\tTime 0.046 (0.047)\tData 0.002 (0.004)\tLoss 0.1671 (0.1283)\tPrec 94.531% (95.429%)\n",
      "Epoch: [111][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.003)\tLoss 0.1281 (0.1273)\tPrec 92.969% (95.565%)\n",
      "Epoch: [111][300/391]\tTime 0.056 (0.046)\tData 0.002 (0.003)\tLoss 0.1037 (0.1286)\tPrec 96.094% (95.403%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.184 (0.184)\tLoss 0.3145 (0.3145)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.300% \n",
      "best acc: 88.190000\n",
      "Epoch: [112][0/391]\tTime 0.259 (0.259)\tData 0.199 (0.199)\tLoss 0.0844 (0.0844)\tPrec 96.094% (96.094%)\n",
      "Epoch: [112][100/391]\tTime 0.048 (0.049)\tData 0.001 (0.004)\tLoss 0.0876 (0.1248)\tPrec 96.875% (95.614%)\n",
      "Epoch: [112][200/391]\tTime 0.051 (0.045)\tData 0.002 (0.003)\tLoss 0.1135 (0.1261)\tPrec 96.875% (95.573%)\n",
      "Epoch: [112][300/391]\tTime 0.049 (0.046)\tData 0.002 (0.002)\tLoss 0.1522 (0.1251)\tPrec 95.312% (95.621%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.1898 (0.1898)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.100% \n",
      "best acc: 88.190000\n",
      "Epoch: [113][0/391]\tTime 0.277 (0.277)\tData 0.216 (0.216)\tLoss 0.1381 (0.1381)\tPrec 94.531% (94.531%)\n",
      "Epoch: [113][100/391]\tTime 0.048 (0.047)\tData 0.002 (0.004)\tLoss 0.1354 (0.1170)\tPrec 95.312% (95.838%)\n",
      "Epoch: [113][200/391]\tTime 0.060 (0.050)\tData 0.002 (0.003)\tLoss 0.1776 (0.1266)\tPrec 92.188% (95.375%)\n",
      "Epoch: [113][300/391]\tTime 0.049 (0.048)\tData 0.002 (0.003)\tLoss 0.1506 (0.1280)\tPrec 93.750% (95.370%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.2520 (0.2520)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.870% \n",
      "best acc: 88.190000\n",
      "Epoch: [114][0/391]\tTime 0.293 (0.293)\tData 0.236 (0.236)\tLoss 0.1108 (0.1108)\tPrec 96.094% (96.094%)\n",
      "Epoch: [114][100/391]\tTime 0.053 (0.046)\tData 0.002 (0.004)\tLoss 0.0819 (0.1274)\tPrec 97.656% (95.452%)\n",
      "Epoch: [114][200/391]\tTime 0.038 (0.044)\tData 0.001 (0.003)\tLoss 0.1677 (0.1263)\tPrec 93.750% (95.468%)\n",
      "Epoch: [114][300/391]\tTime 0.046 (0.045)\tData 0.002 (0.003)\tLoss 0.1341 (0.1286)\tPrec 96.094% (95.383%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.2742 (0.2742)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.350% \n",
      "best acc: 88.190000\n",
      "Epoch: [115][0/391]\tTime 0.257 (0.257)\tData 0.201 (0.201)\tLoss 0.1093 (0.1093)\tPrec 95.312% (95.312%)\n",
      "Epoch: [115][100/391]\tTime 0.049 (0.047)\tData 0.002 (0.004)\tLoss 0.1066 (0.1255)\tPrec 94.531% (95.343%)\n",
      "Epoch: [115][200/391]\tTime 0.038 (0.045)\tData 0.001 (0.003)\tLoss 0.1855 (0.1238)\tPrec 93.750% (95.495%)\n",
      "Epoch: [115][300/391]\tTime 0.051 (0.045)\tData 0.001 (0.002)\tLoss 0.0788 (0.1250)\tPrec 96.875% (95.525%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.2360 (0.2360)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.070% \n",
      "best acc: 88.190000\n",
      "Epoch: [116][0/391]\tTime 0.299 (0.299)\tData 0.238 (0.238)\tLoss 0.1201 (0.1201)\tPrec 95.312% (95.312%)\n",
      "Epoch: [116][100/391]\tTime 0.041 (0.052)\tData 0.001 (0.004)\tLoss 0.1771 (0.1234)\tPrec 92.969% (95.537%)\n",
      "Epoch: [116][200/391]\tTime 0.043 (0.050)\tData 0.002 (0.003)\tLoss 0.1110 (0.1270)\tPrec 96.094% (95.503%)\n",
      "Epoch: [116][300/391]\tTime 0.049 (0.049)\tData 0.002 (0.003)\tLoss 0.0568 (0.1286)\tPrec 98.438% (95.492%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.2251 (0.2251)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.360% \n",
      "best acc: 88.190000\n",
      "Epoch: [117][0/391]\tTime 0.280 (0.280)\tData 0.229 (0.229)\tLoss 0.0946 (0.0946)\tPrec 96.094% (96.094%)\n",
      "Epoch: [117][100/391]\tTime 0.039 (0.049)\tData 0.002 (0.004)\tLoss 0.1243 (0.1235)\tPrec 96.094% (95.483%)\n",
      "Epoch: [117][200/391]\tTime 0.044 (0.046)\tData 0.002 (0.003)\tLoss 0.0715 (0.1255)\tPrec 97.656% (95.421%)\n",
      "Epoch: [117][300/391]\tTime 0.059 (0.044)\tData 0.003 (0.003)\tLoss 0.1500 (0.1269)\tPrec 96.094% (95.349%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.2081 (0.2081)\tPrec 94.531% (94.531%)\n",
      " * Prec 87.460% \n",
      "best acc: 88.190000\n",
      "Epoch: [118][0/391]\tTime 0.332 (0.332)\tData 0.268 (0.268)\tLoss 0.0554 (0.0554)\tPrec 100.000% (100.000%)\n",
      "Epoch: [118][100/391]\tTime 0.040 (0.050)\tData 0.002 (0.005)\tLoss 0.1331 (0.1224)\tPrec 96.875% (95.606%)\n",
      "Epoch: [118][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.003)\tLoss 0.1345 (0.1230)\tPrec 94.531% (95.542%)\n",
      "Epoch: [118][300/391]\tTime 0.048 (0.047)\tData 0.002 (0.003)\tLoss 0.1456 (0.1251)\tPrec 92.188% (95.440%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.2747 (0.2747)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.810% \n",
      "best acc: 88.190000\n",
      "Epoch: [119][0/391]\tTime 0.278 (0.278)\tData 0.216 (0.216)\tLoss 0.0786 (0.0786)\tPrec 98.438% (98.438%)\n",
      "Epoch: [119][100/391]\tTime 0.037 (0.051)\tData 0.002 (0.004)\tLoss 0.1401 (0.1186)\tPrec 93.750% (95.900%)\n",
      "Epoch: [119][200/391]\tTime 0.040 (0.047)\tData 0.002 (0.003)\tLoss 0.2208 (0.1210)\tPrec 91.406% (95.682%)\n",
      "Epoch: [119][300/391]\tTime 0.043 (0.045)\tData 0.002 (0.002)\tLoss 0.1798 (0.1227)\tPrec 94.531% (95.640%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.2773 (0.2773)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.740% \n",
      "best acc: 88.190000\n",
      "Epoch: [120][0/391]\tTime 0.248 (0.248)\tData 0.190 (0.190)\tLoss 0.0757 (0.0757)\tPrec 96.875% (96.875%)\n",
      "Epoch: [120][100/391]\tTime 0.038 (0.040)\tData 0.001 (0.003)\tLoss 0.1389 (0.1162)\tPrec 95.312% (95.962%)\n",
      "Epoch: [120][200/391]\tTime 0.039 (0.041)\tData 0.002 (0.003)\tLoss 0.1470 (0.1194)\tPrec 96.875% (95.759%)\n",
      "Epoch: [120][300/391]\tTime 0.052 (0.041)\tData 0.002 (0.002)\tLoss 0.1179 (0.1221)\tPrec 95.312% (95.554%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.3786 (0.3786)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.830% \n",
      "best acc: 88.190000\n",
      "Epoch: [121][0/391]\tTime 0.298 (0.298)\tData 0.219 (0.219)\tLoss 0.1415 (0.1415)\tPrec 93.750% (93.750%)\n",
      "Epoch: [121][100/391]\tTime 0.049 (0.051)\tData 0.002 (0.004)\tLoss 0.1632 (0.1191)\tPrec 93.750% (95.800%)\n",
      "Epoch: [121][200/391]\tTime 0.043 (0.046)\tData 0.002 (0.003)\tLoss 0.1197 (0.1247)\tPrec 96.875% (95.623%)\n",
      "Epoch: [121][300/391]\tTime 0.042 (0.047)\tData 0.001 (0.003)\tLoss 0.1356 (0.1254)\tPrec 96.094% (95.598%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.2792 (0.2792)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.590% \n",
      "best acc: 88.190000\n",
      "Epoch: [122][0/391]\tTime 0.252 (0.252)\tData 0.202 (0.202)\tLoss 0.0950 (0.0950)\tPrec 97.656% (97.656%)\n",
      "Epoch: [122][100/391]\tTime 0.041 (0.051)\tData 0.002 (0.004)\tLoss 0.1561 (0.1207)\tPrec 93.750% (95.661%)\n",
      "Epoch: [122][200/391]\tTime 0.056 (0.048)\tData 0.002 (0.003)\tLoss 0.1458 (0.1197)\tPrec 95.312% (95.658%)\n",
      "Epoch: [122][300/391]\tTime 0.052 (0.047)\tData 0.001 (0.002)\tLoss 0.1544 (0.1223)\tPrec 93.750% (95.546%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.2937 (0.2937)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.330% \n",
      "best acc: 88.190000\n",
      "Epoch: [123][0/391]\tTime 0.288 (0.288)\tData 0.240 (0.240)\tLoss 0.1193 (0.1193)\tPrec 94.531% (94.531%)\n",
      "Epoch: [123][100/391]\tTime 0.047 (0.045)\tData 0.002 (0.004)\tLoss 0.1238 (0.1185)\tPrec 95.312% (95.730%)\n",
      "Epoch: [123][200/391]\tTime 0.039 (0.045)\tData 0.002 (0.003)\tLoss 0.1358 (0.1196)\tPrec 95.312% (95.756%)\n",
      "Epoch: [123][300/391]\tTime 0.048 (0.044)\tData 0.002 (0.003)\tLoss 0.0895 (0.1202)\tPrec 97.656% (95.746%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.2880 (0.2880)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.400% \n",
      "best acc: 88.190000\n",
      "Epoch: [124][0/391]\tTime 0.300 (0.300)\tData 0.237 (0.237)\tLoss 0.0697 (0.0697)\tPrec 98.438% (98.438%)\n",
      "Epoch: [124][100/391]\tTime 0.045 (0.047)\tData 0.005 (0.004)\tLoss 0.0720 (0.1168)\tPrec 99.219% (96.055%)\n",
      "Epoch: [124][200/391]\tTime 0.059 (0.046)\tData 0.002 (0.003)\tLoss 0.1735 (0.1217)\tPrec 94.531% (95.794%)\n",
      "Epoch: [124][300/391]\tTime 0.054 (0.047)\tData 0.002 (0.003)\tLoss 0.0959 (0.1238)\tPrec 96.875% (95.717%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.2175 (0.2175)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.560% \n",
      "best acc: 88.190000\n",
      "Epoch: [125][0/391]\tTime 0.287 (0.287)\tData 0.226 (0.226)\tLoss 0.1384 (0.1384)\tPrec 93.750% (93.750%)\n",
      "Epoch: [125][100/391]\tTime 0.057 (0.048)\tData 0.002 (0.004)\tLoss 0.1435 (0.1207)\tPrec 93.750% (95.699%)\n",
      "Epoch: [125][200/391]\tTime 0.050 (0.049)\tData 0.002 (0.003)\tLoss 0.1332 (0.1206)\tPrec 95.312% (95.826%)\n",
      "Epoch: [125][300/391]\tTime 0.069 (0.051)\tData 0.003 (0.003)\tLoss 0.2457 (0.1238)\tPrec 90.625% (95.660%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.191 (0.191)\tLoss 0.2914 (0.2914)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.590% \n",
      "best acc: 88.190000\n",
      "Epoch: [126][0/391]\tTime 0.262 (0.262)\tData 0.217 (0.217)\tLoss 0.1679 (0.1679)\tPrec 96.875% (96.875%)\n",
      "Epoch: [126][100/391]\tTime 0.049 (0.050)\tData 0.002 (0.004)\tLoss 0.1295 (0.1152)\tPrec 96.875% (96.016%)\n",
      "Epoch: [126][200/391]\tTime 0.060 (0.050)\tData 0.003 (0.003)\tLoss 0.1694 (0.1155)\tPrec 96.875% (95.962%)\n",
      "Epoch: [126][300/391]\tTime 0.059 (0.049)\tData 0.002 (0.003)\tLoss 0.0783 (0.1193)\tPrec 97.656% (95.800%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.2473 (0.2473)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.200% \n",
      "best acc: 88.190000\n",
      "Epoch: [127][0/391]\tTime 0.241 (0.241)\tData 0.189 (0.189)\tLoss 0.0821 (0.0821)\tPrec 96.094% (96.094%)\n",
      "Epoch: [127][100/391]\tTime 0.052 (0.048)\tData 0.002 (0.004)\tLoss 0.1332 (0.1173)\tPrec 96.094% (95.746%)\n",
      "Epoch: [127][200/391]\tTime 0.039 (0.048)\tData 0.002 (0.003)\tLoss 0.1487 (0.1198)\tPrec 95.312% (95.631%)\n",
      "Epoch: [127][300/391]\tTime 0.043 (0.046)\tData 0.002 (0.002)\tLoss 0.1595 (0.1214)\tPrec 93.750% (95.590%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 0.2683 (0.2683)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.700% \n",
      "best acc: 88.190000\n",
      "Epoch: [128][0/391]\tTime 0.300 (0.300)\tData 0.236 (0.236)\tLoss 0.0638 (0.0638)\tPrec 97.656% (97.656%)\n",
      "Epoch: [128][100/391]\tTime 0.042 (0.046)\tData 0.002 (0.004)\tLoss 0.1691 (0.1200)\tPrec 96.094% (95.924%)\n",
      "Epoch: [128][200/391]\tTime 0.051 (0.047)\tData 0.002 (0.003)\tLoss 0.0818 (0.1193)\tPrec 96.094% (95.822%)\n",
      "Epoch: [128][300/391]\tTime 0.037 (0.046)\tData 0.001 (0.003)\tLoss 0.1346 (0.1218)\tPrec 95.312% (95.645%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.2535 (0.2535)\tPrec 92.188% (92.188%)\n",
      " * Prec 86.730% \n",
      "best acc: 88.190000\n",
      "Epoch: [129][0/391]\tTime 0.250 (0.250)\tData 0.197 (0.197)\tLoss 0.1779 (0.1779)\tPrec 92.188% (92.188%)\n",
      "Epoch: [129][100/391]\tTime 0.041 (0.053)\tData 0.001 (0.004)\tLoss 0.0758 (0.1165)\tPrec 97.656% (95.831%)\n",
      "Epoch: [129][200/391]\tTime 0.037 (0.049)\tData 0.002 (0.003)\tLoss 0.0834 (0.1167)\tPrec 96.875% (95.822%)\n",
      "Epoch: [129][300/391]\tTime 0.032 (0.045)\tData 0.002 (0.002)\tLoss 0.1311 (0.1178)\tPrec 95.312% (95.785%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.2649 (0.2649)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.300% \n",
      "best acc: 88.190000\n",
      "Epoch: [130][0/391]\tTime 0.245 (0.245)\tData 0.186 (0.186)\tLoss 0.1113 (0.1113)\tPrec 96.094% (96.094%)\n",
      "Epoch: [130][100/391]\tTime 0.042 (0.050)\tData 0.001 (0.004)\tLoss 0.1178 (0.1181)\tPrec 96.094% (95.885%)\n",
      "Epoch: [130][200/391]\tTime 0.038 (0.047)\tData 0.002 (0.003)\tLoss 0.1473 (0.1182)\tPrec 95.312% (95.802%)\n",
      "Epoch: [130][300/391]\tTime 0.040 (0.046)\tData 0.001 (0.002)\tLoss 0.1275 (0.1182)\tPrec 95.312% (95.808%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 0.2115 (0.2115)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.590% \n",
      "best acc: 88.190000\n",
      "Epoch: [131][0/391]\tTime 0.290 (0.290)\tData 0.238 (0.238)\tLoss 0.1274 (0.1274)\tPrec 95.312% (95.312%)\n",
      "Epoch: [131][100/391]\tTime 0.052 (0.044)\tData 0.003 (0.004)\tLoss 0.0766 (0.1226)\tPrec 96.875% (95.591%)\n",
      "Epoch: [131][200/391]\tTime 0.053 (0.048)\tData 0.002 (0.003)\tLoss 0.1235 (0.1162)\tPrec 96.094% (95.919%)\n",
      "Epoch: [131][300/391]\tTime 0.040 (0.048)\tData 0.002 (0.003)\tLoss 0.0660 (0.1175)\tPrec 98.438% (95.886%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.2594 (0.2594)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.020% \n",
      "best acc: 88.190000\n",
      "Epoch: [132][0/391]\tTime 0.287 (0.287)\tData 0.227 (0.227)\tLoss 0.0667 (0.0667)\tPrec 97.656% (97.656%)\n",
      "Epoch: [132][100/391]\tTime 0.046 (0.045)\tData 0.002 (0.004)\tLoss 0.1206 (0.1110)\tPrec 95.312% (95.939%)\n",
      "Epoch: [132][200/391]\tTime 0.048 (0.047)\tData 0.002 (0.003)\tLoss 0.1010 (0.1140)\tPrec 96.094% (95.829%)\n",
      "Epoch: [132][300/391]\tTime 0.039 (0.045)\tData 0.001 (0.002)\tLoss 0.1130 (0.1151)\tPrec 97.656% (95.837%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 0.2706 (0.2706)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.510% \n",
      "best acc: 88.190000\n",
      "Epoch: [133][0/391]\tTime 0.291 (0.291)\tData 0.228 (0.228)\tLoss 0.1490 (0.1490)\tPrec 95.312% (95.312%)\n",
      "Epoch: [133][100/391]\tTime 0.049 (0.047)\tData 0.002 (0.004)\tLoss 0.1320 (0.1168)\tPrec 96.875% (95.947%)\n",
      "Epoch: [133][200/391]\tTime 0.040 (0.047)\tData 0.002 (0.003)\tLoss 0.0903 (0.1125)\tPrec 96.875% (95.997%)\n",
      "Epoch: [133][300/391]\tTime 0.040 (0.047)\tData 0.002 (0.003)\tLoss 0.0623 (0.1147)\tPrec 97.656% (95.902%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 0.2739 (0.2739)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.350% \n",
      "best acc: 88.190000\n",
      "Epoch: [134][0/391]\tTime 0.260 (0.260)\tData 0.211 (0.211)\tLoss 0.1420 (0.1420)\tPrec 94.531% (94.531%)\n",
      "Epoch: [134][100/391]\tTime 0.041 (0.047)\tData 0.001 (0.004)\tLoss 0.0923 (0.1156)\tPrec 96.875% (95.939%)\n",
      "Epoch: [134][200/391]\tTime 0.042 (0.044)\tData 0.002 (0.003)\tLoss 0.1246 (0.1190)\tPrec 94.531% (95.693%)\n",
      "Epoch: [134][300/391]\tTime 0.040 (0.044)\tData 0.002 (0.002)\tLoss 0.0683 (0.1187)\tPrec 99.219% (95.751%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.2152 (0.2152)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.700% \n",
      "best acc: 88.190000\n",
      "Epoch: [135][0/391]\tTime 0.278 (0.278)\tData 0.228 (0.228)\tLoss 0.0607 (0.0607)\tPrec 99.219% (99.219%)\n",
      "Epoch: [135][100/391]\tTime 0.053 (0.046)\tData 0.002 (0.004)\tLoss 0.1337 (0.1111)\tPrec 95.312% (96.063%)\n",
      "Epoch: [135][200/391]\tTime 0.046 (0.046)\tData 0.002 (0.003)\tLoss 0.0699 (0.1135)\tPrec 98.438% (95.931%)\n",
      "Epoch: [135][300/391]\tTime 0.039 (0.045)\tData 0.002 (0.002)\tLoss 0.0637 (0.1144)\tPrec 98.438% (95.896%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.1984 (0.1984)\tPrec 93.750% (93.750%)\n",
      " * Prec 87.690% \n",
      "best acc: 88.190000\n",
      "Epoch: [136][0/391]\tTime 0.291 (0.291)\tData 0.225 (0.225)\tLoss 0.0554 (0.0554)\tPrec 96.875% (96.875%)\n",
      "Epoch: [136][100/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.0990 (0.1168)\tPrec 96.875% (95.862%)\n",
      "Epoch: [136][200/391]\tTime 0.040 (0.045)\tData 0.001 (0.003)\tLoss 0.1323 (0.1151)\tPrec 94.531% (95.919%)\n",
      "Epoch: [136][300/391]\tTime 0.069 (0.045)\tData 0.003 (0.002)\tLoss 0.0813 (0.1184)\tPrec 97.656% (95.738%)\n",
      "Validation starts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.1699 (0.1699)\tPrec 93.750% (93.750%)\n",
      " * Prec 87.750% \n",
      "best acc: 88.190000\n",
      "Epoch: [137][0/391]\tTime 0.285 (0.285)\tData 0.219 (0.219)\tLoss 0.0687 (0.0687)\tPrec 97.656% (97.656%)\n",
      "Epoch: [137][100/391]\tTime 0.040 (0.049)\tData 0.001 (0.004)\tLoss 0.0980 (0.1077)\tPrec 96.875% (96.040%)\n",
      "Epoch: [137][200/391]\tTime 0.037 (0.046)\tData 0.001 (0.003)\tLoss 0.0907 (0.1095)\tPrec 97.656% (95.989%)\n",
      "Epoch: [137][300/391]\tTime 0.040 (0.046)\tData 0.001 (0.002)\tLoss 0.0997 (0.1119)\tPrec 96.094% (95.891%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 0.2471 (0.2471)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.440% \n",
      "best acc: 88.190000\n",
      "Epoch: [138][0/391]\tTime 0.281 (0.281)\tData 0.222 (0.222)\tLoss 0.0918 (0.0918)\tPrec 96.094% (96.094%)\n",
      "Epoch: [138][100/391]\tTime 0.043 (0.045)\tData 0.001 (0.004)\tLoss 0.1435 (0.1126)\tPrec 95.312% (95.831%)\n",
      "Epoch: [138][200/391]\tTime 0.039 (0.048)\tData 0.001 (0.003)\tLoss 0.0927 (0.1137)\tPrec 96.875% (95.837%)\n",
      "Epoch: [138][300/391]\tTime 0.038 (0.048)\tData 0.001 (0.003)\tLoss 0.1004 (0.1142)\tPrec 96.875% (95.839%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.252 (0.252)\tLoss 0.2613 (0.2613)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.800% \n",
      "best acc: 88.190000\n",
      "Epoch: [139][0/391]\tTime 0.246 (0.246)\tData 0.202 (0.202)\tLoss 0.1775 (0.1775)\tPrec 94.531% (94.531%)\n",
      "Epoch: [139][100/391]\tTime 0.042 (0.048)\tData 0.002 (0.004)\tLoss 0.0790 (0.1086)\tPrec 96.875% (96.117%)\n",
      "Epoch: [139][200/391]\tTime 0.068 (0.045)\tData 0.002 (0.003)\tLoss 0.0922 (0.1154)\tPrec 97.656% (95.880%)\n",
      "Epoch: [139][300/391]\tTime 0.057 (0.047)\tData 0.002 (0.002)\tLoss 0.1280 (0.1173)\tPrec 95.312% (95.803%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.3240 (0.3240)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.270% \n",
      "best acc: 88.190000\n",
      "Epoch: [140][0/391]\tTime 0.272 (0.272)\tData 0.221 (0.221)\tLoss 0.0655 (0.0655)\tPrec 97.656% (97.656%)\n",
      "Epoch: [140][100/391]\tTime 0.046 (0.049)\tData 0.001 (0.004)\tLoss 0.1251 (0.1145)\tPrec 92.969% (95.947%)\n",
      "Epoch: [140][200/391]\tTime 0.041 (0.046)\tData 0.002 (0.003)\tLoss 0.1771 (0.1160)\tPrec 92.188% (95.864%)\n",
      "Epoch: [140][300/391]\tTime 0.071 (0.047)\tData 0.003 (0.002)\tLoss 0.1048 (0.1177)\tPrec 97.656% (95.754%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 0.2953 (0.2953)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.490% \n",
      "best acc: 88.190000\n",
      "Epoch: [141][0/391]\tTime 0.246 (0.246)\tData 0.189 (0.189)\tLoss 0.0798 (0.0798)\tPrec 98.438% (98.438%)\n",
      "Epoch: [141][100/391]\tTime 0.060 (0.053)\tData 0.002 (0.004)\tLoss 0.1367 (0.1084)\tPrec 93.750% (96.233%)\n",
      "Epoch: [141][200/391]\tTime 0.060 (0.051)\tData 0.002 (0.003)\tLoss 0.0915 (0.1128)\tPrec 98.438% (96.043%)\n",
      "Epoch: [141][300/391]\tTime 0.047 (0.049)\tData 0.002 (0.002)\tLoss 0.0508 (0.1139)\tPrec 99.219% (95.972%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.263 (0.263)\tLoss 0.3071 (0.3071)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.540% \n",
      "best acc: 88.190000\n",
      "Epoch: [142][0/391]\tTime 0.283 (0.283)\tData 0.209 (0.209)\tLoss 0.1057 (0.1057)\tPrec 96.094% (96.094%)\n",
      "Epoch: [142][100/391]\tTime 0.043 (0.049)\tData 0.001 (0.004)\tLoss 0.1381 (0.1105)\tPrec 95.312% (96.040%)\n",
      "Epoch: [142][200/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.0760 (0.1126)\tPrec 96.094% (95.969%)\n",
      "Epoch: [142][300/391]\tTime 0.049 (0.047)\tData 0.002 (0.003)\tLoss 0.0479 (0.1142)\tPrec 97.656% (95.871%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.2992 (0.2992)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.640% \n",
      "best acc: 88.190000\n",
      "Epoch: [143][0/391]\tTime 0.266 (0.266)\tData 0.211 (0.211)\tLoss 0.0417 (0.0417)\tPrec 99.219% (99.219%)\n",
      "Epoch: [143][100/391]\tTime 0.046 (0.050)\tData 0.002 (0.004)\tLoss 0.1122 (0.1099)\tPrec 94.531% (96.140%)\n",
      "Epoch: [143][200/391]\tTime 0.070 (0.050)\tData 0.003 (0.003)\tLoss 0.0545 (0.1103)\tPrec 99.219% (96.121%)\n",
      "Epoch: [143][300/391]\tTime 0.040 (0.048)\tData 0.002 (0.003)\tLoss 0.1502 (0.1109)\tPrec 94.531% (96.063%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.237 (0.237)\tLoss 0.2900 (0.2900)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.280% \n",
      "best acc: 88.190000\n",
      "Epoch: [144][0/391]\tTime 0.276 (0.276)\tData 0.211 (0.211)\tLoss 0.1135 (0.1135)\tPrec 94.531% (94.531%)\n",
      "Epoch: [144][100/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 0.0373 (0.1155)\tPrec 100.000% (95.900%)\n",
      "Epoch: [144][200/391]\tTime 0.037 (0.047)\tData 0.002 (0.003)\tLoss 0.0657 (0.1123)\tPrec 96.875% (96.059%)\n",
      "Epoch: [144][300/391]\tTime 0.048 (0.048)\tData 0.002 (0.003)\tLoss 0.1536 (0.1119)\tPrec 94.531% (96.042%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.2853 (0.2853)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.280% \n",
      "best acc: 88.190000\n",
      "Epoch: [145][0/391]\tTime 0.258 (0.258)\tData 0.210 (0.210)\tLoss 0.0808 (0.0808)\tPrec 96.875% (96.875%)\n",
      "Epoch: [145][100/391]\tTime 0.054 (0.047)\tData 0.002 (0.004)\tLoss 0.1073 (0.1044)\tPrec 96.875% (96.303%)\n",
      "Epoch: [145][200/391]\tTime 0.050 (0.047)\tData 0.002 (0.003)\tLoss 0.0958 (0.1097)\tPrec 96.875% (95.993%)\n",
      "Epoch: [145][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.002)\tLoss 0.1460 (0.1141)\tPrec 93.750% (95.891%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 0.2049 (0.2049)\tPrec 93.750% (93.750%)\n",
      " * Prec 87.800% \n",
      "best acc: 88.190000\n",
      "Epoch: [146][0/391]\tTime 0.297 (0.297)\tData 0.232 (0.232)\tLoss 0.0882 (0.0882)\tPrec 96.875% (96.875%)\n",
      "Epoch: [146][100/391]\tTime 0.067 (0.054)\tData 0.002 (0.004)\tLoss 0.1763 (0.1066)\tPrec 94.531% (96.388%)\n",
      "Epoch: [146][200/391]\tTime 0.052 (0.051)\tData 0.002 (0.003)\tLoss 0.1133 (0.1100)\tPrec 96.875% (96.261%)\n",
      "Epoch: [146][300/391]\tTime 0.037 (0.048)\tData 0.001 (0.003)\tLoss 0.1274 (0.1117)\tPrec 95.312% (96.172%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 0.2746 (0.2746)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.740% \n",
      "best acc: 88.190000\n",
      "Epoch: [147][0/391]\tTime 0.263 (0.263)\tData 0.207 (0.207)\tLoss 0.0985 (0.0985)\tPrec 96.094% (96.094%)\n",
      "Epoch: [147][100/391]\tTime 0.041 (0.046)\tData 0.002 (0.004)\tLoss 0.0743 (0.1076)\tPrec 97.656% (96.016%)\n",
      "Epoch: [147][200/391]\tTime 0.049 (0.047)\tData 0.002 (0.003)\tLoss 0.0913 (0.1089)\tPrec 96.094% (96.051%)\n",
      "Epoch: [147][300/391]\tTime 0.041 (0.048)\tData 0.002 (0.002)\tLoss 0.1329 (0.1128)\tPrec 96.875% (95.881%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 0.2377 (0.2377)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.690% \n",
      "best acc: 88.190000\n",
      "Epoch: [148][0/391]\tTime 0.270 (0.270)\tData 0.214 (0.214)\tLoss 0.1272 (0.1272)\tPrec 96.875% (96.875%)\n",
      "Epoch: [148][100/391]\tTime 0.041 (0.048)\tData 0.002 (0.004)\tLoss 0.1412 (0.1096)\tPrec 94.531% (95.962%)\n",
      "Epoch: [148][200/391]\tTime 0.041 (0.045)\tData 0.002 (0.003)\tLoss 0.0585 (0.1100)\tPrec 98.438% (96.035%)\n",
      "Epoch: [148][300/391]\tTime 0.050 (0.044)\tData 0.002 (0.002)\tLoss 0.1153 (0.1123)\tPrec 95.312% (95.941%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 0.2948 (0.2948)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.010% \n",
      "best acc: 88.190000\n",
      "Epoch: [149][0/391]\tTime 0.292 (0.292)\tData 0.237 (0.237)\tLoss 0.1074 (0.1074)\tPrec 96.875% (96.875%)\n",
      "Epoch: [149][100/391]\tTime 0.061 (0.051)\tData 0.002 (0.004)\tLoss 0.0859 (0.1058)\tPrec 98.438% (96.395%)\n",
      "Epoch: [149][200/391]\tTime 0.044 (0.051)\tData 0.002 (0.003)\tLoss 0.1514 (0.1125)\tPrec 94.531% (96.051%)\n",
      "Epoch: [149][300/391]\tTime 0.037 (0.049)\tData 0.002 (0.003)\tLoss 0.0994 (0.1134)\tPrec 96.875% (96.003%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.252 (0.252)\tLoss 0.3804 (0.3804)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.530% \n",
      "best acc: 88.190000\n",
      "Epoch: [150][0/391]\tTime 0.269 (0.269)\tData 0.212 (0.212)\tLoss 0.1554 (0.1554)\tPrec 93.750% (93.750%)\n",
      "Epoch: [150][100/391]\tTime 0.063 (0.048)\tData 0.003 (0.004)\tLoss 0.0648 (0.1052)\tPrec 98.438% (96.279%)\n",
      "Epoch: [150][200/391]\tTime 0.040 (0.048)\tData 0.001 (0.003)\tLoss 0.0608 (0.0987)\tPrec 96.875% (96.580%)\n",
      "Epoch: [150][300/391]\tTime 0.057 (0.049)\tData 0.002 (0.003)\tLoss 0.1211 (0.0949)\tPrec 96.094% (96.730%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.2564 (0.2564)\tPrec 94.531% (94.531%)\n",
      " * Prec 88.250% \n",
      "best acc: 88.250000\n",
      "Epoch: [151][0/391]\tTime 0.255 (0.255)\tData 0.198 (0.198)\tLoss 0.0738 (0.0738)\tPrec 98.438% (98.438%)\n",
      "Epoch: [151][100/391]\tTime 0.039 (0.049)\tData 0.001 (0.004)\tLoss 0.0626 (0.0890)\tPrec 98.438% (96.914%)\n",
      "Epoch: [151][200/391]\tTime 0.047 (0.047)\tData 0.002 (0.003)\tLoss 0.0827 (0.0875)\tPrec 96.875% (97.034%)\n",
      "Epoch: [151][300/391]\tTime 0.067 (0.050)\tData 0.002 (0.002)\tLoss 0.0472 (0.0866)\tPrec 100.000% (97.041%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.2022 (0.2022)\tPrec 94.531% (94.531%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec 88.090% \n",
      "best acc: 88.250000\n",
      "Epoch: [152][0/391]\tTime 0.265 (0.265)\tData 0.214 (0.214)\tLoss 0.0736 (0.0736)\tPrec 97.656% (97.656%)\n",
      "Epoch: [152][100/391]\tTime 0.041 (0.050)\tData 0.002 (0.004)\tLoss 0.0664 (0.0821)\tPrec 97.656% (97.231%)\n",
      "Epoch: [152][200/391]\tTime 0.042 (0.047)\tData 0.002 (0.003)\tLoss 0.0587 (0.0839)\tPrec 98.438% (97.073%)\n",
      "Epoch: [152][300/391]\tTime 0.046 (0.047)\tData 0.002 (0.002)\tLoss 0.0462 (0.0847)\tPrec 100.000% (97.051%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.1974 (0.1974)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.260% \n",
      "best acc: 88.260000\n",
      "Epoch: [153][0/391]\tTime 0.263 (0.263)\tData 0.209 (0.209)\tLoss 0.0625 (0.0625)\tPrec 97.656% (97.656%)\n",
      "Epoch: [153][100/391]\tTime 0.039 (0.051)\tData 0.002 (0.004)\tLoss 0.0849 (0.0795)\tPrec 96.094% (97.130%)\n",
      "Epoch: [153][200/391]\tTime 0.041 (0.048)\tData 0.002 (0.003)\tLoss 0.1006 (0.0831)\tPrec 96.875% (97.034%)\n",
      "Epoch: [153][300/391]\tTime 0.038 (0.047)\tData 0.002 (0.002)\tLoss 0.0456 (0.0845)\tPrec 99.219% (97.005%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.2347 (0.2347)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.290% \n",
      "best acc: 88.290000\n",
      "Epoch: [154][0/391]\tTime 0.284 (0.284)\tData 0.221 (0.221)\tLoss 0.0608 (0.0608)\tPrec 99.219% (99.219%)\n",
      "Epoch: [154][100/391]\tTime 0.067 (0.046)\tData 0.002 (0.004)\tLoss 0.0757 (0.0841)\tPrec 97.656% (97.169%)\n",
      "Epoch: [154][200/391]\tTime 0.040 (0.049)\tData 0.002 (0.003)\tLoss 0.0620 (0.0819)\tPrec 99.219% (97.209%)\n",
      "Epoch: [154][300/391]\tTime 0.054 (0.048)\tData 0.002 (0.003)\tLoss 0.1358 (0.0835)\tPrec 93.750% (97.148%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.229 (0.229)\tLoss 0.2011 (0.2011)\tPrec 94.531% (94.531%)\n",
      " * Prec 88.140% \n",
      "best acc: 88.290000\n",
      "Epoch: [155][0/391]\tTime 0.291 (0.291)\tData 0.226 (0.226)\tLoss 0.1046 (0.1046)\tPrec 95.312% (95.312%)\n",
      "Epoch: [155][100/391]\tTime 0.041 (0.045)\tData 0.002 (0.004)\tLoss 0.0957 (0.0836)\tPrec 97.656% (97.269%)\n",
      "Epoch: [155][200/391]\tTime 0.049 (0.044)\tData 0.002 (0.003)\tLoss 0.0587 (0.0835)\tPrec 98.438% (97.256%)\n",
      "Epoch: [155][300/391]\tTime 0.036 (0.045)\tData 0.002 (0.003)\tLoss 0.0412 (0.0835)\tPrec 98.438% (97.238%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.2142 (0.2142)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.520% \n",
      "best acc: 88.520000\n",
      "Epoch: [156][0/391]\tTime 0.299 (0.299)\tData 0.242 (0.242)\tLoss 0.1316 (0.1316)\tPrec 93.750% (93.750%)\n",
      "Epoch: [156][100/391]\tTime 0.040 (0.050)\tData 0.002 (0.004)\tLoss 0.1047 (0.0810)\tPrec 96.094% (97.409%)\n",
      "Epoch: [156][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.003)\tLoss 0.0462 (0.0814)\tPrec 98.438% (97.264%)\n",
      "Epoch: [156][300/391]\tTime 0.039 (0.046)\tData 0.001 (0.003)\tLoss 0.1741 (0.0804)\tPrec 92.188% (97.277%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.2352 (0.2352)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.130% \n",
      "best acc: 88.520000\n",
      "Epoch: [157][0/391]\tTime 0.266 (0.266)\tData 0.207 (0.207)\tLoss 0.0755 (0.0755)\tPrec 97.656% (97.656%)\n",
      "Epoch: [157][100/391]\tTime 0.051 (0.053)\tData 0.003 (0.004)\tLoss 0.0715 (0.0757)\tPrec 98.438% (97.532%)\n",
      "Epoch: [157][200/391]\tTime 0.047 (0.054)\tData 0.002 (0.003)\tLoss 0.0567 (0.0775)\tPrec 97.656% (97.423%)\n",
      "Epoch: [157][300/391]\tTime 0.040 (0.052)\tData 0.001 (0.003)\tLoss 0.0697 (0.0784)\tPrec 98.438% (97.345%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.2362 (0.2362)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.340% \n",
      "best acc: 88.520000\n",
      "Epoch: [158][0/391]\tTime 0.261 (0.261)\tData 0.203 (0.203)\tLoss 0.1439 (0.1439)\tPrec 94.531% (94.531%)\n",
      "Epoch: [158][100/391]\tTime 0.048 (0.048)\tData 0.002 (0.004)\tLoss 0.0938 (0.0845)\tPrec 96.094% (97.177%)\n",
      "Epoch: [158][200/391]\tTime 0.043 (0.049)\tData 0.002 (0.003)\tLoss 0.0698 (0.0821)\tPrec 97.656% (97.201%)\n",
      "Epoch: [158][300/391]\tTime 0.052 (0.049)\tData 0.002 (0.003)\tLoss 0.0542 (0.0801)\tPrec 99.219% (97.298%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.2222 (0.2222)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.170% \n",
      "best acc: 88.520000\n",
      "Epoch: [159][0/391]\tTime 0.263 (0.263)\tData 0.213 (0.213)\tLoss 0.0682 (0.0682)\tPrec 97.656% (97.656%)\n",
      "Epoch: [159][100/391]\tTime 0.040 (0.044)\tData 0.002 (0.004)\tLoss 0.0563 (0.0795)\tPrec 97.656% (97.300%)\n",
      "Epoch: [159][200/391]\tTime 0.055 (0.043)\tData 0.002 (0.003)\tLoss 0.1007 (0.0814)\tPrec 96.875% (97.198%)\n",
      "Epoch: [159][300/391]\tTime 0.049 (0.045)\tData 0.002 (0.002)\tLoss 0.0473 (0.0805)\tPrec 99.219% (97.233%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.2369 (0.2369)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.190% \n",
      "best acc: 88.520000\n",
      "Epoch: [160][0/391]\tTime 0.252 (0.252)\tData 0.197 (0.197)\tLoss 0.0817 (0.0817)\tPrec 96.875% (96.875%)\n",
      "Epoch: [160][100/391]\tTime 0.062 (0.051)\tData 0.003 (0.004)\tLoss 0.0497 (0.0776)\tPrec 98.438% (97.239%)\n",
      "Epoch: [160][200/391]\tTime 0.038 (0.049)\tData 0.001 (0.003)\tLoss 0.0870 (0.0784)\tPrec 96.094% (97.236%)\n",
      "Epoch: [160][300/391]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 0.0770 (0.0770)\tPrec 97.656% (97.306%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 0.2444 (0.2444)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.370% \n",
      "best acc: 88.520000\n",
      "Epoch: [161][0/391]\tTime 0.285 (0.285)\tData 0.231 (0.231)\tLoss 0.0588 (0.0588)\tPrec 97.656% (97.656%)\n",
      "Epoch: [161][100/391]\tTime 0.048 (0.052)\tData 0.002 (0.004)\tLoss 0.1174 (0.0782)\tPrec 94.531% (97.409%)\n",
      "Epoch: [161][200/391]\tTime 0.051 (0.052)\tData 0.002 (0.003)\tLoss 0.0706 (0.0765)\tPrec 97.656% (97.458%)\n",
      "Epoch: [161][300/391]\tTime 0.043 (0.050)\tData 0.002 (0.003)\tLoss 0.0797 (0.0768)\tPrec 97.656% (97.438%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 0.2345 (0.2345)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.290% \n",
      "best acc: 88.520000\n",
      "Epoch: [162][0/391]\tTime 0.265 (0.265)\tData 0.202 (0.202)\tLoss 0.1401 (0.1401)\tPrec 95.312% (95.312%)\n",
      "Epoch: [162][100/391]\tTime 0.060 (0.050)\tData 0.002 (0.004)\tLoss 0.0953 (0.0795)\tPrec 96.094% (97.138%)\n",
      "Epoch: [162][200/391]\tTime 0.043 (0.049)\tData 0.002 (0.003)\tLoss 0.0949 (0.0782)\tPrec 96.875% (97.217%)\n",
      "Epoch: [162][300/391]\tTime 0.055 (0.049)\tData 0.002 (0.003)\tLoss 0.0912 (0.0790)\tPrec 96.094% (97.207%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.241 (0.241)\tLoss 0.2583 (0.2583)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.570% \n",
      "best acc: 88.570000\n",
      "Epoch: [163][0/391]\tTime 0.306 (0.306)\tData 0.243 (0.243)\tLoss 0.0621 (0.0621)\tPrec 98.438% (98.438%)\n",
      "Epoch: [163][100/391]\tTime 0.040 (0.043)\tData 0.002 (0.004)\tLoss 0.1134 (0.0753)\tPrec 96.094% (97.486%)\n",
      "Epoch: [163][200/391]\tTime 0.065 (0.045)\tData 0.002 (0.003)\tLoss 0.1191 (0.0783)\tPrec 94.531% (97.357%)\n",
      "Epoch: [163][300/391]\tTime 0.052 (0.045)\tData 0.002 (0.003)\tLoss 0.0628 (0.0801)\tPrec 97.656% (97.327%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.2437 (0.2437)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.400% \n",
      "best acc: 88.570000\n",
      "Epoch: [164][0/391]\tTime 0.252 (0.252)\tData 0.208 (0.208)\tLoss 0.0808 (0.0808)\tPrec 96.094% (96.094%)\n",
      "Epoch: [164][100/391]\tTime 0.062 (0.043)\tData 0.002 (0.004)\tLoss 0.0744 (0.0725)\tPrec 97.656% (97.548%)\n",
      "Epoch: [164][200/391]\tTime 0.043 (0.044)\tData 0.002 (0.003)\tLoss 0.0635 (0.0740)\tPrec 98.438% (97.489%)\n",
      "Epoch: [164][300/391]\tTime 0.063 (0.045)\tData 0.003 (0.002)\tLoss 0.0473 (0.0758)\tPrec 98.438% (97.423%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.2704 (0.2704)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.340% \n",
      "best acc: 88.570000\n",
      "Epoch: [165][0/391]\tTime 0.263 (0.263)\tData 0.196 (0.196)\tLoss 0.1058 (0.1058)\tPrec 96.094% (96.094%)\n",
      "Epoch: [165][100/391]\tTime 0.045 (0.041)\tData 0.002 (0.004)\tLoss 0.0917 (0.0748)\tPrec 95.312% (97.672%)\n",
      "Epoch: [165][200/391]\tTime 0.053 (0.044)\tData 0.002 (0.003)\tLoss 0.0800 (0.0736)\tPrec 96.094% (97.575%)\n",
      "Epoch: [165][300/391]\tTime 0.049 (0.044)\tData 0.002 (0.002)\tLoss 0.0971 (0.0753)\tPrec 95.312% (97.464%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.2619 (0.2619)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.050% \n",
      "best acc: 88.570000\n",
      "Epoch: [166][0/391]\tTime 0.290 (0.290)\tData 0.220 (0.220)\tLoss 0.0648 (0.0648)\tPrec 96.875% (96.875%)\n",
      "Epoch: [166][100/391]\tTime 0.037 (0.048)\tData 0.001 (0.004)\tLoss 0.0547 (0.0810)\tPrec 98.438% (97.153%)\n",
      "Epoch: [166][200/391]\tTime 0.039 (0.046)\tData 0.002 (0.003)\tLoss 0.0525 (0.0790)\tPrec 99.219% (97.260%)\n",
      "Epoch: [166][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.003)\tLoss 0.0593 (0.0784)\tPrec 97.656% (97.259%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.2332 (0.2332)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.380% \n",
      "best acc: 88.570000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [167][0/391]\tTime 0.277 (0.277)\tData 0.224 (0.224)\tLoss 0.0833 (0.0833)\tPrec 97.656% (97.656%)\n",
      "Epoch: [167][100/391]\tTime 0.042 (0.047)\tData 0.002 (0.004)\tLoss 0.0764 (0.0727)\tPrec 96.875% (97.625%)\n",
      "Epoch: [167][200/391]\tTime 0.041 (0.046)\tData 0.002 (0.003)\tLoss 0.1282 (0.0721)\tPrec 95.312% (97.606%)\n",
      "Epoch: [167][300/391]\tTime 0.039 (0.046)\tData 0.001 (0.002)\tLoss 0.0647 (0.0722)\tPrec 97.656% (97.610%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 0.2186 (0.2186)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.390% \n",
      "best acc: 88.570000\n",
      "Epoch: [168][0/391]\tTime 0.261 (0.261)\tData 0.216 (0.216)\tLoss 0.0925 (0.0925)\tPrec 96.875% (96.875%)\n",
      "Epoch: [168][100/391]\tTime 0.037 (0.048)\tData 0.002 (0.004)\tLoss 0.0705 (0.0776)\tPrec 97.656% (97.208%)\n",
      "Epoch: [168][200/391]\tTime 0.044 (0.052)\tData 0.001 (0.003)\tLoss 0.0879 (0.0777)\tPrec 96.094% (97.248%)\n",
      "Epoch: [168][300/391]\tTime 0.056 (0.050)\tData 0.002 (0.003)\tLoss 0.1492 (0.0772)\tPrec 95.312% (97.251%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.2557 (0.2557)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.310% \n",
      "best acc: 88.570000\n",
      "Epoch: [169][0/391]\tTime 0.286 (0.286)\tData 0.221 (0.221)\tLoss 0.0507 (0.0507)\tPrec 98.438% (98.438%)\n",
      "Epoch: [169][100/391]\tTime 0.054 (0.051)\tData 0.002 (0.004)\tLoss 0.0453 (0.0750)\tPrec 100.000% (97.347%)\n",
      "Epoch: [169][200/391]\tTime 0.049 (0.052)\tData 0.002 (0.003)\tLoss 0.1066 (0.0752)\tPrec 96.094% (97.435%)\n",
      "Epoch: [169][300/391]\tTime 0.039 (0.049)\tData 0.002 (0.003)\tLoss 0.0747 (0.0756)\tPrec 96.875% (97.394%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.2287 (0.2287)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.240% \n",
      "best acc: 88.570000\n",
      "Epoch: [170][0/391]\tTime 0.240 (0.240)\tData 0.195 (0.195)\tLoss 0.0784 (0.0784)\tPrec 96.875% (96.875%)\n",
      "Epoch: [170][100/391]\tTime 0.043 (0.047)\tData 0.001 (0.004)\tLoss 0.0368 (0.0747)\tPrec 100.000% (97.478%)\n",
      "Epoch: [170][200/391]\tTime 0.043 (0.047)\tData 0.002 (0.003)\tLoss 0.0356 (0.0734)\tPrec 99.219% (97.559%)\n",
      "Epoch: [170][300/391]\tTime 0.041 (0.047)\tData 0.002 (0.002)\tLoss 0.0412 (0.0752)\tPrec 99.219% (97.462%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.2165 (0.2165)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.330% \n",
      "best acc: 88.570000\n",
      "Epoch: [171][0/391]\tTime 0.285 (0.285)\tData 0.218 (0.218)\tLoss 0.1784 (0.1784)\tPrec 92.188% (92.188%)\n",
      "Epoch: [171][100/391]\tTime 0.066 (0.046)\tData 0.002 (0.004)\tLoss 0.1072 (0.0730)\tPrec 96.875% (97.440%)\n",
      "Epoch: [171][200/391]\tTime 0.042 (0.046)\tData 0.002 (0.003)\tLoss 0.0943 (0.0739)\tPrec 96.094% (97.427%)\n",
      "Epoch: [171][300/391]\tTime 0.053 (0.046)\tData 0.002 (0.002)\tLoss 0.0708 (0.0737)\tPrec 96.875% (97.467%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.2225 (0.2225)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.420% \n",
      "best acc: 88.570000\n",
      "Epoch: [172][0/391]\tTime 0.280 (0.280)\tData 0.214 (0.214)\tLoss 0.0422 (0.0422)\tPrec 98.438% (98.438%)\n",
      "Epoch: [172][100/391]\tTime 0.068 (0.051)\tData 0.003 (0.004)\tLoss 0.0597 (0.0785)\tPrec 97.656% (97.246%)\n",
      "Epoch: [172][200/391]\tTime 0.042 (0.054)\tData 0.002 (0.003)\tLoss 0.0445 (0.0761)\tPrec 97.656% (97.423%)\n",
      "Epoch: [172][300/391]\tTime 0.039 (0.049)\tData 0.002 (0.003)\tLoss 0.0768 (0.0763)\tPrec 97.656% (97.404%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.2121 (0.2121)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.330% \n",
      "best acc: 88.570000\n",
      "Epoch: [173][0/391]\tTime 0.257 (0.257)\tData 0.193 (0.193)\tLoss 0.0306 (0.0306)\tPrec 100.000% (100.000%)\n",
      "Epoch: [173][100/391]\tTime 0.048 (0.046)\tData 0.002 (0.004)\tLoss 0.0506 (0.0709)\tPrec 98.438% (97.579%)\n",
      "Epoch: [173][200/391]\tTime 0.040 (0.046)\tData 0.002 (0.003)\tLoss 0.0620 (0.0723)\tPrec 97.656% (97.497%)\n",
      "Epoch: [173][300/391]\tTime 0.046 (0.045)\tData 0.002 (0.002)\tLoss 0.1001 (0.0754)\tPrec 96.094% (97.384%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.1886 (0.1886)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.270% \n",
      "best acc: 88.570000\n",
      "Epoch: [174][0/391]\tTime 0.267 (0.267)\tData 0.218 (0.218)\tLoss 0.0321 (0.0321)\tPrec 100.000% (100.000%)\n",
      "Epoch: [174][100/391]\tTime 0.044 (0.048)\tData 0.002 (0.004)\tLoss 0.0707 (0.0741)\tPrec 98.438% (97.610%)\n",
      "Epoch: [174][200/391]\tTime 0.039 (0.046)\tData 0.002 (0.003)\tLoss 0.0668 (0.0743)\tPrec 96.875% (97.528%)\n",
      "Epoch: [174][300/391]\tTime 0.069 (0.046)\tData 0.003 (0.002)\tLoss 0.0951 (0.0760)\tPrec 96.094% (97.480%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.227 (0.227)\tLoss 0.2305 (0.2305)\tPrec 94.531% (94.531%)\n",
      " * Prec 88.400% \n",
      "best acc: 88.570000\n",
      "Epoch: [175][0/391]\tTime 0.246 (0.246)\tData 0.202 (0.202)\tLoss 0.0494 (0.0494)\tPrec 97.656% (97.656%)\n",
      "Epoch: [175][100/391]\tTime 0.048 (0.044)\tData 0.002 (0.004)\tLoss 0.0746 (0.0755)\tPrec 96.875% (97.339%)\n",
      "Epoch: [175][200/391]\tTime 0.038 (0.045)\tData 0.002 (0.003)\tLoss 0.0725 (0.0735)\tPrec 96.875% (97.466%)\n",
      "Epoch: [175][300/391]\tTime 0.043 (0.046)\tData 0.002 (0.002)\tLoss 0.0595 (0.0745)\tPrec 97.656% (97.443%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.2308 (0.2308)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.560% \n",
      "best acc: 88.570000\n",
      "Epoch: [176][0/391]\tTime 0.319 (0.319)\tData 0.255 (0.255)\tLoss 0.0406 (0.0406)\tPrec 98.438% (98.438%)\n",
      "Epoch: [176][100/391]\tTime 0.061 (0.048)\tData 0.002 (0.004)\tLoss 0.0902 (0.0766)\tPrec 96.875% (97.184%)\n",
      "Epoch: [176][200/391]\tTime 0.039 (0.047)\tData 0.002 (0.003)\tLoss 0.0668 (0.0758)\tPrec 96.875% (97.326%)\n",
      "Epoch: [176][300/391]\tTime 0.058 (0.045)\tData 0.002 (0.003)\tLoss 0.0929 (0.0750)\tPrec 96.875% (97.381%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.231 (0.231)\tLoss 0.2126 (0.2126)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.350% \n",
      "best acc: 88.570000\n",
      "Epoch: [177][0/391]\tTime 0.278 (0.278)\tData 0.217 (0.217)\tLoss 0.0790 (0.0790)\tPrec 96.094% (96.094%)\n",
      "Epoch: [177][100/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.1028 (0.0752)\tPrec 96.094% (97.331%)\n",
      "Epoch: [177][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.003)\tLoss 0.0290 (0.0765)\tPrec 99.219% (97.314%)\n",
      "Epoch: [177][300/391]\tTime 0.050 (0.048)\tData 0.002 (0.003)\tLoss 0.0372 (0.0756)\tPrec 99.219% (97.433%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 0.2480 (0.2480)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.400% \n",
      "best acc: 88.570000\n",
      "Epoch: [178][0/391]\tTime 0.308 (0.308)\tData 0.241 (0.241)\tLoss 0.0867 (0.0867)\tPrec 98.438% (98.438%)\n",
      "Epoch: [178][100/391]\tTime 0.045 (0.047)\tData 0.001 (0.004)\tLoss 0.0324 (0.0718)\tPrec 100.000% (97.471%)\n",
      "Epoch: [178][200/391]\tTime 0.043 (0.046)\tData 0.002 (0.003)\tLoss 0.0560 (0.0726)\tPrec 98.438% (97.485%)\n",
      "Epoch: [178][300/391]\tTime 0.048 (0.047)\tData 0.002 (0.003)\tLoss 0.1020 (0.0732)\tPrec 96.094% (97.449%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.1986 (0.1986)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.000% \n",
      "best acc: 88.570000\n",
      "Epoch: [179][0/391]\tTime 0.264 (0.264)\tData 0.212 (0.212)\tLoss 0.1022 (0.1022)\tPrec 94.531% (94.531%)\n",
      "Epoch: [179][100/391]\tTime 0.048 (0.050)\tData 0.002 (0.004)\tLoss 0.0645 (0.0745)\tPrec 96.875% (97.471%)\n",
      "Epoch: [179][200/391]\tTime 0.056 (0.049)\tData 0.002 (0.003)\tLoss 0.0533 (0.0731)\tPrec 99.219% (97.567%)\n",
      "Epoch: [179][300/391]\tTime 0.040 (0.048)\tData 0.002 (0.003)\tLoss 0.0661 (0.0744)\tPrec 97.656% (97.482%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.231 (0.231)\tLoss 0.2359 (0.2359)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.350% \n",
      "best acc: 88.570000\n",
      "Epoch: [180][0/391]\tTime 0.279 (0.279)\tData 0.224 (0.224)\tLoss 0.0488 (0.0488)\tPrec 98.438% (98.438%)\n",
      "Epoch: [180][100/391]\tTime 0.044 (0.050)\tData 0.002 (0.004)\tLoss 0.0439 (0.0696)\tPrec 99.219% (97.649%)\n",
      "Epoch: [180][200/391]\tTime 0.038 (0.048)\tData 0.001 (0.003)\tLoss 0.0534 (0.0718)\tPrec 98.438% (97.582%)\n",
      "Epoch: [180][300/391]\tTime 0.042 (0.047)\tData 0.002 (0.002)\tLoss 0.0955 (0.0741)\tPrec 94.531% (97.485%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.2206 (0.2206)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.290% \n",
      "best acc: 88.570000\n",
      "Epoch: [181][0/391]\tTime 0.261 (0.261)\tData 0.212 (0.212)\tLoss 0.0544 (0.0544)\tPrec 99.219% (99.219%)\n",
      "Epoch: [181][100/391]\tTime 0.061 (0.047)\tData 0.002 (0.004)\tLoss 0.0755 (0.0711)\tPrec 96.875% (97.517%)\n",
      "Epoch: [181][200/391]\tTime 0.039 (0.050)\tData 0.002 (0.003)\tLoss 0.1954 (0.0708)\tPrec 93.750% (97.598%)\n",
      "Epoch: [181][300/391]\tTime 0.054 (0.050)\tData 0.002 (0.003)\tLoss 0.1120 (0.0718)\tPrec 96.875% (97.602%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.3018 (0.3018)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.340% \n",
      "best acc: 88.570000\n",
      "Epoch: [182][0/391]\tTime 0.271 (0.271)\tData 0.221 (0.221)\tLoss 0.0668 (0.0668)\tPrec 99.219% (99.219%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [182][100/391]\tTime 0.038 (0.046)\tData 0.001 (0.004)\tLoss 0.0409 (0.0732)\tPrec 99.219% (97.486%)\n",
      "Epoch: [182][200/391]\tTime 0.039 (0.045)\tData 0.002 (0.003)\tLoss 0.0614 (0.0726)\tPrec 97.656% (97.501%)\n",
      "Epoch: [182][300/391]\tTime 0.060 (0.046)\tData 0.002 (0.002)\tLoss 0.1196 (0.0724)\tPrec 96.094% (97.508%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.2453 (0.2453)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.450% \n",
      "best acc: 88.570000\n",
      "Epoch: [183][0/391]\tTime 0.279 (0.279)\tData 0.224 (0.224)\tLoss 0.0750 (0.0750)\tPrec 97.656% (97.656%)\n",
      "Epoch: [183][100/391]\tTime 0.045 (0.043)\tData 0.001 (0.004)\tLoss 0.0692 (0.0726)\tPrec 97.656% (97.679%)\n",
      "Epoch: [183][200/391]\tTime 0.049 (0.046)\tData 0.001 (0.003)\tLoss 0.0874 (0.0729)\tPrec 97.656% (97.625%)\n",
      "Epoch: [183][300/391]\tTime 0.037 (0.047)\tData 0.002 (0.002)\tLoss 0.0597 (0.0742)\tPrec 98.438% (97.552%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.2042 (0.2042)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.050% \n",
      "best acc: 88.570000\n",
      "Epoch: [184][0/391]\tTime 0.271 (0.271)\tData 0.215 (0.215)\tLoss 0.0794 (0.0794)\tPrec 97.656% (97.656%)\n",
      "Epoch: [184][100/391]\tTime 0.043 (0.048)\tData 0.002 (0.004)\tLoss 0.0853 (0.0741)\tPrec 96.094% (97.447%)\n",
      "Epoch: [184][200/391]\tTime 0.042 (0.047)\tData 0.001 (0.003)\tLoss 0.0510 (0.0743)\tPrec 99.219% (97.400%)\n",
      "Epoch: [184][300/391]\tTime 0.041 (0.046)\tData 0.002 (0.002)\tLoss 0.0347 (0.0733)\tPrec 99.219% (97.482%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 0.2168 (0.2168)\tPrec 94.531% (94.531%)\n",
      " * Prec 88.230% \n",
      "best acc: 88.570000\n",
      "Epoch: [185][0/391]\tTime 0.256 (0.256)\tData 0.201 (0.201)\tLoss 0.0372 (0.0372)\tPrec 99.219% (99.219%)\n",
      "Epoch: [185][100/391]\tTime 0.058 (0.050)\tData 0.002 (0.004)\tLoss 0.0992 (0.0649)\tPrec 95.312% (97.765%)\n",
      "Epoch: [185][200/391]\tTime 0.060 (0.051)\tData 0.002 (0.003)\tLoss 0.0540 (0.0710)\tPrec 98.438% (97.528%)\n",
      "Epoch: [185][300/391]\tTime 0.050 (0.049)\tData 0.002 (0.002)\tLoss 0.0886 (0.0724)\tPrec 96.875% (97.459%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.2559 (0.2559)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.470% \n",
      "best acc: 88.570000\n",
      "Epoch: [186][0/391]\tTime 0.303 (0.303)\tData 0.244 (0.244)\tLoss 0.0493 (0.0493)\tPrec 99.219% (99.219%)\n",
      "Epoch: [186][100/391]\tTime 0.039 (0.047)\tData 0.002 (0.004)\tLoss 0.0383 (0.0723)\tPrec 100.000% (97.556%)\n",
      "Epoch: [186][200/391]\tTime 0.061 (0.045)\tData 0.003 (0.003)\tLoss 0.0771 (0.0760)\tPrec 96.875% (97.345%)\n",
      "Epoch: [186][300/391]\tTime 0.058 (0.047)\tData 0.002 (0.003)\tLoss 0.0706 (0.0761)\tPrec 96.875% (97.363%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.184 (0.184)\tLoss 0.2708 (0.2708)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.430% \n",
      "best acc: 88.570000\n",
      "Epoch: [187][0/391]\tTime 0.298 (0.298)\tData 0.233 (0.233)\tLoss 0.0449 (0.0449)\tPrec 98.438% (98.438%)\n",
      "Epoch: [187][100/391]\tTime 0.057 (0.051)\tData 0.002 (0.004)\tLoss 0.0962 (0.0748)\tPrec 96.094% (97.409%)\n",
      "Epoch: [187][200/391]\tTime 0.051 (0.049)\tData 0.002 (0.003)\tLoss 0.0793 (0.0750)\tPrec 97.656% (97.431%)\n",
      "Epoch: [187][300/391]\tTime 0.040 (0.049)\tData 0.001 (0.003)\tLoss 0.0396 (0.0752)\tPrec 100.000% (97.386%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.2500 (0.2500)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.470% \n",
      "best acc: 88.570000\n",
      "Epoch: [188][0/391]\tTime 0.261 (0.261)\tData 0.209 (0.209)\tLoss 0.0835 (0.0835)\tPrec 97.656% (97.656%)\n",
      "Epoch: [188][100/391]\tTime 0.046 (0.053)\tData 0.002 (0.004)\tLoss 0.0705 (0.0719)\tPrec 96.875% (97.556%)\n",
      "Epoch: [188][200/391]\tTime 0.049 (0.051)\tData 0.002 (0.003)\tLoss 0.0698 (0.0730)\tPrec 96.875% (97.536%)\n",
      "Epoch: [188][300/391]\tTime 0.044 (0.049)\tData 0.002 (0.003)\tLoss 0.0318 (0.0730)\tPrec 99.219% (97.526%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.2537 (0.2537)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.240% \n",
      "best acc: 88.570000\n",
      "Epoch: [189][0/391]\tTime 0.278 (0.278)\tData 0.219 (0.219)\tLoss 0.0885 (0.0885)\tPrec 97.656% (97.656%)\n",
      "Epoch: [189][100/391]\tTime 0.046 (0.050)\tData 0.002 (0.004)\tLoss 0.0458 (0.0698)\tPrec 98.438% (97.672%)\n",
      "Epoch: [189][200/391]\tTime 0.037 (0.047)\tData 0.002 (0.003)\tLoss 0.0551 (0.0722)\tPrec 98.438% (97.551%)\n",
      "Epoch: [189][300/391]\tTime 0.046 (0.045)\tData 0.002 (0.002)\tLoss 0.0328 (0.0710)\tPrec 99.219% (97.602%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.2274 (0.2274)\tPrec 94.531% (94.531%)\n",
      " * Prec 88.450% \n",
      "best acc: 88.570000\n",
      "Epoch: [190][0/391]\tTime 0.267 (0.267)\tData 0.213 (0.213)\tLoss 0.0889 (0.0889)\tPrec 96.875% (96.875%)\n",
      "Epoch: [190][100/391]\tTime 0.048 (0.045)\tData 0.002 (0.004)\tLoss 0.0712 (0.0718)\tPrec 96.094% (97.563%)\n",
      "Epoch: [190][200/391]\tTime 0.041 (0.043)\tData 0.002 (0.003)\tLoss 0.0757 (0.0703)\tPrec 97.656% (97.629%)\n",
      "Epoch: [190][300/391]\tTime 0.055 (0.043)\tData 0.002 (0.002)\tLoss 0.0728 (0.0719)\tPrec 97.656% (97.537%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.1915 (0.1915)\tPrec 94.531% (94.531%)\n",
      " * Prec 88.360% \n",
      "best acc: 88.570000\n",
      "Epoch: [191][0/391]\tTime 0.263 (0.263)\tData 0.211 (0.211)\tLoss 0.0413 (0.0413)\tPrec 98.438% (98.438%)\n",
      "Epoch: [191][100/391]\tTime 0.042 (0.048)\tData 0.002 (0.004)\tLoss 0.0742 (0.0673)\tPrec 96.094% (97.664%)\n",
      "Epoch: [191][200/391]\tTime 0.039 (0.047)\tData 0.002 (0.003)\tLoss 0.0729 (0.0698)\tPrec 97.656% (97.625%)\n",
      "Epoch: [191][300/391]\tTime 0.042 (0.046)\tData 0.001 (0.002)\tLoss 0.0933 (0.0708)\tPrec 96.875% (97.552%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.2634 (0.2634)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.390% \n",
      "best acc: 88.570000\n",
      "Epoch: [192][0/391]\tTime 0.271 (0.271)\tData 0.213 (0.213)\tLoss 0.0696 (0.0696)\tPrec 96.875% (96.875%)\n",
      "Epoch: [192][100/391]\tTime 0.042 (0.048)\tData 0.002 (0.004)\tLoss 0.0355 (0.0701)\tPrec 99.219% (97.695%)\n",
      "Epoch: [192][200/391]\tTime 0.039 (0.046)\tData 0.002 (0.003)\tLoss 0.0498 (0.0705)\tPrec 98.438% (97.664%)\n",
      "Epoch: [192][300/391]\tTime 0.041 (0.045)\tData 0.002 (0.002)\tLoss 0.0691 (0.0702)\tPrec 97.656% (97.680%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.2274 (0.2274)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.480% \n",
      "best acc: 88.570000\n",
      "Epoch: [193][0/391]\tTime 0.278 (0.278)\tData 0.225 (0.225)\tLoss 0.0477 (0.0477)\tPrec 97.656% (97.656%)\n",
      "Epoch: [193][100/391]\tTime 0.046 (0.047)\tData 0.002 (0.004)\tLoss 0.0276 (0.0702)\tPrec 100.000% (97.587%)\n",
      "Epoch: [193][200/391]\tTime 0.049 (0.046)\tData 0.002 (0.003)\tLoss 0.0497 (0.0699)\tPrec 99.219% (97.547%)\n",
      "Epoch: [193][300/391]\tTime 0.042 (0.045)\tData 0.002 (0.002)\tLoss 0.1001 (0.0708)\tPrec 97.656% (97.529%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.3015 (0.3015)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.310% \n",
      "best acc: 88.570000\n",
      "Epoch: [194][0/391]\tTime 0.266 (0.266)\tData 0.212 (0.212)\tLoss 0.0926 (0.0926)\tPrec 96.875% (96.875%)\n",
      "Epoch: [194][100/391]\tTime 0.050 (0.046)\tData 0.002 (0.004)\tLoss 0.0296 (0.0723)\tPrec 99.219% (97.610%)\n",
      "Epoch: [194][200/391]\tTime 0.057 (0.046)\tData 0.002 (0.003)\tLoss 0.0703 (0.0706)\tPrec 96.875% (97.660%)\n",
      "Epoch: [194][300/391]\tTime 0.042 (0.046)\tData 0.002 (0.002)\tLoss 0.0837 (0.0701)\tPrec 96.094% (97.680%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.2805 (0.2805)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.590% \n",
      "best acc: 88.590000\n",
      "Epoch: [195][0/391]\tTime 0.275 (0.275)\tData 0.220 (0.220)\tLoss 0.0624 (0.0624)\tPrec 97.656% (97.656%)\n",
      "Epoch: [195][100/391]\tTime 0.049 (0.051)\tData 0.002 (0.004)\tLoss 0.0558 (0.0733)\tPrec 98.438% (97.486%)\n",
      "Epoch: [195][200/391]\tTime 0.041 (0.049)\tData 0.002 (0.003)\tLoss 0.0425 (0.0731)\tPrec 97.656% (97.493%)\n",
      "Epoch: [195][300/391]\tTime 0.042 (0.048)\tData 0.002 (0.003)\tLoss 0.0946 (0.0731)\tPrec 95.312% (97.526%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 0.2691 (0.2691)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.210% \n",
      "best acc: 88.590000\n",
      "Epoch: [196][0/391]\tTime 0.285 (0.285)\tData 0.226 (0.226)\tLoss 0.0806 (0.0806)\tPrec 97.656% (97.656%)\n",
      "Epoch: [196][100/391]\tTime 0.047 (0.050)\tData 0.002 (0.004)\tLoss 0.0251 (0.0676)\tPrec 100.000% (97.850%)\n",
      "Epoch: [196][200/391]\tTime 0.038 (0.050)\tData 0.002 (0.003)\tLoss 0.1012 (0.0685)\tPrec 96.875% (97.773%)\n",
      "Epoch: [196][300/391]\tTime 0.046 (0.050)\tData 0.002 (0.003)\tLoss 0.0325 (0.0699)\tPrec 99.219% (97.680%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.237 (0.237)\tLoss 0.2364 (0.2364)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.590% \n",
      "best acc: 88.590000\n",
      "Epoch: [197][0/391]\tTime 0.296 (0.296)\tData 0.238 (0.238)\tLoss 0.0858 (0.0858)\tPrec 96.875% (96.875%)\n",
      "Epoch: [197][100/391]\tTime 0.039 (0.053)\tData 0.002 (0.004)\tLoss 0.0212 (0.0771)\tPrec 100.000% (97.401%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [197][200/391]\tTime 0.041 (0.052)\tData 0.002 (0.003)\tLoss 0.0450 (0.0727)\tPrec 97.656% (97.547%)\n",
      "Epoch: [197][300/391]\tTime 0.045 (0.049)\tData 0.002 (0.003)\tLoss 0.0283 (0.0720)\tPrec 100.000% (97.555%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.2182 (0.2182)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.110% \n",
      "best acc: 88.590000\n",
      "Epoch: [198][0/391]\tTime 0.251 (0.251)\tData 0.199 (0.199)\tLoss 0.0641 (0.0641)\tPrec 99.219% (99.219%)\n",
      "Epoch: [198][100/391]\tTime 0.043 (0.048)\tData 0.002 (0.004)\tLoss 0.0728 (0.0730)\tPrec 98.438% (97.471%)\n",
      "Epoch: [198][200/391]\tTime 0.038 (0.045)\tData 0.001 (0.003)\tLoss 0.0786 (0.0720)\tPrec 96.094% (97.547%)\n",
      "Epoch: [198][300/391]\tTime 0.052 (0.049)\tData 0.002 (0.002)\tLoss 0.0338 (0.0717)\tPrec 100.000% (97.599%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.2256 (0.2256)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.400% \n",
      "best acc: 88.590000\n",
      "Epoch: [199][0/391]\tTime 0.277 (0.277)\tData 0.216 (0.216)\tLoss 0.0945 (0.0945)\tPrec 96.094% (96.094%)\n",
      "Epoch: [199][100/391]\tTime 0.046 (0.052)\tData 0.002 (0.004)\tLoss 0.0245 (0.0731)\tPrec 100.000% (97.378%)\n",
      "Epoch: [199][200/391]\tTime 0.060 (0.052)\tData 0.002 (0.003)\tLoss 0.0870 (0.0729)\tPrec 96.875% (97.442%)\n",
      "Epoch: [199][300/391]\tTime 0.047 (0.051)\tData 0.002 (0.003)\tLoss 0.0592 (0.0731)\tPrec 96.875% (97.464%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.230 (0.230)\tLoss 0.2538 (0.2538)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.220% \n",
      "best acc: 88.590000\n"
     ]
    }
   ],
   "source": [
    "# This cell won't be given, but students will complete the training\n",
    "\n",
    "lr = 4e-3\n",
    "weight_decay = 1e-4\n",
    "epochs = 200\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decreased-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW\n",
    "\n",
    "#  1. Train with 4 bits for both weight and activation to achieve >90% accuracy\n",
    "#  2. Find x_int and w_int for the 2nd convolution layer\n",
    "#  3. Check the recovered psum has similar value to the un-quantized original psum\n",
    "#     (such as example 1 in W3S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8861/10000 (89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/resnet20_cifar_project/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "1st convolution's input size: torch.Size([128, 3, 32, 32])\n",
      "2nd convolution's input size: torch.Size([128, 8, 32, 32])\n",
      "ResNet_Cifar(\n",
      "  (conv1): QuantConv2d(\n",
      "    3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "    (weight_quant): weight_quantize_fn()\n",
      "  )\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          8, 32, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#send an input and grap the value by using prehook like HW3\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        print(\"prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)       ## Input for the module will be grapped       \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "out = model(images)\n",
    "print(\"1st convolution's input size:\", save_output.outputs[0][0].size())\n",
    "print(\"2nd convolution's input size:\", save_output.outputs[1][0].size())\n",
    "test = model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "759e7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_bit = 4\n",
    "w_alpha = 4\n",
    "weight_q = model.layer1[0].conv2.weight_q # quantized value is stored during the training\n",
    "w_delta      = w_alpha/(2**(w_bit-1)-1)\n",
    "w_int        = weight_q/w_delta\n",
    "#print(w_int) # you should see clean integer numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d65c2d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x_bit = 4\n",
    "x = save_output.outputs[1][0]  # input of the 2nd conv layer\n",
    "x_alpha  = 4\n",
    "x_delta = x_alpha/(2**x_bit-1)\n",
    "\n",
    "act_quant_fn = act_quantization(x_bit) # define the quantization function\n",
    "x_q = act_quant_fn(x, x_alpha)         # create the quantized value for x\n",
    "\n",
    "x_int = x_q/x_delta\n",
    "#print(x_int) # you should see clean integer numbers \n",
    "print(w_int.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b4ecf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 64, out_channels=64, kernel_size = 3, bias = False)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(w_int)\n",
    "\n",
    "output_int =  conv_int(x_int)\n",
    "output_recovered = output_int*w_delta*x_delta\n",
    "#print(output_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf17ede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicBlock(\n",
      "  (conv1): QuantConv2d(\n",
      "    8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "    (weight_quant): weight_quantize_fn()\n",
      "  )\n",
      "  (conv2): QuantConv2d(\n",
      "    8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "    (weight_quant): weight_quantize_fn()\n",
      "  )\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#### input floating number / weight quantized version\n",
    "print(model.layer1[0])\n",
    "conv_ref = torch.nn.Conv2d(in_channels = 64, out_channels=64, kernel_size = 3, bias = False)\n",
    "conv_ref.weight = model.layer1[0].conv2.weight_q\n",
    "\n",
    "output_recovered = model.layer1[0].bn1(output_recovered)\n",
    "output_recovered = model.layer1[0].relu(output_recovered)\n",
    "#print(output_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea9f3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ref = save_output.outputs[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e61e2ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 8, 30, 30])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_recovered.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "67192ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 8, 32, 32])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ref.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "496fc759",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (30) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_108/3793132888.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdifference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0moutput_ref\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moutput_recovered\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m## It should be small, e.g.,2.3 in my trainned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (30) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "difference = abs( output_ref - output_recovered )\n",
    "print(difference.mean())  ## It should be small, e.g.,2.3 in my trainned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d3aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-serbia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
